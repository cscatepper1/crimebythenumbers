[["scrape-table.html", "2 Scraping tables from PDFs 2.1 Scraping the first table 2.2 Making a function", " 2 Scraping tables from PDFs For this chapter youll need the following file, which is available for download here: usbp_stats_fy2017_sector_profile.pdf. Government agencies in particular like to release their data in long PDFs which often have the data we want in a table on one of the pages. To use this data we need to scrape it from the PDF into R. In the majority of cases when you want data from a PDF it will be in a table. Essentially the data will be an Excel file inside of a PDF. This format is not altogether different than what weve done before. Lets first take a look at the data we will be scraping. The first step in any PDF scraping should be to look at the PDF and try to think about the best way to approach this particular problem. While all PDF scraping follows a general format, you cannot necessarily reuse your old code as each situation is likely slightly different. Our data is from the US Customs and Border Protection (CBP) and contains a wealth of information about apprehensions and contraband seizures in border sectors. We will be using the Sector Profile 2017 PDF which has information in four tables, three of which well scrape and then combine together. The data was downloaded from the US Customs and Border Protection Stats and Summaries page here. If youre interested in using more of their data, some of it has been cleaned and made available here. The file we want to use is called usbp_stats_fy2017_sector_profile.pdf and has four tables in the PDF. Lets take a look at them one at a time, understanding what variables are available, and what units each row is in. Then well start scraping the tables. The first table is Sector Profile - Fiscal Year 2017 (Oct. 1st through Sept. 30th). Before we even look down more at the table, the title is important. It is for fiscal year 2017, not calendar year 2017 which is more common in the data we usually use. This is important if we ever want to merge this data with other data sets. If possible, we would have to get data that is monthly so we can just use October 2016 through September 2017 to match up properly. Now if we look more at the table, we can see that each row is a section of the US border. There are three main sections - Coastal, Northern, and Southwest, with subsections of each also included. The bottom row is the sum of all these sections and gives us nationwide data. Many government data sets will be like this form with sections and subsections in the same table. Watch out when doing mathematical operations! Just summing any of these columns will give you triple the true value due to the presence of nationwide, sectional, and subsectional data. There are 9 columns in the data other than the border section identifier. We have total apprehensions, apprehensions for people who are not Mexican citizens, marijuana and cocaine seizures (in pounds), the number of accepted prosecutions (presumably of those apprehended), and the number of CBP agents assaulted. The last two columns have the number of people rescued by CBP and the number of people who died (it is unclear from this data alone if this is solely people in custody or deaths during crossing the border). These two columns are also special as they only have data for the Southwest border. Table 2 has a similar format with each row being a section or subsection. The columns now have the number of juveniles apprehended, subdivided by if they were accompanied by an adult or not, and the number of adults apprehended. The last column is total apprehensions which is also in Table 1. Table 3 follows the same format and the new columns are number of apprehensions by gender. Finally, Table 4 is a bit different in its format. The rows are now variables and the columns are the locations. In this table it doesnt include subsections, only border sections and the nationwide total. The data it has available are partially a repeat of Table 1 but with more drug types and the addition of the number of drug seizures and some firearm seizure information. As this table is formatted differently than the others, we wont scrape it in this lesson - but you can use the skills youll learn to do so yourself. 2.1 Scraping the first table Weve now seen all three of the tables that we want to scrape so we can begin the process of actually scraping them. Note that each table is very similar meaning that we can reuse some code to scrape as well as to clean the data. That means that we will want to write some functions to make our work easier and avoid copy and pasting code. We will start by using the pdf_text() function from the pdftools package to read the PDFs into R. install.packages(&quot;pdftools&quot;) library(pdftools) #&gt; Using poppler version 21.04.0 We can assign the output of the pdf_text() function to the object border_patrol and well use it for each table. The input to pdf_text() is the name of the PDF we want to scrape. border_patrol &lt;- pdf_text(&quot;data/usbp_stats_fy2017_sector_profile.pdf&quot;) We can take a look at the head() of the result using head(border_patrol). Given the length of this option, I put run the code here, but you should do so on your own computer. If you look closely in this huge amount of text output, you can see that it is a vector with each table being an element in the vector. We can see this further by checking the length() of border_patrol which tells us how many elements are in a vector. length(border_patrol) [1] 4 It is four elements long, one for each table. Looking at just the first element in border_patrol gives us all the values in the first table plus a few sentences at the end detailing some features of the table. At the end of each line (where in the PDF it should end but doesnt in our data yet) there is a \\n indicating that there should be a new line. We want to use strsplit() to split at the \\n. border_patrol[1] United States Border Patrol Sector Profile - Fiscal Year 2017 (Oct. 1st through Sept. 30th) Agent Other Than Mexican Marijuana Cocaine Accepted SECTOR Staffing* Apprehensions Apprehensions (pounds) (pounds) Prosecutions Assaults Rescues Deaths Miami 111 2,280 1,646 2,253 231 292 1 N/A N/A New Orleans 63 920 528 21 6 10 0 N/A N/A Ramey 38 388 387 3 2,932 89 0 N/A N/A Coastal Border Sectors Total 212 3,588 2,561 2,277 3,169 391 1 N/A **** N/A **** Blaine 296 288 237 0 0 9 0 N/A N/A Buffalo 277 447 293 228 2 37 2 N/A N/A Detroit 408 1,070 322 124 0 85 1 N/A N/A Grand Forks 189 496 202 0 0 40 2 N/A N/A Havre 183 39 28 98 0 2 0 N/A N/A Houlton 173 30 30 17 0 2 0 N/A N/A Spokane 230 208 67 68 0 24 0 N/A N/A Swanton 292 449 359 531 1 103 6 N/A N/A Northern Border Sectors Total 2,048 3,027 1,538 1,066 3 302 11 N/A **** N/A **** Big Bend (formerly Marfa) 500 6,002 3,346 40,852 45 2,847 11 26 1 Del Rio 1,391 13,476 6,156 9,482 62 8,022 12 99 18 El Centro 870 18,633 5,812 5,554 484 1,413 34 4 2 El Paso 2,182 25,193 15,337 34,189 140 6,996 54 44 8 Laredo 1,666 25,460 7,891 69,535 757 6,119 31 1,054 83 Rio Grande Valley (formerly McAllen) 3,130 137,562 107,909 260,020 1,192 7,979 422 1,190 104 San Diego 2,199 26,086 7,060 10,985 2,903 3,099 84 48 4 Tucson 3,691 38,657 12,328 397,090 331 20,963 93 750 72 Yuma 859 12,847 10,139 30,181 261 2,367 33 6 2 Southwest Border Sectors Total** 16,605 303,916 175,978 857,888 6,174 59,805 774 3,221 294 Nationwide Total*** 19,437 310,531 180,077 861,231 9,346 60,498 786 3,221 294 * Agent staffing statistics depict FY17 on-board personnel data as of 9/30/2017 ** Southwest Border Sectors staffing statistics include: Big Bend, Del Rio, El Centro, El Paso, Laredo, Rio Grande Valley, San Diego, Tucson, Yuma, and the Special Operations Group. *** Nationwide staffing statistics include: All on-board Border Patrol agents in CBP **** Rescue and Death statistics are not tracked for Northern and Coastal Border Sectors. The strsplit() function breaks up a string into pieces based on a value inside of the string. Lets use the word criminology as an example. If we want to split it by the letter n wed have two results, crimi and ology as these are the pieces of the word after breaking up criminology at letter n. strsplit(&quot;criminology&quot;, split = &quot;n&quot;) #&gt; [[1]] #&gt; [1] &quot;crimi&quot; &quot;ology&quot; Note that it deletes whatever value is used to break up the string. Lets assign a new object with the value in the first element of border_patrol, calling it sector_profile as thats the name of that table, and then using strsplit() on it to split it every \\n. In effect this makes each line of the table an element in a vector that well create rather than having the entire table be a single long string as it is now. strsplit() returns a list so we will also want to keep just the first element of that list using double square bracket [[]] notation. sector_profile &lt;- border_patrol[1] sector_profile &lt;- strsplit(sector_profile, &quot;\\n&quot;) sector_profile &lt;- sector_profile[[1]] Now we can look at the first six rows of this data. head(sector_profile) [1]  United States Border Patrol [2]  Sector Profile - Fiscal Year 2017 (Oct. 1st through Sept. 30th) [3]  [4]  Agent Other Than Mexican Marijuana Cocaine Accepted [5]  SECTOR Staffing* [6]  Apprehensions Notice that there is a lot of empty white space at the beginning of the rows. We want to get rid of that to make our next steps easier. We can use trimws() and put the entire sector_profile data in the () and itll remove any white space that is at the beginning or end of the string. sector_profile &lt;- trimws(sector_profile) We have more rows than we want so lets look at the entire data and try to figure out how to keep just the necessary rows. sector_profile [1] United States Border Patrol [2] Sector Profile - Fiscal Year 2017 (Oct. 1st through Sept. 30th) [3]  [4] Agent Other Than Mexican Marijuana Cocaine Accepted [5] SECTOR Staffing [6] Apprehensions [7] Apprehensions (pounds) (pounds) Prosecutions [8] Assaults Rescues Deaths [9]  [10] Miami 111 2,280 1,646 2,253 231 292 1 N/A N/A [11] New Orleans 63 920 528 21 6 10 0 N/A N/A [12] Ramey 38 388 387 3 2,932 89 0 N/A N/A [13] Coastal Border Sectors Total 212 3,588 2,561 2,277 3,169 391 1 N/A *** N/A **** [14]  [15] Blaine 296 288 237 0 0 9 0 N/A N/A [16] Buffalo 277 447 293 228 2 37 2 N/A N/A [17] Detroit 408 1,070 322 124 0 85 1 N/A N/A [18] Grand Forks 189 496 202 0 0 40 2 N/A N/A [19] Havre 183 39 28 98 0 2 0 N/A N/A [20] Houlton 173 30 30 17 0 2 0 N/A N/A [21] Spokane 230 208 67 68 0 24 0 N/A N/A [22] Swanton 292 449 359 531 1 103 6 N/A N/A [23] Northern Border Sectors Total 2,048 3,027 1,538 1,066 3 302 11 N/A **** N/A **** [24] Big Bend (formerly Marfa) 500 6,002 3,346 40,852 45 2,847 11 26 1 [25] Del Rio 1,391 13,476 6,156 9,482 62 8,022 12 99 18 [26] El Centro 870 18,633 5,812 5,554 484 1,413 34 4 2 [27] El Paso 2,182 25,193 15,337 34,189 140 6,996 54 44 8 [28] Laredo 1,666 25,460 7,891 69,535 757 6,119 31 1,054 83 [29] Rio Grande Valley (formerly McAllen) 3,130 137,562 107,909 260,020 1,192 7,979 422 1,190 104 [30] San Diego 2,199 26,086 7,060 10,985 2,903 3,099 84 48 4 [31] Tucson 3,691 38,657 12,328 397,090 331 20,963 93 750 72 [32] Yuma 859 12,847 10,139 30,181 261 2,367 33 6 2 [33] Southwest Border Sectors Total** 16,605 303,916 175,978 857,888 6,174 59,805 774 3,221 294 [34] Nationwide Total*** 19,437 310,531 180,077 861,231 9,346 60,498 786 3,221 294 [35] * Agent staffing statistics depict FY17 on-board personnel data as of 9/30/2017 [36] ** Southwest Border Sectors staffing statistics include: Big Bend, Del Rio, El Centro, El Paso, Laredo, Rio Grande Valley, San Diego, Tucson, Yuma, and the Special Operations Group. [37] *** Nationwide staffing statistics include: All on-board Border Patrol agents in CBP [38] **** Rescue and Death statistics are not tracked for Northern and Coastal Border Sectors. Based on the PDF, we want every row from Miami to Nationwide Total. But here we have several rows with the title of the table and the column names, and at the end we have the sentences with some details that we dont need. To keep only the rows that we want, we can combine grep() and subsetting to find the rows from Miami to Nationwide Total and keep only those rows. We will use grep() to find which row has the text Miami and which has the text Nationwide Total and keep all rows between them (including those matched rows as well). Since each only appears once in the table we dont need to worry about handling duplicate results. grep(&quot;Miami&quot;, sector_profile) #&gt; [1] 10 grep(&quot;Nationwide Total&quot;, sector_profile) #&gt; [1] 34 Well use square bracket notation to keep all rows between those two values (including each value). Since the data is a vector, not a data.frame, we dont need a comma. sector_profile &lt;- sector_profile[grep(&quot;Miami&quot;, sector_profile): grep(&quot;Nationwide Total&quot;, sector_profile)] Note that were getting rid of the rows which had the column names. Its easier to make the names ourselves than to deal with that mess. The data now has only the rows we want but still doesnt have any columns, its currently just a vector of strings. We want to make it into a data.frame to be able to work on it like we usually do. head(sector_profile) [1] Miami 111 2,280 1,646 2,253 231 292 1 N/A N/A [2] New Orleans 63 920 528 21 6 10 0 N/A N/A [3] Ramey 38 388 387 3 2,932 89 0 N/A N/A [4] Coastal Border Sectors Total 212 3,588 2,561 2,277 3,169 391 1 N/A **** N/A **** [5]  [6] Blaine 296 288 237 0 0 9 0 N/A N/A When looking at this data it is clear that where the division between columns is supposed to be is a bunch of white space in each string. Take the first row for example, it says Miami then after lots of white spaces 111 than again with 2,280 and so on for the rest of the row. Well use this pattern of columns differentiated by white space to make sector_profile into a data.frame. We will use the function str_split_fixed() from the stringr package. This function is very similar to strsplit() except you can tell it how many columns to expect. install.packages(&quot;stringr&quot;) library(stringr) The syntax of str_split_fixed() is similar to strsplit() except the new parameter of the number of splits to expect. The _fixed part of str_split_fixed() is that it expects the same number of splits (which in our case become columns) for every element in the vector that we input. Looking at the PDF shows us that there are 10 columns so thats the number well use. Our split will be  {2,}. That is, a space that occurs two or more times. Since there are sectors with spaces in their name, we cant have only one space, we need at least two. If you look carefully at the rows with sectorsCoastal Border Sectors Total and Northern Border Sectors Total, the final two columns actually do not have two spaces between them because of the amount of asterisks they have. Normally wed want to fix this using gsub(), but those values will turn to NA anyway so we wont bother in this case. sector_profile &lt;- str_split_fixed(sector_profile, &quot; {2,}&quot;, 10) If we check the head() we can see that we have the proper columns now, but this still isnt a data.frame and has no column names. head(sector_profile) [,1] [,2] [,3] [,4] [1,] Miami 111 2,280 1,646 [2,] New Orleans 63 920 528 [3,] Ramey 38 388 387 [4,] Coastal Border Sectors Total 212 3,588 2,561 [5,]     [6,] Blaine 296 288 237 [,5] [,6] [,7] [,8] [,9] [,10] [1,] 2,253 231 292 1 N/A N/A [2,] 21 6 10 0 N/A N/A [3,] 3 2,932 89 0 N/A N/A [4,] 2,277 3,169 391 1 N/A **** N/A **** [5,]       [6,] 0 0 9 0 N/A N/A We can make it a data.frame just by putting it in data.frame(). And we can assign the columns names using a vector of strings we can make. Well use the same column names as in the PDF but in lowercase and replacing spaces and parentheses with underscores. sector_profile &lt;- data.frame(sector_profile) names(sector_profile) &lt;- c( &quot;sector&quot;, &quot;agent_staffing&quot;, &quot;apprehensions&quot;, &quot;other_than_mexican_apprehensions&quot;, &quot;marijuana_pounds&quot;, &quot;cocaine_pounds&quot;, &quot;accepted_prosecutions&quot;, &quot;assaults&quot;, &quot;rescues&quot;, &quot;deaths&quot; ) We have now taken a table from a PDF and successfully scraped it to a data.frame in R. Now we can work on it as we would any other data set that weve used previously. head(sector_profile) #&gt; sector agent_staffing apprehensions #&gt; 1 Miami 111 2,280 #&gt; 2 New Orleans 63 920 #&gt; 3 Ramey 38 388 #&gt; 4 Coastal Border Sectors Total 212 3,588 #&gt; 5 #&gt; 6 Blaine 296 288 #&gt; other_than_mexican_apprehensions marijuana_pounds #&gt; 1 1,646 2,253 #&gt; 2 528 21 #&gt; 3 387 3 #&gt; 4 2,561 2,277 #&gt; 5 #&gt; 6 237 0 #&gt; cocaine_pounds accepted_prosecutions assaults rescues #&gt; 1 231 292 1 N/A #&gt; 2 6 10 0 N/A #&gt; 3 2,932 89 0 N/A #&gt; 4 3,169 391 1 N/A **** #&gt; 5 #&gt; 6 0 9 0 N/A #&gt; deaths #&gt; 1 N/A #&gt; 2 N/A #&gt; 3 N/A #&gt; 4 N/A **** #&gt; 5 #&gt; 6 N/A To really be able to use this data well want to clean the columns to turn the values to numeric type but we can leave that until later. For now lets write a function that replicates much of this work for the next tables. 2.2 Making a function As weve done before, we want to take the code we wrote for the specific case of the first table in this PDF and turn it into a function for the general case of other tables in the PDF. Lets copy the code we used above before we convert it to a function. sector_profile &lt;- border_patrol[1] sector_profile &lt;- trimws(sector_profile) sector_profile &lt;- strsplit(sector_profile, &quot;\\r\\n&quot;) sector_profile &lt;- sector_profile[[1]] sector_profile &lt;- sector_profile[grep( &quot;Miami&quot;, sector_profile ): grep( &quot;Nationwide Total&quot;, sector_profile )] sector_profile &lt;- str_split_fixed(sector_profile, &quot; {2,}&quot;, 10) sector_profile &lt;- data.frame(sector_profile) names(sector_profile) &lt;- c( &quot;sector&quot;, &quot;agent_staffing&quot;, &quot;total_apprehensions&quot;, &quot;other_than_mexican_apprehensions&quot;, &quot;marijuana_pounds&quot;, &quot;cocaine_pounds&quot;, &quot;accepted_prosecutions&quot;, &quot;assaults&quot;, &quot;rescues&quot;, &quot;deaths&quot; ) Since each table is so similar our function will only need a few changes in the above code to work for all three tables. The object border_patrol has all four of the tables in the data, so we need to say which of these tables we want - we can call the parameter table_number. Then each table has a different number of columns so we need to change the str_split_fixed() function to take a variable with the number of columns we input, a value well call number_columns. We rename each column to its proper name so we need to input a vector - which well call column_names - with the names for each column. Finally, we want to have a parameter where we enter in the data which holds all of the tables, our object border_patrol, we can call this list_of_tables as it is fairly descriptive. We do this as it is bad form (and potentially dangerous) to have a function that relies on an object that isnt explicitly put in the function. It we change our border_patrol object (such as by scraping a different file but calling that object border_patrol) and the function doesnt have that as an input, it will work differently than we expect. Since we called the object we scraped sector_profile for the first table, lets change that to data as not all tables are called Sector Profile. scrape_pdf &lt;- function(list_of_tables, table_number, number_columns, column_names) { data &lt;- list_of_tables[table_number] data &lt;- trimws(data) data &lt;- strsplit(data, &quot;\\n&quot;) data &lt;- data[[1]] data &lt;- data[grep(&quot;Miami&quot;, data):grep(&quot;Nationwide Total&quot;, data)] data &lt;- str_split_fixed(data, &quot; {2,}&quot;, number_columns) data &lt;- data.frame(data) names(data) &lt;- column_names return(data) } Now lets run this function for each of the three tables we want to scrape, changing the functions parameters to work for each table. To see what parameter values you need to input, look at the PDF itself or the screenshots in this lesson. table_1 &lt;- scrape_pdf( list_of_tables = border_patrol, table_number = 1, number_columns = 10, column_names = c( &quot;sector&quot;, &quot;agent_staffing&quot;, &quot;total_apprehensions&quot;, &quot;other_than_mexican_apprehensions&quot;, &quot;marijuana_pounds&quot;, &quot;cocaine_pounds&quot;, &quot;accepted_prosecutions&quot;, &quot;assaults&quot;, &quot;rescues&quot;, &quot;deaths&quot; ) ) table_2 &lt;- scrape_pdf( list_of_tables = border_patrol, table_number = 2, number_columns = 6, column_names = c( &quot;sector&quot;, &quot;accompanied_juveniles&quot;, &quot;unaccompanied_juveniles&quot;, &quot;total_juveniles&quot;, &quot;total_adults&quot;, &quot;total_apprehensions&quot; ) ) table_3 &lt;- scrape_pdf( list_of_tables = border_patrol, table_number = 3, number_columns = 4, column_names = c( &quot;sector&quot;, &quot;female&quot;, &quot;male&quot;, &quot;total_apprehensions&quot; ) ) We can use the function left_join() from the dplyr package to combine the three tables into a single object. In the first table there are some asterisks after the final two row names in the Sector column. For our match to work properly we need to delete them which we can do using gsub(). table_1$sector &lt;- gsub(&quot;\\\\*&quot;, &quot;&quot;, table_1$sector) Now we can run left_join(). left_join() will automatically join based on shared column names in the two data sets we are joining. In our case this is sector and total_apprehensions. All we need to input into left_join() is the name of the data sets we want to join together. left_join() can only combine two data sets at a time so well first join table_1 and table_2 and then join table_3 with the result of the first join, which well call final_data. library(dplyr) #&gt; #&gt; Attaching package: &#39;dplyr&#39; #&gt; The following objects are masked from &#39;package:stats&#39;: #&gt; #&gt; filter, lag #&gt; The following objects are masked from &#39;package:base&#39;: #&gt; #&gt; intersect, setdiff, setequal, union final_data &lt;- left_join(table_1, table_2) #&gt; Joining, by = c(&quot;sector&quot;, &quot;total_apprehensions&quot;) final_data &lt;- left_join(final_data, table_3) #&gt; Joining, by = c(&quot;sector&quot;, &quot;total_apprehensions&quot;) Lets take a look at the head() of this combined data. head(final_data) #&gt; sector agent_staffing #&gt; 1 Miami 111 #&gt; 2 New Orleans 63 #&gt; 3 Ramey 38 #&gt; 4 Coastal Border Sectors Total 212 #&gt; 5 #&gt; 6 Blaine 296 #&gt; total_apprehensions other_than_mexican_apprehensions #&gt; 1 2,280 1,646 #&gt; 2 920 528 #&gt; 3 388 387 #&gt; 4 3,588 2,561 #&gt; 5 #&gt; 6 288 237 #&gt; marijuana_pounds cocaine_pounds accepted_prosecutions #&gt; 1 2,253 231 292 #&gt; 2 21 6 10 #&gt; 3 3 2,932 89 #&gt; 4 2,277 3,169 391 #&gt; 5 #&gt; 6 0 0 9 #&gt; assaults rescues deaths accompanied_juveniles #&gt; 1 1 N/A N/A 19 #&gt; 2 0 N/A N/A 1 #&gt; 3 0 N/A N/A 7 #&gt; 4 1 N/A **** N/A **** 27 #&gt; 5 &lt;NA&gt; #&gt; 6 0 N/A N/A 29 #&gt; unaccompanied_juveniles total_juveniles total_adults #&gt; 1 42 61 2,219 #&gt; 2 22 23 897 #&gt; 3 1 8 380 #&gt; 4 65 92 3,496 #&gt; 5 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; #&gt; 6 7 36 252 #&gt; female male #&gt; 1 219 2,061 #&gt; 2 92 828 #&gt; 3 65 323 #&gt; 4 376 3,212 #&gt; 5 &lt;NA&gt; &lt;NA&gt; #&gt; 6 97 191 In one data set we now have information from three separate tables in a PDF. We have now scraped three different tables from a PDF and turned them into a single data set, turning the PDF into actually usable (and useful) data! "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
