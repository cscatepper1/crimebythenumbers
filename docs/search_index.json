[
["index.html", "R 4 Criminology Welcome What you will learn What you won’t learn Simple vs Easy How to Contribute", " R 4 Criminology Jacob Kaplan Welcome These notes introduce the programming language R and are meant for undergrads or graduate students studying criminology. R is a programming language that is well-suited to the type of work frequently done in criminology - taking messy data and turning it into useful information such as cleaning the data, graphing it, or running statistical tests on the data. While R is a useful tool for many fields of study, this book focuses on the skills criminologists should know and uses crime data for the example data sets. This book is based off of the lessons I took as a Master’s student in criminology at Penn from Dr. Greg Ridgeway. This book covers much of the same material as well as a focus basic philosophy of teaching by example and a focus on the fundamentals of R (and programming in general) as Dr. Ridgeway’s lessons. For his lessons, please see here . For this book you should have the latest version of R installed and be running it through RStudio Desktop (The free version) . We’ll get into what R and RStudio are soon but please have them installed to be able to follow along with each chapter. I highly recommend following along with the code for each lesson and trying to use the lessons learned on a data set you are interested in. To download the data used in this book please see here. What you will learn For many of the lessons we will be working through real research questions and working from start to finish as you would on your own project. This involves thinking about what you want to accomplish from the data you have and what steps you need to take to reach that goal. This involves more than just knowing what code to write - it includes figuring out what your data has, whether it can answer the question you’re asking, and planning out (without writing any code yet) what you need to do when you start coding. Skills There is a large range of skills in criminological research - far too large to cover in a single book. Here we will attempt to teach fundamental skills to build a solid foundation for future work. We’ll be focusing on the following skills and trying to reinforce our skills with each lesson. Subsetting - Taking only certain rows or columns from a data set Graphing Regular expressions - Essentially R’s “Find and Replace” function for text Getting data from websites (webscraping) Getting data from PDFs Mapping Writing documents through R Data Criminology has a large - and growing - number of data sets publicly available for us to use. In this book we will focus on a few prominent ones including the following: Uniform Crime Report (UCR) - A FBI data set with agency-level crime data for nearly every agency in the United States National Incident-Based Reporting System (NIBRS) - Similar to the UCR, NIBRS is published by the FBI and has agency-level crime data. This data is far more detailed than the UCR which we’ll see greatly increases difficulty of use and the rewards from the data Census - The Census surveys people in the United States on a wide variety of variables including demographic, economic, and geographic information. We’ll also cover a number of other data sets such a local police data and government data on alcohol consumption in the United States. What you won’t learn This book is not a statistics book so we will not be covering any statistical techniques. Though some data sets we handle are fairly large, this book does not discuss how to deal with Big Data. While the lessons you learn in this book can apply to larger data sets, Big Data (which I tend to define loosely as too large for my computer to handle) requires special skills that are outside the realm of this book. If you do intend to deal with huge data sets I recommend you look at the R package data.table which is an excellent resource for it. While we briefly cover mapping, this book will not cover working with geographic data in detail. For a comprehensive look at geographic data please see this book. Simple vs Easy In the course of this book we will cover things that are very simple. For example, we’ll take a data set (think of an Excel file) with crime for nearly every agency in the United States and keep only data from Colorado for a small number of years. We’ll then find out how many murders happened in Colorado each year. This is a fairly simple task - it can be expressed in two sentences. You’ll find that most of what you do is simple like this - it is quick to talk about what you are doing and the concepts are not complicated. What it isn’t is easy. To actually write the R code to do this takes knowing a number of interrelated concepts in R and several lines of code to implement each step. While this distinction may seem minor, I think it is important for newer programmers to understand that what they are doing may be simple to talk about but hard to implement. It is easy to feel like a bad programmer because something that can be articulated in 10 seconds may take hours to do. So during times when you are working with R try to keep in mind that even though a project may be simple to articulate, it may be hard to code and that there is often very little correlation between the two. How to Contribute If you have any questions, suggestions, or find any issues please email me at jacob@crimedatatool.com. If this book has helped you, also email me so I can try to measure the book’s impact and who is using it. "],
["about-the-author.html", "About the Author", " About the Author Jacob Kaplan (http://crimedatatool.com/) is a Ph.D. candidate in criminology at the University of Pennsylvania. His research focuses on Crime Prevention Through Environmental Design (CPTED), specifically on the effect of outdoor lighting on crime. He is the author of several R packages, such as asciiSetupReader, fastDummies, and boxoffice. His website Crime Data Tool allows easy analysis of crime-related data and he has released over a dozen crime data sets (primarily FBI UCR data) on openICPSR. He is currently on the job market. For a list of papers he has written (including working papers), please see here. For a list of data sets he has cleaned, aggregated, and make public, please see here. "],
["introduction-to-r-and-rstudio.html", "1 Introduction to R and RStudio 1.1 Why learn to program? 1.2 Using RStudio 1.3 Reading data into R 1.4 First steps to exploring data 1.5 Finding help about functions", " 1 Introduction to R and RStudio 1.1 Why learn to program? With the exception of some more advanced techniques like scraping data from websites or from PDFs, nearly everything we do here can be done through Excel, a software you’re probably more familiar with. The basic steps for research projects are generally Open up a data set - which frequently comes as an Excel file! Change some values - misspellings or too specific categories are very common in crime data Delete some values - such as states you won’t be studying Make some graphs Calculate some values - such as number of crimes per year Sometimes do a statistical analysis depending on type of project Write up what you find R can do all of this but why should you want (or have) to learn a entirely new skill just to do something you can already do? R is useful for two main reasons: scale and reproducibility. 1.1.1 Scale If you do a one-off project in your career such as downloading some data and making a graph out of it, it makes sense to stick with software like Excel. The cost (in time and effort) of learning R is certainly not worth it for a single (or even several) project - even one perfectly suited for using R. R (and many programming languages more generally, such as Python) has its strength in doing something fairly simple many many times. For example, itm may be quicker to downloading one file yourself than it is to write the code in R to download that file. But when it comes to downloading hundreds of files (as we’ll do in Chapter (scraping-data-from-pdfs) when learning about officer-involved shootings in Philadelphia), writing the R code becomes very quickly the better option than doing it by hand. For most tasks you do in criminology when dealing with data you will end up doing many times (including doing the same task in future projects). So R offers the trade-off of spending time upfront by learning the code with the benefit of that code being able to do work at a large scale with little extra work from you. Please keep in mind this trade-off - you need to front-load the costs of learning R for the rewards of making your life easier when dealing with data - when feeling discouraged about the small returns you get early in learning R. 1.1.2 Reproducibility The second major benefit of using R over something like Excel is that R is reproducible. Every action you take is written down in the code. This is useful when collaborating with others (including your future self) as they can look at your code and follow along what you did without you having to show them every click you made as you frequently would on Excel. Your collaborator can look at your code to help you figure out a bug in the code or to add their own code to yours. In the academic context specifically you want to have code to give to people to ensure that your research was done correctly and there aren’t any important bugs in the code. Additionally, if you build a tool to, for example, interpret raw crime data from an agency and turn it into a map, being able to share the code so others can modify it for their city is an important contribution. 1.2 Using RStudio In this lesson we’ll start by looking at RStudio then write some brief code to load in some crime data and start exploring it. This lesson will cover code that you won’t understand completely yet. That is fine, we’ll cover everything in more detail as the lessons progress. RStudio is the interface we use to work with R. It has a number of features to make it easier for us to work with R - while not strictly necessary to use, most people who use R do so through RStudio. When you open up RStudio you’ll see four panels, each which play an important role in RStudio. Your RStudio may not look like the setup I have in the image below - that is fine, we’ll learn how to change the appearance of RStudio soon. At the top right is the Console panel. Here you can write code, hit enter/return, and R will run that code. If you write 2+2 it will return (in this case that just mean it will print an answer) 4. This is useful for doing something simple like using R as a calculator or quickly looking at data. In most cases during research this is where you’d do something that you don’t care to keep. This is because when you restart R it won’t save anything written in the Console. To do reproducible research or to be able to collaborate with others you need a way to keep the code you’ve written. The way to keep the code you’ve written in a file that you can open later or share with someone else is by writing code in an R Script (if you’re familiar with Stata, an R Script is just like a .do file). An R Script is essentially a text file (similar to a Word document) where you write code. To run code in an R Script just click on a line of code or highlight several lines and hit enter/return or click the “Run” button on the top left of the Source panel. You’ll see the lines of code run in the Console and any output (if your code has an output) will be shown there too (making a plot will be shown in a different panel as we’ll see soon). For code that you don’t want to run, called comments, start the line with a pound sign # and that line will not be run (it will still print in the console if you run it but it won’t do anything). The Source panel is where the R Scripts will be and is located at the top left on the image below. It is good practice to do all of your code writing in an R Script - even if you delete some lines of code later - as it eliminates the possibility of losing code or forgetting what you wrote. Having all the code in front of you in a text file also makes it easier to understand the flow of code from start to finish to a task - an issue we’ll discuss more in later lessons. While the Source and Console panels are the ones that are of most use, there are two other panels worth discussing. As these two panels let you interchange which tabs are available in them, we’ll return to them shortly in the discussion of the options RStudio has to customize it. 1.2.1 Opening an R Script When you want to open up a new R Script you can click File on the very top left, then R Script. It will open up the script in a new tab inside of the Source panel. There are also a number of other file options available R Presentation which can make Powerpoints, R Markdown which can make Word Documents or PDFs that incorporate R code used to make tables or graphs (and which we’ll cover in Chapter (using-r-markdown)), and Shiny Web App to make websites using R. There is too much to cover for an introductory book such as this but keep in mind the wide capabilities of R if you have another task to do. 1.2.2 Setting the working directory Many research projects incorporate data that someone else (such as the FBI or a local police agency) has put together. In these cases we need to load the data into R to be able to use it. In a little bit we’ll load a data set into R and start working on it but let’s take a step back now and think about how to even load data. First we’ll need to get the data onto our computer somehow, probably by downloading it from an agency’s website. Let’s be specific - we don’t download it to our computer, we download it to a specific folder on our computer (usually defaulted to the Downloads folder on a Windows machine). So let’s say you wanted to load a file called “data” into R. If you have a file called “data” in both your Desktop and your Downloads folder, R wouldn’t know which one you wanted. And unless your data was in the folder R searches by default (which may not be where the file is downloaded by default), R won’t know which file to load. We need to tell R explicitly which folder has the data to load. We do this by setting the “Working Directory” or the “Folders where I want you, R, to look for my data” in more simple terms. To set a working directory in R click the Session tab on the top menu, scroll to Set Working Directory, then click Choose Directory. This will open a window where you can navigate to the folder you want. After clicking Open in that window you’ll see a new line of code in the Console starting with setwd() and inside of the parentheses is the route your computer takes to get to the folder you selected. And now R knows which folder to look in for the data you want. It is good form to start your R Script with setwd() to make sure you can load the data. So copy that line of code that says setwd() (which stands for “set working directory”), including everything in the parentheses, to your R Script when you start working. 1.2.3 Changing RStudio Your RStudio looks different than my RStudio because I changed a number of settings to suit my preferences. To do so yourself click the Tools tab on the top menu and then click Global Options. This opens up a window with a number of different tabs to change how R behaves and how it looks. 1.2.3.1 General Under Workspace in the General tab make sure to uncheck the “Restore .RData into workspace at startup” and to set “Save workspace to .RData on exit:” to Never. What this does is make sure that every time you open R it starts fresh with no objects (essentially data loaded into R or made in R) from previous sessions. This may be annoying at times, especially when it comes to loading large files, but the benefits far outweigh the costs. You want your code to run from start to finish without any errors. Something I’ve seen many students do is write some code in the Console (or in their R Script but out of order of how it should be run) to fix an issue with the data. This means their data is how it should be but when the R session restarts (such as if the computer restarts) they won’t be able to get back to that point. Making sure your code handles everything from start to finish is well-worth the avoided headache of trying to remember what code you did to fix the issue previously. 1.2.3.2 Code The Code tab lets you specify how you want the code to be displayed. The important section for us is to make sure to check the “Soft-wrap R source files” check-box. If you write a very long line of code it gets too big to view all at once and you must scroll to the right to read it all. That can be annoying as you won’t be able to see all the code at once. Setting “Soft-wrap” makes it so if a line is too long it will just be shown on multiple lines which solves that issue. In practice it is best to avoid long lines of codes as it makes it hard to read but that isn’t always possible. 1.2.3.3 Appearance The Appearance tab lets you change the background, color, and size of text. Change it to your preferences. 1.2.3.4 Pane Layout The final tab we’ll look at is Pane Layout. This lets you move around the Source, Console, and the other two panels. There are a number of different tabs to select for the panels (unchecking one just moves it to the other panel, it doesn’t remove it from RStudio) and we’ll talk about three of them. The Environment tab shows every object you load into R or make in R. So if you load a file called “data” you can check the Environment tab If it is there, you have loaded the file correctly. As we’ll discuss more in Section (finding-help-about-functions), the Help tab will open up to show you a help page for a function you want more information on. The Plots tab will display any plot you make. It also keeps all plots you’ve made (until restarting R) so you can scroll through the plots. 1.2.4 Helpful cheatsheets RStudio also includes a number of links to helpful cheatsheets for a few important topics. To get to it click Help, then Cheatsheets and click on whichever one you need. 1.3 Reading data into R For many research projects you’ll have data produced by some outside group (FBI, local police agencies) and you want to take that data and put it inside R to work on it. We call that reading data into R. R is capable of reading a number of different formats of data which we will discuss in more detail in Chapter (reading-and-writing-data). Here, we will talk about the standard R data file only. 1.3.1 Loading data As we learned above in Section (Setting the working directory) we need to set out working directory to the folder where the data is. For my own setup, R is already defaulted to the folder with this data so I do not need to set a working directory. For those following along on your own computer, make sure to set your working directory now. The load() function lets us load data already in the R format. These files will end in the extension “.rda” or sometimes “.Rda” or “.RData”. Since we are telling R to load a specific file we need to have that file name in quotes and include the file extension “.rda”. With R data, the object inside the data already has a name so we don’t need to assign (something we will discuss in detail in Section (#assignment)) a name to the data. With other forms of data such as .csv files we will need to do that as we’ll see in Chapter (reading-and-writing-data). load(&quot;data/ucr2017.rda&quot;) 1.4 First steps to exploring data The object we loaded is called ucr2017. We’ll explore this data more thoroughly in the Chapter (#explore) but for now let’s use four simple (and important) functions to get a sense of what the data holds. For each of these functions write the name of the data set (without quotes since we don’t need quotes for an object already made in R) inside the (). head() summary() plot() View() Note that the first three functions are lowercase while View() is capitalized. That is simply because older functions in R were often capitalized while newer ones use all lowercase letters. R is case sensitive so using view() will not work. The head() function prints the first 6 rows of each column of the data to the console. This is useful to get a quick glance at the data but has some important drawbacks. When using data with a large number of columns it can be quickly overwhelming by printing too much. There may also be differences in the first 6 rows with other rows. For example if the rows are ordered chronologically (as is the case with most crime data) the first 6 rows will be the most recent. If data collection methods or the quality of collection changed over time, these 6 rows won’t be representative of the data. head(ucr2017) #&gt; ori year agency_name state population actual_murder #&gt; 1 AK00101 2017 anchorage alaska 296188 27 #&gt; 2 AK00102 2017 fairbanks alaska 32937 10 #&gt; 3 AK00103 2017 juneau alaska 32344 1 #&gt; 4 AK00104 2017 ketchikan alaska 8230 1 #&gt; 5 AK00105 2017 kodiak alaska 6198 0 #&gt; 6 AK00106 2017 nome alaska 3829 0 #&gt; actual_rape_total actual_robbery_total actual_assault_aggravated #&gt; 1 391 778 2368 #&gt; 2 24 40 131 #&gt; 3 50 46 206 #&gt; 4 19 0 14 #&gt; 5 15 4 41 #&gt; 6 7 0 52 The summary() function gives a six number summary of each numeric or Date column in the data. For other types of data, such as “character” types (which are just columns with words rather than numbers), it’ll say what type of data it is. The six values it returns for numeric and Date columns are The minimum value The value at the 1st quartile The median value The mean value The value at the 3rd quartile The max value In cases where there are NAs, it will say how many NAs there are. An NA value is a missing value. Think of it like an empty cell in an Excel file. NA values will cause issues when doing math such as finding the mean of a column as R doesn’t know how to handle a NA value in these situations. We’ll learn how to deal with this later. summary(ucr2017) #&gt; ori year agency_name state #&gt; Length:15764 Min. :2017 Length:15764 Length:15764 #&gt; Class :character 1st Qu.:2017 Class :character Class :character #&gt; Mode :character Median :2017 Mode :character Mode :character #&gt; Mean :2017 #&gt; 3rd Qu.:2017 #&gt; Max. :2017 #&gt; population actual_murder actual_rape_total #&gt; Min. : 0 Min. : 0.000 Min. : -2.000 #&gt; 1st Qu.: 914 1st Qu.: 0.000 1st Qu.: 0.000 #&gt; Median : 4460 Median : 0.000 Median : 1.000 #&gt; Mean : 19872 Mean : 1.069 Mean : 8.262 #&gt; 3rd Qu.: 15390 3rd Qu.: 0.000 3rd Qu.: 5.000 #&gt; Max. :8616333 Max. :653.000 Max. :2455.000 #&gt; actual_robbery_total actual_assault_aggravated #&gt; Min. : -1.00 Min. : -1.00 #&gt; 1st Qu.: 0.00 1st Qu.: 1.00 #&gt; Median : 0.00 Median : 5.00 #&gt; Mean : 19.85 Mean : 49.98 #&gt; 3rd Qu.: 4.00 3rd Qu.: 21.00 #&gt; Max. :13995.00 Max. :29771.00 The plot() function allows us to graph our data. For criminology research we generally want to make scatterplots to show the relationship between two numeric variables, time-series graphs to see how a variable (or variables) change over time, or barplots comparing categorical variables. Here we’ll make a scatterplot seeing the relationship between a city’s number of murders and their number of aggravated assaults (assault with a weapon or that causes serious bodily injury). To do so we must specify which column is displayed on the x-axis and which one is displayed on the y-axis. In Section (select-a-specific-column) we’ll talk explicitly about how to select specific columns from our data. For now all you need to know is to select a column you write the data name followed by dollar sign $ followed by the column name. Do not include any quotations or spaces (technically spaces can be included but make it a bit harder to read and are against conventional style when writing R code so we’ll exclude them). Inside of plot() we say that “x = ucr2017$actual_murder” so that column goes on the x-axis and “y = ucr2017$actual_assault_aggravated” so aggravated assault goes on the y-axis. And that’s all it takes to make a simple graph. plot(x = ucr2017$actual_murder, y = ucr2017$actual_assault_aggravated) Finally, View() opens essentially an Excel file of the data set you put inside the (). This allows you to look at the data as if it were in Excel and is a good way to start to understand the data. View(ucr2017) 1.5 Finding help about functions If you are having trouble understanding what a function does, you can ask R for help and it will open up a page explaining what the function does, what options it has, and examples of how to use it. To do so we write help(function) or ?function in the console and it will open up that function’s help page. If we wrote help(c) to figure out what the c() function does, it will open up this page. For finding the help page of a function the parentheses (e.g. c()) are optional. "],
["subsetting-intro.html", "2 Subsetting: Making big things small 2.1 Select specific values 2.2 Assignment values to objects (Making “things”) 2.3 Vectors (collections of “things”) 2.4 Logical values and operations 2.5 Subsetting a data.frame", " 2 Subsetting: Making big things small Subsetting data is a way to take a large data set and reduce it to a smaller one that is better suited for answering a specific question. This is useful when you have a lot of data in the data set that isn’t relevant to your research. Reducing it to a smaller data set makes it easier to manage, both in understanding your data and avoiding have a huge file that could slow down R. 2.1 Select specific values animals &lt;- c(&quot;cat&quot;, &quot;dog&quot;, &quot;gorilla&quot;, &quot;buffalo&quot;, &quot;lion&quot;, &quot;snake&quot;) animals #&gt; [1] &quot;cat&quot; &quot;dog&quot; &quot;gorilla&quot; &quot;buffalo&quot; &quot;lion&quot; &quot;snake&quot; Here we have made an object called “animals” with a number of different animals in it (we’ll explain what it really means to “make an object” soon). In R, we will use square brackets [] to select specific values in that object, something called “indexing”. Put a number (or numbers) in the square bracket and it will return the value at that “index”. The index is just the place number where each value is. “cat” is the first value in “animals” so it is at the first index, “dog” is the second value so it is the second index or index 2. “snake” is our last value and is the 6th value in “animals” so it is index 6 (some languages use “zero indexing” which means the first index is index 0, the second is index 1. So in our example “cat” would be index 0. R does not do that and the first value is index 1, the second is index 2 and so on.). The syntax (how the code is written) goes object[index] First we have the object and then we put the square bracket []. We need both the object and the [] for subsetting to work. Let’s say we wanted to choose just the “snake” from our “animals” object. In normal language we say “I want the 6th value from”animals\". We say where we’re looking and which value we want. animals[6] #&gt; [1] &quot;snake&quot; Now let’s get the third value. animals[3] #&gt; [1] &quot;gorilla&quot; If we want multiple values we can enter multiple numbers. If you have multiple values, you need to make a vector using c() and put the numbers inside the parentheses separated by a comma. We’ll learn more about vectors and using c() in Section (#vectors) shortly. If we wanted values 1-3 we could use c(1, 2, 3), with each number separated by a comma. animals[c(1, 2, 3)] #&gt; [1] &quot;cat&quot; &quot;dog&quot; &quot;gorilla&quot; When making a vector of sequential integers, instead of writing them all out manually we can use first_number:last_number like so 1:3 #&gt; [1] 1 2 3 To use it in subsetting we can treat 1:3 as if we wrote c(1, 2, 3). animals[1:3] #&gt; [1] &quot;cat&quot; &quot;dog&quot; &quot;gorilla&quot; The order we enter the numbers determines the order of values it returns. Let’s get the third index, the fourth index, and the first index, in that order. animals[c(3, 4, 1)] #&gt; [1] &quot;gorilla&quot; &quot;buffalo&quot; &quot;cat&quot; Putting a negative number inside the [] will return all values except for that index, essentially deleting it. Let’s remove “cat” from “animals”. Since it is the 1st item in “animals” we can remove it like this animals[-1] #&gt; [1] &quot;dog&quot; &quot;gorilla&quot; &quot;buffalo&quot; &quot;lion&quot; &quot;snake&quot; Now let’s remove multiple values, the first 3. animals[-c(1, 2, 3)] #&gt; [1] &quot;buffalo&quot; &quot;lion&quot; &quot;snake&quot; 2.2 Assignment values to objects (Making “things”) Earlier we wrote animals &lt;- c(\"cat\", \"dog\", \"gorilla\", \"buffalo\", \"lion\", \"snake\") to make the object “animals” with the value of each of the different animals we wrote. We say&lt;- as “gets”. So above “animals gets the values cat, dog, etc.”. This is read from left to right as thing on left (the name of the object) “gets” the value of the thing on the right of the &lt;-. The proper terminology is that the “thing” on the left is an “object”. So if we had x &lt;- 5 the object “x” gets the value 5. We could also say “five was assigned to x”. The terminology is “object gets value” or “value assigned to object”, both work. You can use the = instead of &lt;-. Again, the thing on the left gets the value of the thing on the right even when using =. x = 2 x now has the value of the number 2. x #&gt; [1] 2 It is the convention in R to use &lt;- instead of = and in some cases the = will not work properly. For those reasons we will use &lt;- for this class. 2.3 Vectors (collections of “things”) When we made “x” we wrote x &lt;- 2 while when we made “animals” we wrote animals &lt;- c(\"cat\", \"dog\", \"gorilla\", \"buffalo\", \"lion\", \"snake\"). The important difference is that when assigning multiple values to an object we must use the function c() which combines them together. With multiple values we follow the same pattern of object &lt;- value but put the value inside of c() and separate each value by a comma. x &lt;- c(1, 2, 3) The result of the c() is called a vector and you can think of it as a collection of values. Note that vectors take values that are the same type, so all values included must be the same type such as a number or a string (a character type such as words or values with letters. In R they are put in quotes.). If they aren’t the same type R will automatically convert it. c(&quot;cat&quot;, &quot;dog&quot;, 2) #&gt; [1] &quot;cat&quot; &quot;dog&quot; &quot;2&quot; Above we made a vector with the values “cat”, “dog” and 2 (without quotes) and it added quotes to the 2. Since everything must be the same type R automatically converted the 2 to a string of “2”. 2.4 Logical values and operations We also frequently want to conditionally select certain values. Earlier we selected values indexing specific numbers, but that requires us to know exactly which values we want. We can conditionally select values by having some conditional statement (e.g. “this value is lower than the number 100”) and keeping only values where that condition is true. When we talk about logical values we mean TRUE and FALSE (in R you must spell it in capital letters). First we will discuss conditionals abstractly and then we will use a real example using data from the FBI to make a data set tailored to answer a specific question. We can use these TRUE and FALSE values to index and it will return every element which we say is TRUE. animals[c(TRUE, TRUE, FALSE, FALSE, FALSE, FALSE)] #&gt; [1] &quot;cat&quot; &quot;dog&quot; This is the basis of conditional subsetting. If we have a large data set and only want a small chunk based on some condition (data in a single state (or multiple states), at a certain time, at least a certain population) we need to make a conditional statement that returns TRUE if it matches what we want and FALSE if it doesn’t. There are a number of different ways to make conditional statements. First let’s go through some special characters involved and then show examples of each one. For each case you are asking does the thing on the left of the conditional statement return TRUE or FALSE compared to the thing on the right. == Equals (compared to a single value) %in% Equals (one value match out of multiple comparisons) != Does not equal &lt; Less than &gt; Greater than &lt;= Less than or equal to &gt;= Greater than or equal to Since many conditionals involve numbers (especially in criminology), let’s make a new object called “numbers” with the numbers 1-10. numbers &lt;- 1:10 2.4.1 Matching a single value The conditional == asks if the thing on the left equals the thing on the right. Note that it uses two equal signs. If we used only one equal sign it would assign the thing on the left the value of the thing on the right (as if we did &lt;-). 2 == 2 #&gt; [1] TRUE This gives TRUE as we know that 2 does equal 2. If we change either value, it would give us FALSE. 2 == 3 #&gt; [1] FALSE And it works when we have multiple numbers on the left side, such as our object called “numbers”. numbers == 2 #&gt; [1] FALSE TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE This also works with characters such as the animals in the object we made earlier. “gorilla” is the third animal in our object, so if we check animals == “gorilla” we expect the third value to be TRUE and all others to be FALSE. Make sure the match is spelled correctly (including capitalization) and is in quotes. animals == &quot;gorilla&quot; #&gt; [1] FALSE FALSE TRUE FALSE FALSE FALSE The == only works when there is one thing on the right hand side. In criminology we often want to know if there is a match for multiple things - is the crime one of the following crimes…, did the crime happen in one of these months…, is the victim a member of these demographic groups…? So we need a way to check if a value is one of many values. 2.4.2 Matching multiple values The R operator %in% asks each value on the left whether or not it is a member of the set on the right. It asks, is the single value on the left hand side (even when there are multiple values such as our “animals” object, it goes through them one at a time) a match with any of the values on the right hand side? It only has to match with one of the right hand side values to be a match. 2 %in% c(1, 2, 3) #&gt; [1] TRUE For our “animals” object, if we check if they are in the vector c(“cat”, “dog”, “gorilla”), now all three of those animals will return TRUE. animals %in% c(&quot;cat&quot;, &quot;dog&quot;, &quot;gorilla&quot;) #&gt; [1] TRUE TRUE TRUE FALSE FALSE FALSE 2.4.3 Does not match Sometimes it is easier to ask what is not a match. For example, if you wanted to get every month except January, instead of writing the other 11 months, you just ask for any month that does not equal “January”. We can use !=, which means “not equal”. When we wanted an exact match we used ==, if we want a not match we can use != (this time it is only a single equals sign). 2 != 3 #&gt; [1] TRUE &quot;cat&quot; != &quot;gorilla&quot; #&gt; [1] TRUE Note that for matching multiple values with %in%, we cannot write !%in% but have to put the ! before the values on the left. !animals %in% c(&quot;cat&quot;, &quot;dog&quot;, &quot;gorilla&quot;) #&gt; [1] FALSE FALSE FALSE TRUE TRUE TRUE 2.4.4 Greater than or less than We can use R to compare values using greater than or less than symbols. We can also express “greater than or equal to” or “less than or equal to.” These will evaluate to TRUE or FALSE depending, of course, on whether the statement is true or false. 6 &gt; 5 #&gt; [1] TRUE 6 &lt; 5 #&gt; [1] FALSE 6 &gt;= 5 #&gt; [1] TRUE 5 &lt;= 5 #&gt; [1] TRUE When used on our object “numbers” it will return 10 values (since “numbers” is 10 elements long) with a TRUE if the condition is true for the element and FALSE otherwise. Let’s run numbers &gt; 3. We expect the first 3 values to be FALSE as 1, 2, and 3 and not larger than 3. numbers &gt; 3 #&gt; [1] FALSE FALSE FALSE TRUE TRUE TRUE TRUE TRUE TRUE TRUE 2.4.5 Combining conditional statements - or, and In many cases when you are subsetting you will want to subset based on more than one condition. For example, let’s say you have crime data from every state between 1960 and 2017. Your research question is “did Colorado’s marijuana legalization affect crime in the state?” In that case you want only data from Colorado. Since legalization began in January 2014, you wouldn’t need every year, only years some period of time before and after legalization to be able to measure its effect. So you would need to subset based on the state and the year. To make conditional statements with multiple conditions we use | for “or” and &amp; for “and”. Condition 1 | Condition 2 2 == 3 | 2 &gt; 1 #&gt; [1] TRUE As it sounds, when using | as long as at least one condition is true (we can include as many conditions as we like) it will return TRUE. Condition 1 &amp; Condition 2 2 == 3 &amp; 2 &gt; 1 #&gt; [1] FALSE For &amp;, all of the conditions must be true. If even one condition is not true it will return FALSE. 2.5 Subsetting a data.frame Earlier we were using a simple vector (collection of values). In this class - and in your own work - you will usually work on an entire data set. These generally come in the form called a “data.frame” which you can imagine as being like an Excel file with multiple rows and columns. Let’s load in data from the Uniform Crime Report (UCR), an FBI data set that we’ll work on in a later lesson. This data has crime data every year from 1960-2017 and for every nearly every agency in the country (early years have far fewer agencies reporting than recent years). load(&quot;data/offenses_known_yearly_1960_2017.rda&quot;) Let’s peak at the first 6 rows and 6 columns using the square bracket notation [] for data.frames which we’ll explain more below. offenses_known_yearly_1960_2017[1:6, 1:6] #&gt; ori ori9 agency_name state state_abb year #&gt; 1 AK00101 AK0010100 anchorage alaska AK 2017 #&gt; 2 AK00101 AK0010100 anchorage alaska AK 2016 #&gt; 3 AK00101 AK0010100 anchorage alaska AK 2015 #&gt; 4 AK00101 AK0010100 anchorage alaska AK 2014 #&gt; 5 AK00101 AK0010100 anchorage alaska AK 2013 #&gt; 6 AK00101 AK0010100 anchorage alaska AK 2012 The first 6 rows appear to be agency identification info for Anchorage, Alaska from 2017-2012. For good measure let’s check how many rows and columns are in this data. This will give us some guidance on subsetting which we’ll see below. nrow() gives us the number of rows and ncol() gives us the number of columns. nrow(offenses_known_yearly_1960_2017) #&gt; [1] 959010 ncol(offenses_known_yearly_1960_2017) #&gt; [1] 159 This is a large file with 159 columns and nearly a million rows. Normally we wouldn’t want to print out the names of all 159 columns but let’s do this here as we want to know the variables available to subset. names(offenses_known_yearly_1960_2017) #&gt; [1] &quot;ori&quot; &quot;ori9&quot; #&gt; [3] &quot;agency_name&quot; &quot;state&quot; #&gt; [5] &quot;state_abb&quot; &quot;year&quot; #&gt; [7] &quot;number_of_months_reported&quot; &quot;fips_state_code&quot; #&gt; [9] &quot;fips_county_code&quot; &quot;fips_state_county_code&quot; #&gt; [11] &quot;fips_place_code&quot; &quot;fips_state_place_code&quot; #&gt; [13] &quot;agency_type&quot; &quot;agency_subtype_1&quot; #&gt; [15] &quot;agency_subtype_2&quot; &quot;crosswalk_agency_name&quot; #&gt; [17] &quot;census_name&quot; &quot;population&quot; #&gt; [19] &quot;population_group&quot; &quot;country_division&quot; #&gt; [21] &quot;juvenile_age&quot; &quot;core_city_indication&quot; #&gt; [23] &quot;last_update&quot; &quot;fbi_field_office&quot; #&gt; [25] &quot;followup_indication&quot; &quot;zip_code&quot; #&gt; [27] &quot;covered_by_ori&quot; &quot;agency_count&quot; #&gt; [29] &quot;date_of_last_update&quot; &quot;month_included_in&quot; #&gt; [31] &quot;special_mailing_group&quot; &quot;special_mailing_address&quot; #&gt; [33] &quot;first_line_of_mailing_address&quot; &quot;second_line_of_mailing_address&quot; #&gt; [35] &quot;third_line_of_mailing_address&quot; &quot;fourth_line_of_mailing_address&quot; #&gt; [37] &quot;officers_killed_by_felony&quot; &quot;officers_killed_by_accident&quot; #&gt; [39] &quot;officers_assaulted&quot; &quot;actual_murder&quot; #&gt; [41] &quot;actual_manslaughter&quot; &quot;actual_rape_total&quot; #&gt; [43] &quot;actual_rape_by_force&quot; &quot;actual_rape_attempted&quot; #&gt; [45] &quot;actual_robbery_total&quot; &quot;actual_robbery_with_a_gun&quot; #&gt; [47] &quot;actual_robbery_with_a_knife&quot; &quot;actual_robbery_other_weapon&quot; #&gt; [49] &quot;actual_robbery_unarmed&quot; &quot;actual_assault_total&quot; #&gt; [51] &quot;actual_assault_with_a_gun&quot; &quot;actual_assault_with_a_knife&quot; #&gt; [53] &quot;actual_assault_other_weapon&quot; &quot;actual_assault_unarmed&quot; #&gt; [55] &quot;actual_assault_simple&quot; &quot;actual_burg_total&quot; #&gt; [57] &quot;actual_burg_force_entry&quot; &quot;actual_burg_nonforce_entry&quot; #&gt; [59] &quot;actual_burg_attempted&quot; &quot;actual_theft_total&quot; #&gt; [61] &quot;actual_mtr_veh_theft_total&quot; &quot;actual_mtr_veh_theft_car&quot; #&gt; [63] &quot;actual_mtr_veh_theft_truck&quot; &quot;actual_mtr_veh_theft_other&quot; #&gt; [65] &quot;actual_all_crimes&quot; &quot;actual_assault_aggravated&quot; #&gt; [67] &quot;actual_index_violent&quot; &quot;actual_index_property&quot; #&gt; [69] &quot;actual_index_total&quot; &quot;tot_clr_murder&quot; #&gt; [71] &quot;tot_clr_manslaughter&quot; &quot;tot_clr_rape_total&quot; #&gt; [73] &quot;tot_clr_rape_by_force&quot; &quot;tot_clr_rape_attempted&quot; #&gt; [75] &quot;tot_clr_robbery_total&quot; &quot;tot_clr_robbery_with_a_gun&quot; #&gt; [77] &quot;tot_clr_robbery_with_a_knife&quot; &quot;tot_clr_robbery_other_weapon&quot; #&gt; [79] &quot;tot_clr_robbery_unarmed&quot; &quot;tot_clr_assault_total&quot; #&gt; [81] &quot;tot_clr_assault_with_a_gun&quot; &quot;tot_clr_assault_with_a_knife&quot; #&gt; [83] &quot;tot_clr_assault_other_weapon&quot; &quot;tot_clr_assault_unarmed&quot; #&gt; [85] &quot;tot_clr_assault_simple&quot; &quot;tot_clr_burg_total&quot; #&gt; [87] &quot;tot_clr_burg_force_entry&quot; &quot;tot_clr_burg_nonforce_entry&quot; #&gt; [89] &quot;tot_clr_burg_attempted&quot; &quot;tot_clr_theft_total&quot; #&gt; [91] &quot;tot_clr_mtr_veh_theft_total&quot; &quot;tot_clr_mtr_veh_theft_car&quot; #&gt; [93] &quot;tot_clr_mtr_veh_theft_truck&quot; &quot;tot_clr_mtr_veh_theft_other&quot; #&gt; [95] &quot;tot_clr_all_crimes&quot; &quot;tot_clr_assault_aggravated&quot; #&gt; [97] &quot;tot_clr_index_violent&quot; &quot;tot_clr_index_property&quot; #&gt; [99] &quot;tot_clr_index_total&quot; &quot;clr_18_murder&quot; #&gt; [101] &quot;clr_18_manslaughter&quot; &quot;clr_18_rape_total&quot; #&gt; [103] &quot;clr_18_rape_by_force&quot; &quot;clr_18_rape_attempted&quot; #&gt; [105] &quot;clr_18_robbery_total&quot; &quot;clr_18_robbery_with_a_gun&quot; #&gt; [107] &quot;clr_18_robbery_with_a_knife&quot; &quot;clr_18_robbery_other_weapon&quot; #&gt; [109] &quot;clr_18_robbery_unarmed&quot; &quot;clr_18_assault_total&quot; #&gt; [111] &quot;clr_18_assault_with_a_gun&quot; &quot;clr_18_assault_with_a_knife&quot; #&gt; [113] &quot;clr_18_assault_other_weapon&quot; &quot;clr_18_assault_unarmed&quot; #&gt; [115] &quot;clr_18_assault_simple&quot; &quot;clr_18_burg_total&quot; #&gt; [117] &quot;clr_18_burg_force_entry&quot; &quot;clr_18_burg_nonforce_entry&quot; #&gt; [119] &quot;clr_18_burg_attempted&quot; &quot;clr_18_theft_total&quot; #&gt; [121] &quot;clr_18_mtr_veh_theft_total&quot; &quot;clr_18_mtr_veh_theft_car&quot; #&gt; [123] &quot;clr_18_mtr_veh_theft_truck&quot; &quot;clr_18_mtr_veh_theft_other&quot; #&gt; [125] &quot;clr_18_all_crimes&quot; &quot;clr_18_assault_aggravated&quot; #&gt; [127] &quot;clr_18_index_violent&quot; &quot;clr_18_index_property&quot; #&gt; [129] &quot;clr_18_index_total&quot; &quot;unfound_murder&quot; #&gt; [131] &quot;unfound_manslaughter&quot; &quot;unfound_rape_total&quot; #&gt; [133] &quot;unfound_rape_by_force&quot; &quot;unfound_rape_attempted&quot; #&gt; [135] &quot;unfound_robbery_total&quot; &quot;unfound_robbery_with_a_gun&quot; #&gt; [137] &quot;unfound_robbery_with_a_knife&quot; &quot;unfound_robbery_other_weapon&quot; #&gt; [139] &quot;unfound_robbery_unarmed&quot; &quot;unfound_assault_total&quot; #&gt; [141] &quot;unfound_assault_with_a_gun&quot; &quot;unfound_assault_with_a_knife&quot; #&gt; [143] &quot;unfound_assault_other_weapon&quot; &quot;unfound_assault_unarmed&quot; #&gt; [145] &quot;unfound_assault_simple&quot; &quot;unfound_burg_total&quot; #&gt; [147] &quot;unfound_burg_force_entry&quot; &quot;unfound_burg_nonforce_entry&quot; #&gt; [149] &quot;unfound_burg_attempted&quot; &quot;unfound_theft_total&quot; #&gt; [151] &quot;unfound_mtr_veh_theft_total&quot; &quot;unfound_mtr_veh_theft_car&quot; #&gt; [153] &quot;unfound_mtr_veh_theft_truck&quot; &quot;unfound_mtr_veh_theft_other&quot; #&gt; [155] &quot;unfound_all_crimes&quot; &quot;unfound_assault_aggravated&quot; #&gt; [157] &quot;unfound_index_violent&quot; &quot;unfound_index_property&quot; #&gt; [159] &quot;unfound_index_total&quot; Now let’s discuss how to subset this data into a smaller data set to answer a specific question. Let’s subset the data to answer our above question of “did Colorado’s marijuana legalization affect crime in the state?” Like mentioned above, we need data just from Colorado and just for years around the legalization year - we can do 2011-2017 for simplicity. We also don’t need all 159 columns in the current data. Let’s say we’re only interested in if murder changes. We’d need the column called “actual_murder”, the “state” column (as a check), the “year” column, the “population” column, the “ori” column, and the “agency_name” column (a real analysis would likely grab geographic variables too to see if changes depended on location but here we’re just using it as an example). The last two columns - ori and agency_name - aren’t strictly necessary but would be useful if checking if an agency’s values are reasonable when checking for outliers, a step we won’t do here. Before explaining how to subset from a data.frame, let’s write pseudocode (essentially a description of what we are going to do that is readable to people but isn’t real code) for our subset. We want Only rows where the state equals Colorado Only rows where the year is 2011-2017 Only the following columns: actual_murder, state, year, population, ori, agency_name 2.5.1 Select specific columns The way to select a specific column in R is called the dollar sign notation. data$column We write the data name followed by a $ and then the column name. Make sure there are no spaces, quotes, or misspellings (or capitalization issues). Just the data$column exactly as it is spelled. Since we are referring to data already read into R, there should not be any quotes for either the data or the column name. We can do this for the column “agency_name” in our UCR data. If we wrote this in the console it would print out every single row in the column. Because this data is large (nearly a million rows), I am going to wrap this in head() so it only displays the first 6 rows of the column rather than printing the entire column. head(offenses_known_yearly_1960_2017$agency_name) #&gt; [1] &quot;anchorage&quot; &quot;anchorage&quot; &quot;anchorage&quot; &quot;anchorage&quot; &quot;anchorage&quot; &quot;anchorage&quot; They’re all the same name because Anchorage Police reported many times and are in the data set multiple times. Let’s look at the column “actual_murder” which shows the annual number of murders in that agency. head(offenses_known_yearly_1960_2017$actual_murder) #&gt; [1] 27 28 26 12 14 15 One hint is to write out the data set name in the console and hit the Tab key. Wait a couple of seconds and a popup will appear listing every column in the data set. You can scroll through this and then hit enter to select that column. 2.5.2 Select specific rows In the earlier examples we used square bracket notation [] and just put a number or several numbers in the []. When dealing with data.frames, however, you need an extra step to tell R which columns to keep. The syntax in the square bracket is [row, column] As we did earlier, we start in the square bracket by saying which row we want. Now, since we also have to consider the columns, we need to tell it the number or name (in a vector using c() if more than one name and putting column names in quotes.) of the column or columns we want. The exception to this is when we use the dollar sign notation to select a single column. In that case we don’t need a comma (and indeed it will give us an error!). Let’s see a few examples then explain why this works the way it does. offenses_known_yearly_1960_2017[1, 1] #&gt; [1] &quot;AK00101&quot; If we input multiple numbers we can get multiple rows and columns. offenses_known_yearly_1960_2017[1:6, 1:6] #&gt; ori ori9 agency_name state state_abb year #&gt; 1 AK00101 AK0010100 anchorage alaska AK 2017 #&gt; 2 AK00101 AK0010100 anchorage alaska AK 2016 #&gt; 3 AK00101 AK0010100 anchorage alaska AK 2015 #&gt; 4 AK00101 AK0010100 anchorage alaska AK 2014 #&gt; 5 AK00101 AK0010100 anchorage alaska AK 2013 #&gt; 6 AK00101 AK0010100 anchorage alaska AK 2012 The column section also accepts a vector of the names of the columns. These names must be spelled correctly and in quotes. offenses_known_yearly_1960_2017[1:6, c(&quot;ori&quot;, &quot;year&quot;)] #&gt; ori year #&gt; 1 AK00101 2017 #&gt; 2 AK00101 2016 #&gt; 3 AK00101 2015 #&gt; 4 AK00101 2014 #&gt; 5 AK00101 2013 #&gt; 6 AK00101 2012 In cases where we want every row or every column, we just don’t put a number. By default R will return every row/column if you don’t specify which ones you want. However you will still need to include the comma. Here is every column in the first row. offenses_known_yearly_1960_2017[1, ] #&gt; ori ori9 agency_name state state_abb year #&gt; 1 AK00101 AK0010100 anchorage alaska AK 2017 #&gt; number_of_months_reported fips_state_code fips_county_code #&gt; 1 12 02 020 #&gt; fips_state_county_code fips_place_code fips_state_place_code #&gt; 1 02020 03000 0203000 #&gt; agency_type agency_subtype_1 agency_subtype_2 #&gt; 1 local police department not applicable not applicable #&gt; crosswalk_agency_name census_name population #&gt; 1 anchorage police department anchorage municipality 296188 #&gt; population_group country_division juvenile_age #&gt; 1 city 250,000 thru 499,999 pacific 18 #&gt; core_city_indication last_update fbi_field_office followup_indication #&gt; 1 core city of msa 42094 3030 send a follow-up #&gt; zip_code covered_by_ori agency_count date_of_last_update #&gt; 1 99507 &lt;NA&gt; 1 120717 #&gt; month_included_in #&gt; 1 0 #&gt; special_mailing_group #&gt; 1 the agency is a contributor but not on the mailing list,they are not sent forms. #&gt; special_mailing_address first_line_of_mailing_address #&gt; 1 not a special mailing address chief of police #&gt; second_line_of_mailing_address third_line_of_mailing_address #&gt; 1 anchorage police department 4501 elmore rd #&gt; fourth_line_of_mailing_address officers_killed_by_felony #&gt; 1 anchorage, ak 0 #&gt; officers_killed_by_accident officers_assaulted actual_murder #&gt; 1 0 426 27 #&gt; actual_manslaughter actual_rape_total actual_rape_by_force #&gt; 1 3 391 350 #&gt; actual_rape_attempted actual_robbery_total actual_robbery_with_a_gun #&gt; 1 41 778 249 #&gt; actual_robbery_with_a_knife actual_robbery_other_weapon #&gt; 1 69 116 #&gt; actual_robbery_unarmed actual_assault_total actual_assault_with_a_gun #&gt; 1 344 6448 621 #&gt; actual_assault_with_a_knife actual_assault_other_weapon #&gt; 1 392 704 #&gt; actual_assault_unarmed actual_assault_simple actual_burg_total #&gt; 1 651 4080 2216 #&gt; actual_burg_force_entry actual_burg_nonforce_entry actual_burg_attempted #&gt; 1 1537 521 158 #&gt; actual_theft_total actual_mtr_veh_theft_total actual_mtr_veh_theft_car #&gt; 1 10721 3104 1934 #&gt; actual_mtr_veh_theft_truck actual_mtr_veh_theft_other actual_all_crimes #&gt; 1 971 199 23688 #&gt; actual_assault_aggravated actual_index_violent actual_index_property #&gt; 1 2368 3564 16041 #&gt; actual_index_total tot_clr_murder tot_clr_manslaughter #&gt; 1 19605 28 0 #&gt; tot_clr_rape_total tot_clr_rape_by_force tot_clr_rape_attempted #&gt; 1 58 48 10 #&gt; tot_clr_robbery_total tot_clr_robbery_with_a_gun #&gt; 1 216 47 #&gt; tot_clr_robbery_with_a_knife tot_clr_robbery_other_weapon #&gt; 1 22 37 #&gt; tot_clr_robbery_unarmed tot_clr_assault_total tot_clr_assault_with_a_gun #&gt; 1 110 3576 249 #&gt; tot_clr_assault_with_a_knife tot_clr_assault_other_weapon #&gt; 1 250 413 #&gt; tot_clr_assault_unarmed tot_clr_assault_simple tot_clr_burg_total #&gt; 1 436 2228 250 #&gt; tot_clr_burg_force_entry tot_clr_burg_nonforce_entry #&gt; 1 129 114 #&gt; tot_clr_burg_attempted tot_clr_theft_total tot_clr_mtr_veh_theft_total #&gt; 1 7 1358 497 #&gt; tot_clr_mtr_veh_theft_car tot_clr_mtr_veh_theft_truck #&gt; 1 335 145 #&gt; tot_clr_mtr_veh_theft_other tot_clr_all_crimes #&gt; 1 17 5983 #&gt; tot_clr_assault_aggravated tot_clr_index_violent tot_clr_index_property #&gt; 1 1348 1650 2105 #&gt; tot_clr_index_total clr_18_murder clr_18_manslaughter clr_18_rape_total #&gt; 1 3755 1 0 5 #&gt; clr_18_rape_by_force clr_18_rape_attempted clr_18_robbery_total #&gt; 1 4 1 9 #&gt; clr_18_robbery_with_a_gun clr_18_robbery_with_a_knife #&gt; 1 1 1 #&gt; clr_18_robbery_other_weapon clr_18_robbery_unarmed clr_18_assault_total #&gt; 1 0 7 277 #&gt; clr_18_assault_with_a_gun clr_18_assault_with_a_knife #&gt; 1 37 17 #&gt; clr_18_assault_other_weapon clr_18_assault_unarmed clr_18_assault_simple #&gt; 1 19 17 187 #&gt; clr_18_burg_total clr_18_burg_force_entry clr_18_burg_nonforce_entry #&gt; 1 8 4 2 #&gt; clr_18_burg_attempted clr_18_theft_total clr_18_mtr_veh_theft_total #&gt; 1 2 107 22 #&gt; clr_18_mtr_veh_theft_car clr_18_mtr_veh_theft_truck #&gt; 1 17 2 #&gt; clr_18_mtr_veh_theft_other clr_18_all_crimes clr_18_assault_aggravated #&gt; 1 3 429 90 #&gt; clr_18_index_violent clr_18_index_property clr_18_index_total #&gt; 1 105 137 242 #&gt; unfound_murder unfound_manslaughter unfound_rape_total #&gt; 1 5 0 16 #&gt; unfound_rape_by_force unfound_rape_attempted unfound_robbery_total #&gt; 1 16 0 1 #&gt; unfound_robbery_with_a_gun unfound_robbery_with_a_knife #&gt; 1 1 0 #&gt; unfound_robbery_other_weapon unfound_robbery_unarmed #&gt; 1 0 0 #&gt; unfound_assault_total unfound_assault_with_a_gun #&gt; 1 6 0 #&gt; unfound_assault_with_a_knife unfound_assault_other_weapon #&gt; 1 1 1 #&gt; unfound_assault_unarmed unfound_assault_simple unfound_burg_total #&gt; 1 0 4 0 #&gt; unfound_burg_force_entry unfound_burg_nonforce_entry #&gt; 1 0 0 #&gt; unfound_burg_attempted unfound_theft_total unfound_mtr_veh_theft_total #&gt; 1 0 40 70 #&gt; unfound_mtr_veh_theft_car unfound_mtr_veh_theft_truck #&gt; 1 53 16 #&gt; unfound_mtr_veh_theft_other unfound_all_crimes #&gt; 1 1 138 #&gt; unfound_assault_aggravated unfound_index_violent unfound_index_property #&gt; 1 2 24 110 #&gt; unfound_index_total #&gt; 1 134 Since there are 159 columns in our data, normally we’d want to avoid printing out all of them. And in most cases we would save the output of subsets to a new object to be used later rather than just printing the output in the console. What happens if we forget the comma? If we put in numbers for both rows and columns but don’t include a comma between them it will have an error. offenses_known_yearly_1960_2017[1 1] #&gt; Error: &lt;text&gt;:1:35: unexpected numeric constant #&gt; 1: offenses_known_yearly_1960_2017[1 1 #&gt; ^ If we only put in a single number and no comma, it will return the column that matches that number. Here we have number 1 and it will return the first column. We’ll wrap it in head() to it doesn’t print out a million rows. head(offenses_known_yearly_1960_2017[1]) #&gt; ori #&gt; 1 AK00101 #&gt; 2 AK00101 #&gt; 3 AK00101 #&gt; 4 AK00101 #&gt; 5 AK00101 #&gt; 6 AK00101 Since R thinks you are requesting a columns, and we only have 159 columns in the data, asking for any number above 159 will return an error. head(offenses_known_yearly_1960_2017[1000]) #&gt; Error in `[.data.frame`(offenses_known_yearly_1960_2017, 1000): undefined columns selected So make sure when you want a row from a data.frame you always include the comma! 2.5.3 Battleships When we use square bracket [] notation on a data.frame we must include both row and column numbers (or column names) for the subset to work properly. Why? Think about the game Battleships. The board has 10 rows and 10 columns making for 100 cells. When you select a target to fire at you tell the opponent the row and the column, such as A7. Saying you attack A or attack 7 doesn’t make sense. Column A has 10 rows and row 7 has 10 columns so it is not clear which cell you mean. So your opponent only knows which cell you mean if you give both the column name and row number. A data.frame is very similar to the Battleships board, with a number of rows and columns. You need to specify both the row(s) and column(s) you want to subset (hit) for R to understand what it is you want. 2.5.4 Subset Colorado data Finally we have the tools to subset our UCR data to just be Colorado from 2011-2017. There are three conditional statements we need to make, two for rows and one for columns. Only rows where the state equals Colorado Only rows where the year is 2011-2017 Only the following columns: actual_murder, state, year, population, ori, agency_name We could use the &amp; operator to say rows must meet condition 1 and condition 2. Since this is an intro lesson we will do them as two separate conditional statements. For the first step we want to get all rows in the data where the state equals “colorado” (in this data all state names are lowercase). And at this point we want keep all columns in the data. So let’s make a new object called “colorado” to save the result of this subset. Remember that we want to put the object to the left of the [] to make sure it returns the data. Just having the [] will only return TRUE or FALSE values based on the conditional statement. Since we want all columns we don’t need to put anything after the comma. colorado &lt;- offenses_known_yearly_1960_2017[offenses_known_yearly_1960_2017$state == &quot;colorado&quot;, ] Now we want to get all the rows where the year is 2011-2017. Since we want to check if the year is one of the years 2011-2017, we will use %in% and put the years in a vector 2011:2017. This time our primary data set is “colorado”, not “offenses_known_yearly_1960_2017” since “colorado” has already subsetted to just the state we want. This is how subsetting generally works. You take a large data set, subset it to a smaller one and continue to subset the smaller one to only the data you want. colorado &lt;- colorado[colorado$year %in% 2011:2017, ] Finally we want the columns stated above and to keep every row in the current data. Since the format is [row, column] in this case we keep the “row” part blank to indicate we want every row. colorado &lt;- colorado[ , c(&quot;actual_murder&quot;, &quot;state&quot;, &quot;year&quot;, &quot;population&quot;, &quot;ori&quot;, &quot;agency_name&quot;)] We can do a quick check using the unique() function. The unique() prints all the unique values in a category, such as a column. We will use it on the “state” and “year” columns to make sure only the values we want are present. unique(colorado$state) #&gt; [1] &quot;colorado&quot; unique(colorado$year) #&gt; [1] 2017 2016 2015 2014 2013 2012 2011 The only state is Colorado and the only years are 2011-2017 so our subset worked! This data shows the number of murders in each agency. We want to look at state trends so in Section (#aggregate) we will sum up all the murders per year and see if marijuana affected it. "],
["explore.html", "3 Exploratory data analysis 3.1 Summary and Table 3.2 Graphing 3.3 Aggregating (summaries of groups)", " 3 Exploratory data analysis When you first start working on new data it is important to spend some time getting familiar with the data. This includes understanding how many rows and columns it has, what each row means (is each row an offender, crime in a city over a day/month/year, a unique ID code, etc.), and what columns it has. Basically you want to know if the data is capable of answering the question you are asking. While not a comprehensive list, the following is a good start for exploratory data analysis of new data sets. What variables are available? What time period does it cover? What are the units (what does each row represent?)? Are there outliers? How many? Are there missing values? How many? For this lesson we will use a data set of FBI Uniform Crime Data (UCR) for 2017. This data includes every agency that reported their data for all 12 months of the year. Throughout this lesson we will look at some summary statistics for the variables we are interested in and make some basic graphs to visualize the data. We’ll return to UCR data in Chapter @ref(#ucr) when focusing on what UCR is and how to use it. First we need to load the data. Make sure your working directory is set to the folder where the data is. load(&quot;data/ucr2017.rda&quot;) As a first step let’s see how many rows and columns are in the data, and glance at the first several rows from each column. nrow() and ncol() tell us the number of rows and columns it has, respectively. Like most functions, what you need to do is put the data set name inside the () (exactly as it is spelled without any quotes). nrow(ucr2017) #&gt; [1] 15764 ncol(ucr2017) #&gt; [1] 9 The function head() will print out the first 6 rows of every column in the data. Since we only have 9 columns, we will use this function. Be careful when you have many columns (100+) as printing all of them out makes it read to read. head(ucr2017) #&gt; ori year agency_name state population actual_murder #&gt; 1 AK00101 2017 anchorage alaska 296188 27 #&gt; 2 AK00102 2017 fairbanks alaska 32937 10 #&gt; 3 AK00103 2017 juneau alaska 32344 1 #&gt; 4 AK00104 2017 ketchikan alaska 8230 1 #&gt; 5 AK00105 2017 kodiak alaska 6198 0 #&gt; 6 AK00106 2017 nome alaska 3829 0 #&gt; actual_rape_total actual_robbery_total actual_assault_aggravated #&gt; 1 391 778 2368 #&gt; 2 24 40 131 #&gt; 3 50 46 206 #&gt; 4 19 0 14 #&gt; 5 15 4 41 #&gt; 6 7 0 52 From these results it appears that each row is a single agency’s annual data for 2017 and the columns show the number of crimes for four crime categories included (the full UCR data contains many more crimes which we’ll see in a later lesson). Finally, we can run names() to print out every column name. We can already see every name from head() but this is useful when we have many columns and don’t want to use head(). names(ucr2017) #&gt; [1] &quot;ori&quot; &quot;year&quot; #&gt; [3] &quot;agency_name&quot; &quot;state&quot; #&gt; [5] &quot;population&quot; &quot;actual_murder&quot; #&gt; [7] &quot;actual_rape_total&quot; &quot;actual_robbery_total&quot; #&gt; [9] &quot;actual_assault_aggravated&quot; 3.1 Summary and Table An important function in understanding the data you have is summary() which, as discussed in Section 1.4, provides summary statistics on the numeric columns you have. Let’s take a look at the results before seeing how to do something similar for categorical columns. summary(ucr2017) #&gt; ori year agency_name state #&gt; Length:15764 Min. :2017 Length:15764 Length:15764 #&gt; Class :character 1st Qu.:2017 Class :character Class :character #&gt; Mode :character Median :2017 Mode :character Mode :character #&gt; Mean :2017 #&gt; 3rd Qu.:2017 #&gt; Max. :2017 #&gt; population actual_murder actual_rape_total #&gt; Min. : 0 Min. : 0.000 Min. : -2.000 #&gt; 1st Qu.: 914 1st Qu.: 0.000 1st Qu.: 0.000 #&gt; Median : 4460 Median : 0.000 Median : 1.000 #&gt; Mean : 19872 Mean : 1.069 Mean : 8.262 #&gt; 3rd Qu.: 15390 3rd Qu.: 0.000 3rd Qu.: 5.000 #&gt; Max. :8616333 Max. :653.000 Max. :2455.000 #&gt; actual_robbery_total actual_assault_aggravated #&gt; Min. : -1.00 Min. : -1.00 #&gt; 1st Qu.: 0.00 1st Qu.: 1.00 #&gt; Median : 0.00 Median : 5.00 #&gt; Mean : 19.85 Mean : 49.98 #&gt; 3rd Qu.: 4.00 3rd Qu.: 21.00 #&gt; Max. :13995.00 Max. :29771.00 The table() function returns every unique value in a category and how often that value appears. Unlike summary() we can’t just put the entire data set into the (), we need to specify a single column. To specify a column you use the dollar sign notation which is data$column. For most functions we use to examine the data as a whole, you can do the same for a specific column. head(ucr2017$agency_name) #&gt; [1] &quot;anchorage&quot; &quot;fairbanks&quot; &quot;juneau&quot; &quot;ketchikan&quot; &quot;kodiak&quot; &quot;nome&quot; There are only two columns in our data with categorical values that we can use - “year” and “state” so let’s use table() on both of them. The columns “ori” and “agency_name” are also categorical but as each row of data has a unique ORI and name, running table() on those columns would not be helpful. table(ucr2017$year) #&gt; #&gt; 2017 #&gt; 15764 We can see that every year in our data is 2017, as expected based on the data name. “year” is a numerical column so why can we use table() on it? R doesn’t differentiate between numbers and characters when seeing how often each value appears. If we ran table() on the column “actual_murder” it would tell us how many times each unique value in the column appeared in the data. That wouldn’t be very useful as we don’t really care how many times an agency has 7 murders, for example (though looking for how often a numeric column has the value 0 can be helpful in finding likely erroneous data). As numeric variables often have many more unique values than character variables, it also leads to many values being printed, making it harder to understand. For columns where the number of categories is important to us, such as years, states, neighborhoods, we should use table(). table(ucr2017$state) #&gt; #&gt; alabama alaska arizona #&gt; 305 32 107 #&gt; arkansas california colorado #&gt; 273 732 213 #&gt; connecticut delaware district of columbia #&gt; 107 63 3 #&gt; florida georgia guam #&gt; 603 522 1 #&gt; hawaii idaho illinois #&gt; 4 95 696 #&gt; indiana iowa kansas #&gt; 247 216 309 #&gt; kentucky louisiana maine #&gt; 352 192 135 #&gt; maryland massachusetts michigan #&gt; 152 346 625 #&gt; minnesota mississippi missouri #&gt; 397 71 580 #&gt; montana nebraska nevada #&gt; 108 225 59 #&gt; new hampshire new jersey new mexico #&gt; 176 576 116 #&gt; new york north carolina north dakota #&gt; 532 310 108 #&gt; ohio oklahoma oregon #&gt; 532 409 172 #&gt; pennsylvania rhode island south carolina #&gt; 1473 49 427 #&gt; south dakota tennessee texas #&gt; 92 466 999 #&gt; utah vermont virginia #&gt; 125 85 407 #&gt; washington west virginia wisconsin #&gt; 250 200 433 #&gt; wyoming #&gt; 57 This shows us how many times each state is present in the data. States with a larger population tend to appear more often, this makes sense as those states have more agencies to report. Right now the results are in alphabetical order, but when knowing how frequently something appears we usually want it order by frequency. We can use the sort() function to order the results from table(). Just put the entire table() function inside of the () in sort(). sort(table(ucr2017$state)) #&gt; #&gt; guam district of columbia hawaii #&gt; 1 3 4 #&gt; alaska rhode island wyoming #&gt; 32 49 57 #&gt; nevada delaware mississippi #&gt; 59 63 71 #&gt; vermont south dakota idaho #&gt; 85 92 95 #&gt; arizona connecticut montana #&gt; 107 107 108 #&gt; north dakota new mexico utah #&gt; 108 116 125 #&gt; maine maryland oregon #&gt; 135 152 172 #&gt; new hampshire louisiana west virginia #&gt; 176 192 200 #&gt; colorado iowa nebraska #&gt; 213 216 225 #&gt; indiana washington arkansas #&gt; 247 250 273 #&gt; alabama kansas north carolina #&gt; 305 309 310 #&gt; massachusetts kentucky minnesota #&gt; 346 352 397 #&gt; virginia oklahoma south carolina #&gt; 407 409 427 #&gt; wisconsin tennessee georgia #&gt; 433 466 522 #&gt; new york ohio new jersey #&gt; 532 532 576 #&gt; missouri florida michigan #&gt; 580 603 625 #&gt; illinois california texas #&gt; 696 732 999 #&gt; pennsylvania #&gt; 1473 And if we want to sort it in decreasing order of frequency, we can use the parameter decreasing in sort() and set it to TRUE. A parameter is just an option used in an R function to change the way the function is used or what output it gives. Almost all functions have these parameters and they are useful if you don’t want to use the default setting in the function. This parameter, decreasing changes the sort() output to print from largest to smallest. By default this parameter is set to FALSE and here we say it is equal to TRUE. sort(table(ucr2017$state), decreasing = TRUE) #&gt; #&gt; pennsylvania texas california #&gt; 1473 999 732 #&gt; illinois michigan florida #&gt; 696 625 603 #&gt; missouri new jersey new york #&gt; 580 576 532 #&gt; ohio georgia tennessee #&gt; 532 522 466 #&gt; wisconsin south carolina oklahoma #&gt; 433 427 409 #&gt; virginia minnesota kentucky #&gt; 407 397 352 #&gt; massachusetts north carolina kansas #&gt; 346 310 309 #&gt; alabama arkansas washington #&gt; 305 273 250 #&gt; indiana nebraska iowa #&gt; 247 225 216 #&gt; colorado west virginia louisiana #&gt; 213 200 192 #&gt; new hampshire oregon maryland #&gt; 176 172 152 #&gt; maine utah new mexico #&gt; 135 125 116 #&gt; montana north dakota arizona #&gt; 108 108 107 #&gt; connecticut idaho south dakota #&gt; 107 95 92 #&gt; vermont mississippi delaware #&gt; 85 71 63 #&gt; nevada wyoming rhode island #&gt; 59 57 49 #&gt; alaska hawaii district of columbia #&gt; 32 4 3 #&gt; guam #&gt; 1 3.2 Graphing We often want to make quick plots of our data to get a visual understanding of the data. We will learn a more different way to make graphs in Chapter @ref(#graphing-intro) but for now let’s use the function plot(). Let’s make a few scatterplots showing the relationship between two variables. With plot() the syntax (how you write the code) is plot(x_axis_variable, y_axis_variable). So all we need to do is give it the variable for the x- and y-axis. Each dot will represent a single agency (a single row in our data). plot(ucr2017$actual_murder, ucr2017$actual_robbery_total) Above we are telling R to plot the number of murders on the x-axis and the number of robberies on the y-axis. This shows the relationship between a city’s number of murders and number of robberies. We can see that there is a relationship where more murders is correlated with more robberies However, there are a huge number of agencies in the bottom-left corner which have very few murders or robberies. This makes sense as - as we see in the summary() above - most agencies are small, with the median population under 5,000 people. To try to avoid that clump of small agencies at the bottom, let’s make a new data set of only agencies with a population over 1 million. We will use the square bracket [] notation to subset. Remember it is [rows, columns] where we either say exactly which rows or columns we want or give a conditional statement and it’ll return only those that meet the condition. We will use the condition that we only want rows where the population is over 1 million. [ucr2017$population &gt; 1000000, ] Now our row conditional is done. We want all the columns in the data so leave the section after the comma (don’t forget to include that comma!) empty. Now our square bracket notation is done but we need to put it directly to the right of our data so that we take the rows from the right data set. ucr2017[ucr2017$population &gt; 1000000, ] And let’s save the results in a new object called “ucr2017_big_cities”. ucr2017_big_cities &lt;- ucr2017[ucr2017$population &gt; 1000000, ] Now we can do the same graph as above but using this new data set. plot(ucr2017_big_cities$actual_murder, ucr2017_big_cities$actual_robbery_total) The problem is somewhat solved. There is still a small clumping of agencies with few robberies or aggravated assaults but the issue is much better. And interestingly the trend is similar with this small subset of data as with all agencies included. To make our graph look better, we can add labels for the axes and a title (there are many options for changing the appears of this graph, we will just use these three). xlab - X-axis label ylab - Y-axis label main - Graph title Like all parameters, we add them in the () of plot() and separate each parameter by a comma. Since we are adding text to write in the plot, all of these parameter inputs must be in quotes. plot(ucr2017_big_cities$actual_murder, ucr2017_big_cities$actual_robbery_total, xlab = &quot;Murder&quot;, ylab = &quot;Robberies&quot;, main = &quot;Relationship between murder and robbery&quot;) 3.3 Aggregating (summaries of groups) Right now we have the number of crimes in each agency. For many policy analyses we’d be looking at the effect on the state as a whole, rather than at the agency-level. If we wanted to do this in our data we need to aggregate up to the state level. What the aggregate() function does is group values at some higher level than they currently are (e.g. from agency to state, from day to month, from city street to city neighborhood) and then do some mathematical operation of our choosing (in our case usually sum) to that group. In Section 2.5.4 we started to see if marijuana legalization affected murder in Colorado. We subsetted the data to only include agencies in Colorado from 2011-2017. Now we can continue to answer the question by aggregating to the state-level to see the total number of murders per year. Let’s think about how our data are and how we would (theoretically, before we write any code) find that out. Our data is a single row for each agency and we have a column indicating the year the agency reported. So how would be find out how many murders happened in Colorado for each year? Well, first we take all the agencies in 2011 (the first year available) and add up the murders for all agencies that reported that year. Then take all the rows in 2012 and add up their murders. And so on for all the years. That is essentially what aggregate() does. It takes each row and groups them according to the category we specify and then adds up (or does the mathematical operator we specify) each value in each group. The syntax (how we write the code) is as follows aggregate(numerical_column ~ category_column, FUN = math, data = data_set) The numerical column is the column that we are doing the mathematical operation (sum, mean, median) on. The category column is the one we are using to group (e.g. state, year). Note the ~ between the numerical and category columns. Unlike most functions where we specify a column name, in aggregate() we do not use quotes for the columns. FUN is the parameter where we tell aggregate() which mathematical operator to use. Note that FUN is all in capital letters. That is just how this function calls the parameter so we need to make sure we write it in capital letters. data_set is the name of the data set we are aggregating. In Chapter @ref(#subsetting-intro) we wanted to see if marijuana legalization in Colorado affected murder. To do this we need to have data showing the number of murders for a few years before and after legalization. We have subsetted UCR data to get all agencies in Colorado for the 3 years before and after 2014, the year of legalization. Let’s reload that data and rerun the subsetting code. load(&quot;data/offenses_known_yearly_1960_2017.rda&quot;) colorado &lt;- offenses_known_yearly_1960_2017[offenses_known_yearly_1960_2017$state == &quot;colorado&quot;, ] colorado &lt;- colorado[colorado$year %in% 2011:2017, ] colorado &lt;- colorado[ , c(&quot;actual_murder&quot;, &quot;state&quot;, &quot;year&quot;, &quot;population&quot;, &quot;ori&quot;, &quot;agency_name&quot;)] Now we can run aggregate() to get the number of murders per year. aggregate(actual_murder ~ year, FUN = sum, data = colorado) year actual_murder 1 2011 154 2 2012 163 3 2013 172 4 2014 148 5 2015 173 6 2016 203 7 2017 218 If we had more grouping categories would could add them by literally using + and then writing the next grouping variable name. In our case since all agencies are in the same state it doesn’t actually change the results. aggregate(actual_murder ~ year + state, FUN = sum, data = colorado) year state actual_murder 1 2011 colorado 154 2 2012 colorado 163 3 2013 colorado 172 4 2014 colorado 148 5 2015 colorado 173 6 2016 colorado 203 7 2017 colorado 218 If we want to aggregate multiple numeric columns we would use the cbind() function which binds together columns. Many times we care more about the crime rate (per 100,000 population usually) than the total number of crimes as a larger population tends to also mean more crime. We can aggregate both the population column and the actual_murder column to get totals for each year which we can use to make a murder rate column. Since we need the output of this aggregate saved somewhere to make that column, let’s call it “colorado_agg”. colorado_agg &lt;- aggregate(cbind(population, actual_murder) ~ year, FUN = sum, data = colorado) To make the murder rate we simply make a new column, which we can call “murder_rate” which is the number of murders divided by population multiplied by 100,000. colorado_agg$murder_rate &lt;- colorado_agg$actual_murder / colorado_agg$population * 100000 colorado_agg #&gt; year population actual_murder murder_rate #&gt; 1 2011 5155993 154 2.986816 #&gt; 2 2012 5227884 163 3.117896 #&gt; 3 2013 5308236 172 3.240248 #&gt; 4 2014 5402555 148 2.739445 #&gt; 5 2015 5505856 173 3.142109 #&gt; 6 2016 5590124 203 3.631404 #&gt; 7 2017 5661529 218 3.850550 Now we can see that the total number of murders increased as did the murder rate. So can we conclude that marijuana legalization increases murder? No, all this analysis shows is that the years following marijuana legalization, murders increased in Colorado. But that can be due to many reasons other than marijuana. For a proper analysis you’d need a comparison area that is similar to Colorado prior to legalization (and that doesn’t have legal marijuana) and see if the murder rates changes following Colorado’s legalization. We can also make a plot of this data showing the murder rate over time. With time-series graphs we want the time variable to be on the x-axis and the numeric variable we are measuring to the on the y-axis. plot(x = colorado_agg$year, y = colorado_agg$murder_rate) By default plot() makes a scatterplot. If we set the parameter type to “l” it will be a line plot. plot(x = colorado_agg$year, y = colorado_agg$murder_rate, type = &quot;l&quot;) We can add some labels and a title to make this graph easier to read. plot(x = colorado_agg$year, y = colorado_agg$murder_rate, type = &quot;l&quot;, xlab = &quot;Year&quot;, ylab = &quot;Murders per 100k Population&quot;, main = &quot;Murder Rate in Colorado, 2011-2017&quot;) "],
["dates-and-times.html", "4 Dates and Times 4.1 Why do dates and times matter? 4.2 lubridate 4.3 Working with dates 4.4 Chicago crime data", " 4 Dates and Times 4.1 Why do dates and times matter? Before we get started with any code, let’s think about why we should care about dates and times in data. Like most things you’ll use R for in this book (and for your own research), the data you have isn’t in the format you want it to be. For simple questions like “what day has the most crime?” you’ll need to know what day each crime occurred on. For more complex questions like “did marijuana legalization affect murder?” you need to know how many crimes occurred on months or years before and after marijuana legalization. In almost every case where time matters for research (and it matters in many studies) you will have data in the wrong format to answer you question. You’ll likely want to group all the days in a month together or just take crimes that happened at a certain time (as is common in studies of outdoor lighting). Many research studies are policy analyses comparing some outcome (e.g. number of crimes) in a state before and after a policy change compared to a similar locations without that change. In these cases you want to think about what time unit your data should be in (crimes per month, crime per year) and use the following tools to get the data into the right format. 4.2 lubridate To work with dates and times we will use the lubridate package. For a useful cheatsheet for this package click here To install this package run install.packages(&quot;lubridate&quot;) and R will download the package, allowing you to use it. Some Mac users have issues installing packages so if you run into an issue try changing the parameter type to “mac.binary” in the install.packages() function. install.packages(&quot;lubridate&quot;, type = &quot;mac.binary&quot;) When you use a new package you will always need to download it using install.packages(\"package_name\") the first time. You only need to do it once however every session you use it (i.e. time without restarting R) you will need to run library(\"package_name\") to tell R you want to use this package. Since some packages have functions with the same name as other packages this is useful so you don’t accidentally use a function you didn’t intend to use. In our case we’ll run library(lubridate) to be able to use the package. Note that install.package() has the package name in quotes and library() does not. library(lubridate) #&gt; #&gt; Attaching package: &#39;lubridate&#39; #&gt; The following object is masked from &#39;package:base&#39;: #&gt; #&gt; date 4.3 Working with dates Before using real data, we’ll start with defining useful functions and using a toy example. Below we have made the object called “dates” with three character values showing the dates August 7th for the years 2010-2012. Please note that Dates (capital D) are a special type of value that R understands and just putting what we can read as a date in quotes doesn’t make it so. dates &lt;- c(&quot;2010-08-07&quot;, &quot;2011-08-07&quot;, &quot;2012-08-07&quot;) When we look at these dates we can see that it starts with the year, then has the month, then the day. R doesn’t know that. We have to tell R what order the year, month, and day are in. This is the key part of the lubridate package. The functions below are the ones we’ll use to tell R which order the date is in and to convert it to a Date type. ymd() Order is year-month-day mdy() Order is month-day-year (common in crime data) dmy() Order is day-month-year Year, month, and day are all abbreviated to the first letter and all lowercase. Inside the parentheses we will put the date(s) we want to convert to a Date type. Since our date are in year-month-day order, we will use ymd(). ymd(dates) #&gt; [1] &quot;2010-08-07&quot; &quot;2011-08-07&quot; &quot;2012-08-07&quot; If you tell R the wrong order, it will not be able to read the data and will return NAs. myd(dates) #&gt; Warning: All formats failed to parse. No formats found. #&gt; [1] NA NA NA Some dates come with hour, minutes, and even seconds telling exactly when the event happened. In those cases you must add _hm to the end of your code to indicate that there are hour and minute information in the data. If there are also seconds, use _hms. ymd_hm() mdy_hm() dmy_hm() ymd_hms() mdy_hms() dmy_hms() Like before, telling R the wrong order will return all NAs. If the date has hours and minutes (and seconds) you must have _hm or it won’t work right, and if it doesn’t you must not include it. ymd_hms(dates) #&gt; Warning: All formats failed to parse. No formats found. #&gt; [1] NA NA NA Once you have the dates in the Date format, you can use a number of useful functions to extract information from these dates such as the year or month of the date, the hour if hours are available, and even the day of the month or week. year() month() day() Day of year mday() Day of month wday() Day of week hour() year(dates) #&gt; [1] 2010 2011 2012 This gives us an error. Why? When we ran the code ymd(dates) it changed the value in “dates” to Date type and printed out those new values. But it didn’t save it anywhere so our “dates” object is still a vector of characters rather than Dates. We need to run ymd(dates) again and save the result somewhere. Generally, to reduce the number of objects created when you’re making a change you just save it back in the original object, overwriting it. This doesn’t change the raw data found in .csv or .rda files, only the data that is read into R. This is important because we always want to keep the raw data unchanged and have all our changes recorded in code. dates &lt;- ymd(dates) Now that we have saved our changes in the “dates” object, lets try again. year(dates) #&gt; [1] 2010 2011 2012 month(dates) #&gt; [1] 8 8 8 By default month() gives the month number rather than the name of the month. We need to set the parameter label to TRUE to get the month name. month(dates, label = TRUE) #&gt; [1] Aug Aug Aug #&gt; 12 Levels: Jan &lt; Feb &lt; Mar &lt; Apr &lt; May &lt; Jun &lt; Jul &lt; Aug &lt; Sep &lt; ... &lt; Dec We can also set the parameter abbr to FALSE if we want the full month name rather than the abbreviation. month(dates, label = TRUE, abbr = FALSE) #&gt; [1] August August August #&gt; 12 Levels: January &lt; February &lt; March &lt; April &lt; May &lt; June &lt; ... &lt; December The final useful function we will discuss is floor_date() which rounds down the date to the first day of the unit given. There are a number of possible units, the most common for our purposes will be “year”, “month” “week”, and “day”. floor_date() floor_date(dates, unit = &quot;month&quot;) #&gt; [1] &quot;2010-08-01&quot; &quot;2011-08-01&quot; &quot;2012-08-01&quot; If we change the unit to “year” it’ll change the date to the first date in the year. floor_date(dates, unit = &quot;year&quot;) #&gt; [1] &quot;2010-01-01&quot; &quot;2011-01-01&quot; &quot;2012-01-01&quot; Using floor_date() will be very useful when you want to find the number of crimes in each month/year/week/day as you can do this to get a single date for each time period and aggregate crimes in that time period. 4.4 Chicago crime data Let’s use some sample data from Chicago to be able to work with real data. load(&quot;data/chicago.rda&quot;) We can use head() to look at the first 6 rows of dates head(chicago$Date) #&gt; [1] &quot;12/09/2014 11:54:00 PM&quot; &quot;12/09/2014 11:45:00 PM&quot; #&gt; [3] &quot;12/09/2014 11:42:00 PM&quot; &quot;12/09/2014 11:42:00 PM&quot; #&gt; [5] &quot;12/09/2014 11:40:00 PM&quot; &quot;12/09/2014 11:37:00 PM&quot; Now let’s use the square bracket [] indexing to also see the first 6 rows of dates. Remember, we’re going to want a vector of numbers 1 through 6 for this. Since these numbers are sequential without any missing we can use 1:6 instead of manually making a vector c(1, 2, 3, 4, 5, 6). Since we already specify we want the Date column, we don’t need any commas after the vector of numbers. chicago$Date[1:6] #&gt; [1] &quot;12/09/2014 11:54:00 PM&quot; &quot;12/09/2014 11:45:00 PM&quot; #&gt; [3] &quot;12/09/2014 11:42:00 PM&quot; &quot;12/09/2014 11:42:00 PM&quot; #&gt; [5] &quot;12/09/2014 11:40:00 PM&quot; &quot;12/09/2014 11:37:00 PM&quot; As you can see, the dates include the date in month-day-year format and the time includes hours, minutes, and seconds. So we must read in the data using mdy_hms() to tell R the proper order of the date and that it includes time up to the second. Lets save the results in a new column called “real_date”. It’s often useful when changing a column to save it as a new column in case you make a mistake in the code - that way you don’t have to reload the data to fix it. chicago$real_date &lt;- mdy_hms(chicago$Date) Now lets use head() again on our new column to see what we made. head(chicago$real_date) #&gt; [1] &quot;2014-12-09 23:54:00 UTC&quot; &quot;2014-12-09 23:45:00 UTC&quot; #&gt; [3] &quot;2014-12-09 23:42:00 UTC&quot; &quot;2014-12-09 23:42:00 UTC&quot; #&gt; [5] &quot;2014-12-09 23:40:00 UTC&quot; &quot;2014-12-09 23:37:00 UTC&quot; Lets make new columns for the year, month, and weekday for each date and then do some basic exploring on these new variables. chicago$year &lt;- year(chicago$real_date) chicago$month &lt;- month(chicago$real_date,label = TRUE, abbr = FALSE) chicago$weekday &lt;- wday(chicago$real_date, label = TRUE, abbr = FALSE) First we can use table() on each of these new columns to see how frequently each value in the category appears in our data. table(chicago$year) #&gt; #&gt; 2014 #&gt; 10000 table(chicago$month) #&gt; #&gt; January February March April May June July #&gt; 0 0 0 0 0 0 0 #&gt; August September October November December #&gt; 0 0 0 4179 5821 Our data comes entirely from November and December in 2014. This certainly limits our ability to see if crime changes across seasons or over years. table(chicago$weekday) #&gt; #&gt; Sunday Monday Tuesday Wednesday Thursday Friday Saturday #&gt; 1260 1855 1832 1341 1092 1312 1308 It looks like there’s a difference in which days have the most crime with Monday and Tuesday being the most dangerous days. For easier interpretation let’s turn these counts into percents. A simple way is to divide the results by the total number of rows in our data. table(chicago$weekday) / nrow(chicago) #&gt; #&gt; Sunday Monday Tuesday Wednesday Thursday Friday Saturday #&gt; 0.1260 0.1855 0.1832 0.1341 0.1092 0.1312 0.1308 This gives us proportions - we can multiple by 100 to get percents. table(chicago$weekday) / nrow(chicago) * 100 #&gt; #&gt; Sunday Monday Tuesday Wednesday Thursday Friday Saturday #&gt; 12.60 18.55 18.32 13.41 10.92 13.12 13.08 Now we see that indeed Monday and Tuesday have a much higher percent of crime in the data than other days. Is this reasonable? Most studies find that weekends have the highest amount of crime and that Mondays and Tuesdays have relatively low crime. But remember that we’re only using a sample of 10,000 crimes across two months in a single year from Chicago. Our data is likely not representative and we shouldn’t believe it too much. 4.4.1 Exercises What is the most common crime on Fridays? How many assaults happened on Fridays? Which weekday had the fewest assaults? How many fewer assaults did it have than on Fridays? "],
["regular-expressions.html", "5 Regular Expressions 5.1 Finding patterns in text with grep() 5.2 Finding and replacing patterns in text with gsub() 5.3 Useful special characters 5.4 Changing capitalization", " 5 Regular Expressions Many word processing programs like Microsoft Word or Google Docs let you search for a pattern - usually a word or phrase - and it will show you where on the page that pattern appears. It also lets you replace that word or phrase with something new. R does the same using the function grep() to search for a pattern and tell you where in the data it appears, and gsub() which lets you search for a pattern and then replace it with a new pattern. grep() - Find gsub() - Find and Replace The grep() function lets you find a pattern in the text and it will return a number saying which element has the pattern (basically which row has a match). gsub() lets you input a pattern to find and a pattern to replace it with, just like Find and Replace features elsewhere. You can remember the difference because gsub() has the word “sub” in it and what it does is substitute text with new text. A useful cheat sheet on regular expressions is available here. For this lesson we will use a vector of 50 crime categories. These are all of the crimes in San Francisco Police data. As you’ll see, there are some issues with the crime names that we need to fix. crimes &lt;- c( &quot;Arson&quot;, &quot;Assault&quot;, &quot;Burglary&quot;, &quot;Case Closure&quot;, &quot;Civil Sidewalks&quot;, &quot;Courtesy Report&quot;, &quot;Disorderly Conduct&quot;, &quot;Drug Offense&quot;, &quot;Drug Violation&quot;, &quot;Embezzlement&quot;, &quot;Family Offense&quot;, &quot;Fire Report&quot;, &quot;Forgery And Counterfeiting&quot;, &quot;Fraud&quot;, &quot;Gambling&quot;, &quot;Homicide&quot;, &quot;Human Trafficking (A), Commercial Sex Acts&quot;, &quot;Human Trafficking, Commercial Sex Acts&quot;, &quot;Juvenile Offenses&quot;, &quot;Larceny Theft&quot;, &quot;Liquor Laws&quot;, &quot;Lost Property&quot;, &quot;Malicious Mischief&quot;, &quot;Miscellaneous Investigation&quot;, &quot;Missing Person&quot;, &quot;Motor Vehicle Theft&quot;, &quot;Motor Vehicle Theft?&quot;, &quot;Non-Criminal&quot;, &quot;Offences Against The Family And Children&quot;, &quot;Other&quot;, &quot;Other Miscellaneous&quot;, &quot;Other Offenses&quot;, &quot;Prostitution&quot;, &quot;Rape&quot;, &quot;Recovered Vehicle&quot;, &quot;Robbery&quot;, &quot;Sex Offense&quot;, &quot;Stolen Property&quot;, &quot;Suicide&quot;, &quot;Suspicious&quot;, &quot;Suspicious Occ&quot;, &quot;Traffic Collision&quot;, &quot;Traffic Violation Arrest&quot;, &quot;Vandalism&quot;, &quot;Vehicle Impounded&quot;, &quot;Vehicle Misplaced&quot;, &quot;Warrant&quot;, &quot;Weapons Carrying Etc&quot;, &quot;Weapons Offence&quot;, &quot;Weapons Offense&quot; ) When looking closely at these crimes it is clear that some may overlap in certain categories such as theft, and there are several duplicates with slight differences in spelling. For example the last two crimes are “Weapons Offence” and “Weapons Offense”. These should be the same crime but the first one spelled “offense” wrong. And take a look at “motor vehicle theft”. There are two crimes here because one of them adds a question mark at the end for some reason. 5.1 Finding patterns in text with grep() We’ll start with grep() which allows us to search a vector of data (in R columns in a data.frame operate the same as a vector) and find where there is a match for the pattern we want to look for. The syntax for grep() is grep(\"pattern\", data) Where pattern is the pattern you are searching for, such as “a” if you want to find all values with the letter a. The pattern must always be in quotes. data is a vector of strings (such as “crimes” we made above or a column in a data.frame) that you are searching in to find the pattern. The output of this function is a number which says which element(s) in the vector the pattern was found in. If it returns, for example, the numbers 1 and 3 you know that the first and third element in your vector has the pattern - and no other elements do. It is essentially returning the index where the conditional statement “is this pattern present” is true. So since our data is “crimes” our grep() function will be grep(\"\", crimes). What we put in the \"\" is the pattern we want to search for. Let’s start with the letter “a”. grep(&quot;a&quot;, crimes) #&gt; [1] 2 3 4 5 9 11 14 15 17 18 20 21 23 24 28 29 31 34 42 43 44 46 47 #&gt; [24] 48 49 50 It gives us a bunch of numbers where the letter “a” is present in that element of “crimes”. What this is useful for is subsetting. We can use grep() to find all values that match a pattern we want and subset to keep just those values. crimes[grep(&quot;a&quot;, crimes)] #&gt; [1] &quot;Assault&quot; #&gt; [2] &quot;Burglary&quot; #&gt; [3] &quot;Case Closure&quot; #&gt; [4] &quot;Civil Sidewalks&quot; #&gt; [5] &quot;Drug Violation&quot; #&gt; [6] &quot;Family Offense&quot; #&gt; [7] &quot;Fraud&quot; #&gt; [8] &quot;Gambling&quot; #&gt; [9] &quot;Human Trafficking (A), Commercial Sex Acts&quot; #&gt; [10] &quot;Human Trafficking, Commercial Sex Acts&quot; #&gt; [11] &quot;Larceny Theft&quot; #&gt; [12] &quot;Liquor Laws&quot; #&gt; [13] &quot;Malicious Mischief&quot; #&gt; [14] &quot;Miscellaneous Investigation&quot; #&gt; [15] &quot;Non-Criminal&quot; #&gt; [16] &quot;Offences Against The Family And Children&quot; #&gt; [17] &quot;Other Miscellaneous&quot; #&gt; [18] &quot;Rape&quot; #&gt; [19] &quot;Traffic Collision&quot; #&gt; [20] &quot;Traffic Violation Arrest&quot; #&gt; [21] &quot;Vandalism&quot; #&gt; [22] &quot;Vehicle Misplaced&quot; #&gt; [23] &quot;Warrant&quot; #&gt; [24] &quot;Weapons Carrying Etc&quot; #&gt; [25] &quot;Weapons Offence&quot; #&gt; [26] &quot;Weapons Offense&quot; Searching for the letter “a” isn’t that useful. Let’s say we want to subset the data to only include theft related crimes. From reading the list of crimes we can see there are multiple theft crimes - “Larceny Theft”, “Motor Vehicle Theft”, and “Motor Vehicle Theft?”. We may also want to include “Stolen Property” in this search but we’ll wait until later in this lesson for how to search for multiple patterns. Since those three crimes all have the word “Theft” in the name we can search for the pattern and it will return only those crimes grep(&quot;Theft&quot;, crimes) #&gt; [1] 20 26 27 crimes[grep(&quot;Theft&quot;, crimes)] #&gt; [1] &quot;Larceny Theft&quot; &quot;Motor Vehicle Theft&quot; &quot;Motor Vehicle Theft?&quot; A very useful parameter is value. When we set value to TRUE, it will print out the actual strings that are a match rather than the element number. While this prevents us from using it to subset (since R no longer knows which rows are a match), it is an excellent tool to check if the grep() was successful as we can visually confirm it returns what we want. When we start to learn about special characters which make the patterns more complicated, this will be important. grep(&quot;Theft&quot;, crimes, value = TRUE) #&gt; [1] &quot;Larceny Theft&quot; &quot;Motor Vehicle Theft&quot; &quot;Motor Vehicle Theft?&quot; Note that grep() (and gsub()) is case sensitive so you must capitalize properly. grep(&quot;theft&quot;, crimes) #&gt; integer(0) Setting the parameter ignore.case to be TRUE makes grep() ignore capitalization. grep(&quot;theft&quot;, crimes, ignore.case = TRUE) #&gt; [1] 20 26 27 5.2 Finding and replacing patterns in text with gsub() gsub() takes patterns and replaces them with other patterns. An important use in criminology for gsub() is to fix spelling mistakes in the text such as the way “offense” was spelled wrong in our data. This will be a standard part of your data cleaning process and is important as a misspelled word can cause significant issues. For example if our previous example of marijuana legalization in Colorado had half of agencies misspelling the name “Colorado”, aggregating the data by the state (or simply subsetting to just Colorado agencies) would give completely different results as you’d lose half your data. gsub() is also useful when you want to take subcategories and change the value to larger categories. For example we could take any crime with the word “Theft” in it and change the whole crime name to “Theft”. In our data that would take 3 subcategories of thefts and turn it into a larger category we could aggregate to. This will be useful in city-level data where you may only care about a certain type of crime but it has many subcategories that you need to aggregate. The syntax of gsub() is similar to grep() with the addition of a pattern to replace the pattern we found. gsub(\"find_pattern\", \"replace_pattern\", data) Let’s start with a simple example of finding the letter “a” and replacing it with “z”. Our data will be the word “cat”. gsub(&quot;a&quot;, &quot;z&quot;, &quot;cat&quot;) #&gt; [1] &quot;czt&quot; Like grep(), gsub() is case sensitive and has the parameter ignore.case to ignore capitalization. gsub(&quot;A&quot;, &quot;z&quot;, &quot;cat&quot;) #&gt; [1] &quot;cat&quot; gsub(&quot;A&quot;, &quot;z&quot;, &quot;cat&quot;, ignore.case = TRUE) #&gt; [1] &quot;czt&quot; gsub() returns the same data you input but with the pattern already replaced. Above you can see that when using capital A, it returns “cat” unchanged as it never found the pattern. When ignore.case was set to TRUE it returned “czt” as it then matched to letter “A”. We can use gsub() to replace some issues in the crimes data such as “Offense” being spelled “Offence”. gsub(&quot;Offence&quot;, &quot;Offense&quot;, crimes) #&gt; [1] &quot;Arson&quot; #&gt; [2] &quot;Assault&quot; #&gt; [3] &quot;Burglary&quot; #&gt; [4] &quot;Case Closure&quot; #&gt; [5] &quot;Civil Sidewalks&quot; #&gt; [6] &quot;Courtesy Report&quot; #&gt; [7] &quot;Disorderly Conduct&quot; #&gt; [8] &quot;Drug Offense&quot; #&gt; [9] &quot;Drug Violation&quot; #&gt; [10] &quot;Embezzlement&quot; #&gt; [11] &quot;Family Offense&quot; #&gt; [12] &quot;Fire Report&quot; #&gt; [13] &quot;Forgery And Counterfeiting&quot; #&gt; [14] &quot;Fraud&quot; #&gt; [15] &quot;Gambling&quot; #&gt; [16] &quot;Homicide&quot; #&gt; [17] &quot;Human Trafficking (A), Commercial Sex Acts&quot; #&gt; [18] &quot;Human Trafficking, Commercial Sex Acts&quot; #&gt; [19] &quot;Juvenile Offenses&quot; #&gt; [20] &quot;Larceny Theft&quot; #&gt; [21] &quot;Liquor Laws&quot; #&gt; [22] &quot;Lost Property&quot; #&gt; [23] &quot;Malicious Mischief&quot; #&gt; [24] &quot;Miscellaneous Investigation&quot; #&gt; [25] &quot;Missing Person&quot; #&gt; [26] &quot;Motor Vehicle Theft&quot; #&gt; [27] &quot;Motor Vehicle Theft?&quot; #&gt; [28] &quot;Non-Criminal&quot; #&gt; [29] &quot;Offenses Against The Family And Children&quot; #&gt; [30] &quot;Other&quot; #&gt; [31] &quot;Other Miscellaneous&quot; #&gt; [32] &quot;Other Offenses&quot; #&gt; [33] &quot;Prostitution&quot; #&gt; [34] &quot;Rape&quot; #&gt; [35] &quot;Recovered Vehicle&quot; #&gt; [36] &quot;Robbery&quot; #&gt; [37] &quot;Sex Offense&quot; #&gt; [38] &quot;Stolen Property&quot; #&gt; [39] &quot;Suicide&quot; #&gt; [40] &quot;Suspicious&quot; #&gt; [41] &quot;Suspicious Occ&quot; #&gt; [42] &quot;Traffic Collision&quot; #&gt; [43] &quot;Traffic Violation Arrest&quot; #&gt; [44] &quot;Vandalism&quot; #&gt; [45] &quot;Vehicle Impounded&quot; #&gt; [46] &quot;Vehicle Misplaced&quot; #&gt; [47] &quot;Warrant&quot; #&gt; [48] &quot;Weapons Carrying Etc&quot; #&gt; [49] &quot;Weapons Offense&quot; #&gt; [50] &quot;Weapons Offense&quot; A useful pattern is an empty string \"\" which says replace whatever the find_pattern is with nothing, deleting it. Let’s delete the letter “a” from the data. gsub(&quot;a&quot;, &quot;&quot;, crimes) #&gt; [1] &quot;Arson&quot; #&gt; [2] &quot;Assult&quot; #&gt; [3] &quot;Burglry&quot; #&gt; [4] &quot;Cse Closure&quot; #&gt; [5] &quot;Civil Sidewlks&quot; #&gt; [6] &quot;Courtesy Report&quot; #&gt; [7] &quot;Disorderly Conduct&quot; #&gt; [8] &quot;Drug Offense&quot; #&gt; [9] &quot;Drug Violtion&quot; #&gt; [10] &quot;Embezzlement&quot; #&gt; [11] &quot;Fmily Offense&quot; #&gt; [12] &quot;Fire Report&quot; #&gt; [13] &quot;Forgery And Counterfeiting&quot; #&gt; [14] &quot;Frud&quot; #&gt; [15] &quot;Gmbling&quot; #&gt; [16] &quot;Homicide&quot; #&gt; [17] &quot;Humn Trfficking (A), Commercil Sex Acts&quot; #&gt; [18] &quot;Humn Trfficking, Commercil Sex Acts&quot; #&gt; [19] &quot;Juvenile Offenses&quot; #&gt; [20] &quot;Lrceny Theft&quot; #&gt; [21] &quot;Liquor Lws&quot; #&gt; [22] &quot;Lost Property&quot; #&gt; [23] &quot;Mlicious Mischief&quot; #&gt; [24] &quot;Miscellneous Investigtion&quot; #&gt; [25] &quot;Missing Person&quot; #&gt; [26] &quot;Motor Vehicle Theft&quot; #&gt; [27] &quot;Motor Vehicle Theft?&quot; #&gt; [28] &quot;Non-Criminl&quot; #&gt; [29] &quot;Offences Aginst The Fmily And Children&quot; #&gt; [30] &quot;Other&quot; #&gt; [31] &quot;Other Miscellneous&quot; #&gt; [32] &quot;Other Offenses&quot; #&gt; [33] &quot;Prostitution&quot; #&gt; [34] &quot;Rpe&quot; #&gt; [35] &quot;Recovered Vehicle&quot; #&gt; [36] &quot;Robbery&quot; #&gt; [37] &quot;Sex Offense&quot; #&gt; [38] &quot;Stolen Property&quot; #&gt; [39] &quot;Suicide&quot; #&gt; [40] &quot;Suspicious&quot; #&gt; [41] &quot;Suspicious Occ&quot; #&gt; [42] &quot;Trffic Collision&quot; #&gt; [43] &quot;Trffic Violtion Arrest&quot; #&gt; [44] &quot;Vndlism&quot; #&gt; [45] &quot;Vehicle Impounded&quot; #&gt; [46] &quot;Vehicle Misplced&quot; #&gt; [47] &quot;Wrrnt&quot; #&gt; [48] &quot;Wepons Crrying Etc&quot; #&gt; [49] &quot;Wepons Offence&quot; #&gt; [50] &quot;Wepons Offense&quot; 5.3 Useful special characters So far we have just searched for a single character or word and expected a return only if an exact match was found. Now we’ll discuss a number of characters called “special characters” that allow us to make more complex grep() and gsub() pattern searches. 5.3.1 Multiple characters [] To search for multiple matches we can put the pattern we want to search for inside square brackets [] (note that we use the same square brackets for subsetting but they operate very differently in this context). For example, we can find all the crimes that contain vowels. The grep() searches if any of the letters inside of the [] are present in our “crimes” vector. grep(&quot;[aeiou]&quot;, crimes, value = TRUE) #&gt; [1] &quot;Arson&quot; #&gt; [2] &quot;Assault&quot; #&gt; [3] &quot;Burglary&quot; #&gt; [4] &quot;Case Closure&quot; #&gt; [5] &quot;Civil Sidewalks&quot; #&gt; [6] &quot;Courtesy Report&quot; #&gt; [7] &quot;Disorderly Conduct&quot; #&gt; [8] &quot;Drug Offense&quot; #&gt; [9] &quot;Drug Violation&quot; #&gt; [10] &quot;Embezzlement&quot; #&gt; [11] &quot;Family Offense&quot; #&gt; [12] &quot;Fire Report&quot; #&gt; [13] &quot;Forgery And Counterfeiting&quot; #&gt; [14] &quot;Fraud&quot; #&gt; [15] &quot;Gambling&quot; #&gt; [16] &quot;Homicide&quot; #&gt; [17] &quot;Human Trafficking (A), Commercial Sex Acts&quot; #&gt; [18] &quot;Human Trafficking, Commercial Sex Acts&quot; #&gt; [19] &quot;Juvenile Offenses&quot; #&gt; [20] &quot;Larceny Theft&quot; #&gt; [21] &quot;Liquor Laws&quot; #&gt; [22] &quot;Lost Property&quot; #&gt; [23] &quot;Malicious Mischief&quot; #&gt; [24] &quot;Miscellaneous Investigation&quot; #&gt; [25] &quot;Missing Person&quot; #&gt; [26] &quot;Motor Vehicle Theft&quot; #&gt; [27] &quot;Motor Vehicle Theft?&quot; #&gt; [28] &quot;Non-Criminal&quot; #&gt; [29] &quot;Offences Against The Family And Children&quot; #&gt; [30] &quot;Other&quot; #&gt; [31] &quot;Other Miscellaneous&quot; #&gt; [32] &quot;Other Offenses&quot; #&gt; [33] &quot;Prostitution&quot; #&gt; [34] &quot;Rape&quot; #&gt; [35] &quot;Recovered Vehicle&quot; #&gt; [36] &quot;Robbery&quot; #&gt; [37] &quot;Sex Offense&quot; #&gt; [38] &quot;Stolen Property&quot; #&gt; [39] &quot;Suicide&quot; #&gt; [40] &quot;Suspicious&quot; #&gt; [41] &quot;Suspicious Occ&quot; #&gt; [42] &quot;Traffic Collision&quot; #&gt; [43] &quot;Traffic Violation Arrest&quot; #&gt; [44] &quot;Vandalism&quot; #&gt; [45] &quot;Vehicle Impounded&quot; #&gt; [46] &quot;Vehicle Misplaced&quot; #&gt; [47] &quot;Warrant&quot; #&gt; [48] &quot;Weapons Carrying Etc&quot; #&gt; [49] &quot;Weapons Offence&quot; #&gt; [50] &quot;Weapons Offense&quot; As it searches for any letter inside of the square brackets, the order does not matter. grep(&quot;[uoiea]&quot;, crimes, value = TRUE) #&gt; [1] &quot;Arson&quot; #&gt; [2] &quot;Assault&quot; #&gt; [3] &quot;Burglary&quot; #&gt; [4] &quot;Case Closure&quot; #&gt; [5] &quot;Civil Sidewalks&quot; #&gt; [6] &quot;Courtesy Report&quot; #&gt; [7] &quot;Disorderly Conduct&quot; #&gt; [8] &quot;Drug Offense&quot; #&gt; [9] &quot;Drug Violation&quot; #&gt; [10] &quot;Embezzlement&quot; #&gt; [11] &quot;Family Offense&quot; #&gt; [12] &quot;Fire Report&quot; #&gt; [13] &quot;Forgery And Counterfeiting&quot; #&gt; [14] &quot;Fraud&quot; #&gt; [15] &quot;Gambling&quot; #&gt; [16] &quot;Homicide&quot; #&gt; [17] &quot;Human Trafficking (A), Commercial Sex Acts&quot; #&gt; [18] &quot;Human Trafficking, Commercial Sex Acts&quot; #&gt; [19] &quot;Juvenile Offenses&quot; #&gt; [20] &quot;Larceny Theft&quot; #&gt; [21] &quot;Liquor Laws&quot; #&gt; [22] &quot;Lost Property&quot; #&gt; [23] &quot;Malicious Mischief&quot; #&gt; [24] &quot;Miscellaneous Investigation&quot; #&gt; [25] &quot;Missing Person&quot; #&gt; [26] &quot;Motor Vehicle Theft&quot; #&gt; [27] &quot;Motor Vehicle Theft?&quot; #&gt; [28] &quot;Non-Criminal&quot; #&gt; [29] &quot;Offences Against The Family And Children&quot; #&gt; [30] &quot;Other&quot; #&gt; [31] &quot;Other Miscellaneous&quot; #&gt; [32] &quot;Other Offenses&quot; #&gt; [33] &quot;Prostitution&quot; #&gt; [34] &quot;Rape&quot; #&gt; [35] &quot;Recovered Vehicle&quot; #&gt; [36] &quot;Robbery&quot; #&gt; [37] &quot;Sex Offense&quot; #&gt; [38] &quot;Stolen Property&quot; #&gt; [39] &quot;Suicide&quot; #&gt; [40] &quot;Suspicious&quot; #&gt; [41] &quot;Suspicious Occ&quot; #&gt; [42] &quot;Traffic Collision&quot; #&gt; [43] &quot;Traffic Violation Arrest&quot; #&gt; [44] &quot;Vandalism&quot; #&gt; [45] &quot;Vehicle Impounded&quot; #&gt; [46] &quot;Vehicle Misplaced&quot; #&gt; [47] &quot;Warrant&quot; #&gt; [48] &quot;Weapons Carrying Etc&quot; #&gt; [49] &quot;Weapons Offence&quot; #&gt; [50] &quot;Weapons Offense&quot; This also works for numbers though we do not have any numbers in the data. grep(&quot;[01234567890]&quot;, crimes, value = TRUE) #&gt; character(0) If we wanted to search for a pattern, such as vowels, that is repeated we could put multiple [] patterns together. We will see another way to search for a repeated pattern soon. grep(&quot;[aeiou][aeiou][aeiou]&quot;, crimes, value = TRUE) #&gt; [1] &quot;Malicious Mischief&quot; &quot;Miscellaneous Investigation&quot; #&gt; [3] &quot;Other Miscellaneous&quot; &quot;Suspicious&quot; #&gt; [5] &quot;Suspicious Occ&quot; Inside the [] we can also use the - to make intervals between certain values. For numbers, n-m means any number between n and m (inclusive). For letters, a-z means all lowercase letters and A-Z means all uppercase letters in that range (inclusive). grep(&quot;[x-z]&quot;, crimes, value = TRUE) #&gt; [1] &quot;Burglary&quot; #&gt; [2] &quot;Courtesy Report&quot; #&gt; [3] &quot;Disorderly Conduct&quot; #&gt; [4] &quot;Embezzlement&quot; #&gt; [5] &quot;Family Offense&quot; #&gt; [6] &quot;Forgery And Counterfeiting&quot; #&gt; [7] &quot;Human Trafficking (A), Commercial Sex Acts&quot; #&gt; [8] &quot;Human Trafficking, Commercial Sex Acts&quot; #&gt; [9] &quot;Larceny Theft&quot; #&gt; [10] &quot;Lost Property&quot; #&gt; [11] &quot;Offences Against The Family And Children&quot; #&gt; [12] &quot;Robbery&quot; #&gt; [13] &quot;Sex Offense&quot; #&gt; [14] &quot;Stolen Property&quot; #&gt; [15] &quot;Weapons Carrying Etc&quot; 5.3.2 n-many of previous character {n} {n} means the preceding item will be matched exactly n times. We can use it to rewrite the above grep() to saw the values in the [] should be repeated three times. grep(&quot;[aeiou]{3}&quot;, crimes, value = TRUE) #&gt; [1] &quot;Malicious Mischief&quot; &quot;Miscellaneous Investigation&quot; #&gt; [3] &quot;Other Miscellaneous&quot; &quot;Suspicious&quot; #&gt; [5] &quot;Suspicious Occ&quot; 5.3.3 n-many to m-many of previous character {n,m} While {n} says “the previous character (or characters inside a []) must be present exactly n times”, we can allow a range by using {n,m}. Here the previous character must be present between n and m times. We can check for values where there are 2-3 vowels in a row. Note that there cannot be a space before or after the comma. grep(&quot;[aeiou]{2,3}&quot;, crimes, value = TRUE) #&gt; [1] &quot;Assault&quot; #&gt; [2] &quot;Courtesy Report&quot; #&gt; [3] &quot;Drug Violation&quot; #&gt; [4] &quot;Forgery And Counterfeiting&quot; #&gt; [5] &quot;Fraud&quot; #&gt; [6] &quot;Human Trafficking (A), Commercial Sex Acts&quot; #&gt; [7] &quot;Human Trafficking, Commercial Sex Acts&quot; #&gt; [8] &quot;Liquor Laws&quot; #&gt; [9] &quot;Malicious Mischief&quot; #&gt; [10] &quot;Miscellaneous Investigation&quot; #&gt; [11] &quot;Offences Against The Family And Children&quot; #&gt; [12] &quot;Other Miscellaneous&quot; #&gt; [13] &quot;Prostitution&quot; #&gt; [14] &quot;Suicide&quot; #&gt; [15] &quot;Suspicious&quot; #&gt; [16] &quot;Suspicious Occ&quot; #&gt; [17] &quot;Traffic Collision&quot; #&gt; [18] &quot;Traffic Violation Arrest&quot; #&gt; [19] &quot;Vehicle Impounded&quot; #&gt; [20] &quot;Weapons Carrying Etc&quot; #&gt; [21] &quot;Weapons Offence&quot; #&gt; [22] &quot;Weapons Offense&quot; If we wanted only crimes with exactly three vowels in a row we’d use {3,3}. grep(&quot;[aeiou]{3,3}&quot;, crimes, value = TRUE) #&gt; [1] &quot;Malicious Mischief&quot; &quot;Miscellaneous Investigation&quot; #&gt; [3] &quot;Other Miscellaneous&quot; &quot;Suspicious&quot; #&gt; [5] &quot;Suspicious Occ&quot; If we leave n blank, such as {,m} it says “previous character must be present up to m times”. grep(&quot;[aeiou]{,3}&quot;, crimes, value = TRUE) #&gt; [1] &quot;Arson&quot; #&gt; [2] &quot;Assault&quot; #&gt; [3] &quot;Burglary&quot; #&gt; [4] &quot;Case Closure&quot; #&gt; [5] &quot;Civil Sidewalks&quot; #&gt; [6] &quot;Courtesy Report&quot; #&gt; [7] &quot;Disorderly Conduct&quot; #&gt; [8] &quot;Drug Offense&quot; #&gt; [9] &quot;Drug Violation&quot; #&gt; [10] &quot;Embezzlement&quot; #&gt; [11] &quot;Family Offense&quot; #&gt; [12] &quot;Fire Report&quot; #&gt; [13] &quot;Forgery And Counterfeiting&quot; #&gt; [14] &quot;Fraud&quot; #&gt; [15] &quot;Gambling&quot; #&gt; [16] &quot;Homicide&quot; #&gt; [17] &quot;Human Trafficking (A), Commercial Sex Acts&quot; #&gt; [18] &quot;Human Trafficking, Commercial Sex Acts&quot; #&gt; [19] &quot;Juvenile Offenses&quot; #&gt; [20] &quot;Larceny Theft&quot; #&gt; [21] &quot;Liquor Laws&quot; #&gt; [22] &quot;Lost Property&quot; #&gt; [23] &quot;Malicious Mischief&quot; #&gt; [24] &quot;Miscellaneous Investigation&quot; #&gt; [25] &quot;Missing Person&quot; #&gt; [26] &quot;Motor Vehicle Theft&quot; #&gt; [27] &quot;Motor Vehicle Theft?&quot; #&gt; [28] &quot;Non-Criminal&quot; #&gt; [29] &quot;Offences Against The Family And Children&quot; #&gt; [30] &quot;Other&quot; #&gt; [31] &quot;Other Miscellaneous&quot; #&gt; [32] &quot;Other Offenses&quot; #&gt; [33] &quot;Prostitution&quot; #&gt; [34] &quot;Rape&quot; #&gt; [35] &quot;Recovered Vehicle&quot; #&gt; [36] &quot;Robbery&quot; #&gt; [37] &quot;Sex Offense&quot; #&gt; [38] &quot;Stolen Property&quot; #&gt; [39] &quot;Suicide&quot; #&gt; [40] &quot;Suspicious&quot; #&gt; [41] &quot;Suspicious Occ&quot; #&gt; [42] &quot;Traffic Collision&quot; #&gt; [43] &quot;Traffic Violation Arrest&quot; #&gt; [44] &quot;Vandalism&quot; #&gt; [45] &quot;Vehicle Impounded&quot; #&gt; [46] &quot;Vehicle Misplaced&quot; #&gt; [47] &quot;Warrant&quot; #&gt; [48] &quot;Weapons Carrying Etc&quot; #&gt; [49] &quot;Weapons Offence&quot; #&gt; [50] &quot;Weapons Offense&quot; This returns every crime as “up to m times” includes zero times. And the same works for leaving m blank but it will be “present at least n times”. grep(&quot;[aeiou]{3,}&quot;, crimes, value = TRUE) #&gt; [1] &quot;Malicious Mischief&quot; &quot;Miscellaneous Investigation&quot; #&gt; [3] &quot;Other Miscellaneous&quot; &quot;Suspicious&quot; #&gt; [5] &quot;Suspicious Occ&quot; 5.3.4 Start of string and “not” ^ The ^ symbol (called a caret) has two meanings. When the ^ is within square brackets [], it means “not” any of the following characters in the square brackets. Let’s use it for the pattern “Theft”. Here we want grep() to return any string that does not have the pattern “Theft” in it. grep(&quot;[^Theft]&quot;, crimes, value = TRUE) #&gt; [1] &quot;Arson&quot; #&gt; [2] &quot;Assault&quot; #&gt; [3] &quot;Burglary&quot; #&gt; [4] &quot;Case Closure&quot; #&gt; [5] &quot;Civil Sidewalks&quot; #&gt; [6] &quot;Courtesy Report&quot; #&gt; [7] &quot;Disorderly Conduct&quot; #&gt; [8] &quot;Drug Offense&quot; #&gt; [9] &quot;Drug Violation&quot; #&gt; [10] &quot;Embezzlement&quot; #&gt; [11] &quot;Family Offense&quot; #&gt; [12] &quot;Fire Report&quot; #&gt; [13] &quot;Forgery And Counterfeiting&quot; #&gt; [14] &quot;Fraud&quot; #&gt; [15] &quot;Gambling&quot; #&gt; [16] &quot;Homicide&quot; #&gt; [17] &quot;Human Trafficking (A), Commercial Sex Acts&quot; #&gt; [18] &quot;Human Trafficking, Commercial Sex Acts&quot; #&gt; [19] &quot;Juvenile Offenses&quot; #&gt; [20] &quot;Larceny Theft&quot; #&gt; [21] &quot;Liquor Laws&quot; #&gt; [22] &quot;Lost Property&quot; #&gt; [23] &quot;Malicious Mischief&quot; #&gt; [24] &quot;Miscellaneous Investigation&quot; #&gt; [25] &quot;Missing Person&quot; #&gt; [26] &quot;Motor Vehicle Theft&quot; #&gt; [27] &quot;Motor Vehicle Theft?&quot; #&gt; [28] &quot;Non-Criminal&quot; #&gt; [29] &quot;Offences Against The Family And Children&quot; #&gt; [30] &quot;Other&quot; #&gt; [31] &quot;Other Miscellaneous&quot; #&gt; [32] &quot;Other Offenses&quot; #&gt; [33] &quot;Prostitution&quot; #&gt; [34] &quot;Rape&quot; #&gt; [35] &quot;Recovered Vehicle&quot; #&gt; [36] &quot;Robbery&quot; #&gt; [37] &quot;Sex Offense&quot; #&gt; [38] &quot;Stolen Property&quot; #&gt; [39] &quot;Suicide&quot; #&gt; [40] &quot;Suspicious&quot; #&gt; [41] &quot;Suspicious Occ&quot; #&gt; [42] &quot;Traffic Collision&quot; #&gt; [43] &quot;Traffic Violation Arrest&quot; #&gt; [44] &quot;Vandalism&quot; #&gt; [45] &quot;Vehicle Impounded&quot; #&gt; [46] &quot;Vehicle Misplaced&quot; #&gt; [47] &quot;Warrant&quot; #&gt; [48] &quot;Weapons Carrying Etc&quot; #&gt; [49] &quot;Weapons Offence&quot; #&gt; [50] &quot;Weapons Offense&quot; As expected it returns all the crimes other than ones with the word “Theft” in it. This method is similar to the parameter invert which returns all values that do not meet the pattern. grep(&quot;Theft&quot;, crimes, invert = TRUE, value = TRUE) #&gt; [1] &quot;Arson&quot; #&gt; [2] &quot;Assault&quot; #&gt; [3] &quot;Burglary&quot; #&gt; [4] &quot;Case Closure&quot; #&gt; [5] &quot;Civil Sidewalks&quot; #&gt; [6] &quot;Courtesy Report&quot; #&gt; [7] &quot;Disorderly Conduct&quot; #&gt; [8] &quot;Drug Offense&quot; #&gt; [9] &quot;Drug Violation&quot; #&gt; [10] &quot;Embezzlement&quot; #&gt; [11] &quot;Family Offense&quot; #&gt; [12] &quot;Fire Report&quot; #&gt; [13] &quot;Forgery And Counterfeiting&quot; #&gt; [14] &quot;Fraud&quot; #&gt; [15] &quot;Gambling&quot; #&gt; [16] &quot;Homicide&quot; #&gt; [17] &quot;Human Trafficking (A), Commercial Sex Acts&quot; #&gt; [18] &quot;Human Trafficking, Commercial Sex Acts&quot; #&gt; [19] &quot;Juvenile Offenses&quot; #&gt; [20] &quot;Liquor Laws&quot; #&gt; [21] &quot;Lost Property&quot; #&gt; [22] &quot;Malicious Mischief&quot; #&gt; [23] &quot;Miscellaneous Investigation&quot; #&gt; [24] &quot;Missing Person&quot; #&gt; [25] &quot;Non-Criminal&quot; #&gt; [26] &quot;Offences Against The Family And Children&quot; #&gt; [27] &quot;Other&quot; #&gt; [28] &quot;Other Miscellaneous&quot; #&gt; [29] &quot;Other Offenses&quot; #&gt; [30] &quot;Prostitution&quot; #&gt; [31] &quot;Rape&quot; #&gt; [32] &quot;Recovered Vehicle&quot; #&gt; [33] &quot;Robbery&quot; #&gt; [34] &quot;Sex Offense&quot; #&gt; [35] &quot;Stolen Property&quot; #&gt; [36] &quot;Suicide&quot; #&gt; [37] &quot;Suspicious&quot; #&gt; [38] &quot;Suspicious Occ&quot; #&gt; [39] &quot;Traffic Collision&quot; #&gt; [40] &quot;Traffic Violation Arrest&quot; #&gt; [41] &quot;Vandalism&quot; #&gt; [42] &quot;Vehicle Impounded&quot; #&gt; [43] &quot;Vehicle Misplaced&quot; #&gt; [44] &quot;Warrant&quot; #&gt; [45] &quot;Weapons Carrying Etc&quot; #&gt; [46] &quot;Weapons Offence&quot; #&gt; [47] &quot;Weapons Offense&quot; The second use of ^ signifies that what follows it is the start of the string. We put the ^ at the beginning of the quotes and then anything that follows it must be the very start of the string. As an example let’s search for “Family”. Our data has both the “Family Offense” crime and the “Offences Against The Family And Children” crime (which likely are the same crime written differently). If we use ^ then we should only have the first one returned. grep(&quot;^Family&quot;, crimes, value = TRUE) #&gt; [1] &quot;Family Offense&quot; 5.3.5 End of string $ The dollar sign $ acts similar to the caret ^ except that it signifies that the value before it is the end of the string. We put the $ at the very end of our search pattern and whatever character is before it is the end of the string. For example, let’s search for all crimes that end with the word “Theft”. grep(&quot;Theft$&quot;, crimes, value = TRUE) #&gt; [1] &quot;Larceny Theft&quot; &quot;Motor Vehicle Theft&quot; Note that the crime “Motor Vehicle Theft?” doesn’t get selected as it ends with a question mark. 5.3.6 Anything . The . symbol is a stand-in for any value. This is useful when you aren’t sure about every part of the pattern you are searching. It can also be used when there are slight differences in words such as our incorrect “Offence” and “Offense”. We can replace the “c” and “s” with the .. grep(&quot;Weapons Offen.e&quot;, crimes, value = TRUE) #&gt; [1] &quot;Weapons Offence&quot; &quot;Weapons Offense&quot; 5.3.7 One or more of previous + The + means that the character immediately before it is present at least one time. This is the same as writing {1,}. If we wanted to find all values with only two words we would start with some number of letters followed by a space followed by some more letters and the string would end. grep(&quot;^[A-Za-z]+ [A-Za-z]+$&quot;, crimes, value = TRUE) #&gt; [1] &quot;Case Closure&quot; &quot;Civil Sidewalks&quot; #&gt; [3] &quot;Courtesy Report&quot; &quot;Disorderly Conduct&quot; #&gt; [5] &quot;Drug Offense&quot; &quot;Drug Violation&quot; #&gt; [7] &quot;Family Offense&quot; &quot;Fire Report&quot; #&gt; [9] &quot;Juvenile Offenses&quot; &quot;Larceny Theft&quot; #&gt; [11] &quot;Liquor Laws&quot; &quot;Lost Property&quot; #&gt; [13] &quot;Malicious Mischief&quot; &quot;Miscellaneous Investigation&quot; #&gt; [15] &quot;Missing Person&quot; &quot;Other Miscellaneous&quot; #&gt; [17] &quot;Other Offenses&quot; &quot;Recovered Vehicle&quot; #&gt; [19] &quot;Sex Offense&quot; &quot;Stolen Property&quot; #&gt; [21] &quot;Suspicious Occ&quot; &quot;Traffic Collision&quot; #&gt; [23] &quot;Vehicle Impounded&quot; &quot;Vehicle Misplaced&quot; #&gt; [25] &quot;Weapons Offence&quot; &quot;Weapons Offense&quot; 5.3.8 Zero or more of previous * The * special character says match zero or more of the previous character and is the same as {0,}. Combining . with * is powerful when used in gsub() to delete text before or after a pattern. Let’s write a pattern that searches the text for the word “Weapons” and then deletes any text after that. Our pattern would be \"Weapons.*\" which is the word “Weapons” followed by anything zero or more times. gsub(&quot;Weapons.*&quot;, &quot;Weapons&quot;, crimes) #&gt; [1] &quot;Arson&quot; #&gt; [2] &quot;Assault&quot; #&gt; [3] &quot;Burglary&quot; #&gt; [4] &quot;Case Closure&quot; #&gt; [5] &quot;Civil Sidewalks&quot; #&gt; [6] &quot;Courtesy Report&quot; #&gt; [7] &quot;Disorderly Conduct&quot; #&gt; [8] &quot;Drug Offense&quot; #&gt; [9] &quot;Drug Violation&quot; #&gt; [10] &quot;Embezzlement&quot; #&gt; [11] &quot;Family Offense&quot; #&gt; [12] &quot;Fire Report&quot; #&gt; [13] &quot;Forgery And Counterfeiting&quot; #&gt; [14] &quot;Fraud&quot; #&gt; [15] &quot;Gambling&quot; #&gt; [16] &quot;Homicide&quot; #&gt; [17] &quot;Human Trafficking (A), Commercial Sex Acts&quot; #&gt; [18] &quot;Human Trafficking, Commercial Sex Acts&quot; #&gt; [19] &quot;Juvenile Offenses&quot; #&gt; [20] &quot;Larceny Theft&quot; #&gt; [21] &quot;Liquor Laws&quot; #&gt; [22] &quot;Lost Property&quot; #&gt; [23] &quot;Malicious Mischief&quot; #&gt; [24] &quot;Miscellaneous Investigation&quot; #&gt; [25] &quot;Missing Person&quot; #&gt; [26] &quot;Motor Vehicle Theft&quot; #&gt; [27] &quot;Motor Vehicle Theft?&quot; #&gt; [28] &quot;Non-Criminal&quot; #&gt; [29] &quot;Offences Against The Family And Children&quot; #&gt; [30] &quot;Other&quot; #&gt; [31] &quot;Other Miscellaneous&quot; #&gt; [32] &quot;Other Offenses&quot; #&gt; [33] &quot;Prostitution&quot; #&gt; [34] &quot;Rape&quot; #&gt; [35] &quot;Recovered Vehicle&quot; #&gt; [36] &quot;Robbery&quot; #&gt; [37] &quot;Sex Offense&quot; #&gt; [38] &quot;Stolen Property&quot; #&gt; [39] &quot;Suicide&quot; #&gt; [40] &quot;Suspicious&quot; #&gt; [41] &quot;Suspicious Occ&quot; #&gt; [42] &quot;Traffic Collision&quot; #&gt; [43] &quot;Traffic Violation Arrest&quot; #&gt; [44] &quot;Vandalism&quot; #&gt; [45] &quot;Vehicle Impounded&quot; #&gt; [46] &quot;Vehicle Misplaced&quot; #&gt; [47] &quot;Warrant&quot; #&gt; [48] &quot;Weapons&quot; #&gt; [49] &quot;Weapons&quot; #&gt; [50] &quot;Weapons&quot; And now our last three crimes are all identical. 5.3.9 Multiple patterns | The vertical bar | special character allows us to check for multiple patterns. It essentially functions as “pattern A or Pattern B” with the | symbol replacing the word “or” (and making sure to not have any space between patterns.). To check our crimes for the word “Drug” or the word “Weapons” we could write “Drug|Weapon” which searches for “Drug” or “Weapons” in the text. grep(&quot;Drug|Weapons&quot;, crimes, value = TRUE) #&gt; [1] &quot;Drug Offense&quot; &quot;Drug Violation&quot; &quot;Weapons Carrying Etc&quot; #&gt; [4] &quot;Weapons Offence&quot; &quot;Weapons Offense&quot; 5.3.10 Parentheses () Parentheses act similar to the square brackets [] where we want everything inside but with parentheses the values must be in the proper order. grep(&quot;(Offense)&quot;, crimes, value = TRUE) #&gt; [1] &quot;Drug Offense&quot; &quot;Family Offense&quot; &quot;Juvenile Offenses&quot; #&gt; [4] &quot;Other Offenses&quot; &quot;Sex Offense&quot; &quot;Weapons Offense&quot; Running the above code returns the same results as if we didn’t include the parentheses. The usefulness of parentheses comes when combining it with the | symbol to be able to check “(X|Y) Z”), which says, “look for either X or Y which must be followed by Z”. Running just “(Offense)” returns values for multiple types of offenses. Let’s say we just care about Drug and Weapon Offenses. We can search for “Offense” normally and combine () and | to say “search for either the word”Drug\" or the word “Family” and they should be followed by the word “Offense”. grep(&quot;(Drug|Weapons) Offense&quot;, crimes, value = TRUE) #&gt; [1] &quot;Drug Offense&quot; &quot;Weapons Offense&quot; 5.3.11 Optional text ? The question mark indicates that the character immediately before the ? is optional. Let’s search for the term “offens” and add a ? at the end. This says search for the pattern “offen” and we expect an exact match for that pattern. And if the letter “s” follows “offen” return that too, but it isn’t required to be there. grep(&quot;Offens?&quot;, crimes, value = TRUE) #&gt; [1] &quot;Drug Offense&quot; #&gt; [2] &quot;Family Offense&quot; #&gt; [3] &quot;Juvenile Offenses&quot; #&gt; [4] &quot;Offences Against The Family And Children&quot; #&gt; [5] &quot;Other Offenses&quot; #&gt; [6] &quot;Sex Offense&quot; #&gt; [7] &quot;Weapons Offence&quot; #&gt; [8] &quot;Weapons Offense&quot; We can further combine it with () and | to get both spellings of Weapon Offense. grep(&quot;(Drug|Weapons) Offens?&quot;, crimes, value = TRUE) #&gt; [1] &quot;Drug Offense&quot; &quot;Weapons Offence&quot; &quot;Weapons Offense&quot; 5.4 Changing capitalization If you’re dealing with data where the only difference is capitalization (as is common in crime data) instead of using gsub() to change individual values, you can use the functions toupper() and tolower() to change every letter’s capitalization. These functions take as an input a vector of strings (or a column from a data.frame) and return those strings either upper or lowercase. toupper(crimes) #&gt; [1] &quot;ARSON&quot; #&gt; [2] &quot;ASSAULT&quot; #&gt; [3] &quot;BURGLARY&quot; #&gt; [4] &quot;CASE CLOSURE&quot; #&gt; [5] &quot;CIVIL SIDEWALKS&quot; #&gt; [6] &quot;COURTESY REPORT&quot; #&gt; [7] &quot;DISORDERLY CONDUCT&quot; #&gt; [8] &quot;DRUG OFFENSE&quot; #&gt; [9] &quot;DRUG VIOLATION&quot; #&gt; [10] &quot;EMBEZZLEMENT&quot; #&gt; [11] &quot;FAMILY OFFENSE&quot; #&gt; [12] &quot;FIRE REPORT&quot; #&gt; [13] &quot;FORGERY AND COUNTERFEITING&quot; #&gt; [14] &quot;FRAUD&quot; #&gt; [15] &quot;GAMBLING&quot; #&gt; [16] &quot;HOMICIDE&quot; #&gt; [17] &quot;HUMAN TRAFFICKING (A), COMMERCIAL SEX ACTS&quot; #&gt; [18] &quot;HUMAN TRAFFICKING, COMMERCIAL SEX ACTS&quot; #&gt; [19] &quot;JUVENILE OFFENSES&quot; #&gt; [20] &quot;LARCENY THEFT&quot; #&gt; [21] &quot;LIQUOR LAWS&quot; #&gt; [22] &quot;LOST PROPERTY&quot; #&gt; [23] &quot;MALICIOUS MISCHIEF&quot; #&gt; [24] &quot;MISCELLANEOUS INVESTIGATION&quot; #&gt; [25] &quot;MISSING PERSON&quot; #&gt; [26] &quot;MOTOR VEHICLE THEFT&quot; #&gt; [27] &quot;MOTOR VEHICLE THEFT?&quot; #&gt; [28] &quot;NON-CRIMINAL&quot; #&gt; [29] &quot;OFFENCES AGAINST THE FAMILY AND CHILDREN&quot; #&gt; [30] &quot;OTHER&quot; #&gt; [31] &quot;OTHER MISCELLANEOUS&quot; #&gt; [32] &quot;OTHER OFFENSES&quot; #&gt; [33] &quot;PROSTITUTION&quot; #&gt; [34] &quot;RAPE&quot; #&gt; [35] &quot;RECOVERED VEHICLE&quot; #&gt; [36] &quot;ROBBERY&quot; #&gt; [37] &quot;SEX OFFENSE&quot; #&gt; [38] &quot;STOLEN PROPERTY&quot; #&gt; [39] &quot;SUICIDE&quot; #&gt; [40] &quot;SUSPICIOUS&quot; #&gt; [41] &quot;SUSPICIOUS OCC&quot; #&gt; [42] &quot;TRAFFIC COLLISION&quot; #&gt; [43] &quot;TRAFFIC VIOLATION ARREST&quot; #&gt; [44] &quot;VANDALISM&quot; #&gt; [45] &quot;VEHICLE IMPOUNDED&quot; #&gt; [46] &quot;VEHICLE MISPLACED&quot; #&gt; [47] &quot;WARRANT&quot; #&gt; [48] &quot;WEAPONS CARRYING ETC&quot; #&gt; [49] &quot;WEAPONS OFFENCE&quot; #&gt; [50] &quot;WEAPONS OFFENSE&quot; tolower(crimes) #&gt; [1] &quot;arson&quot; #&gt; [2] &quot;assault&quot; #&gt; [3] &quot;burglary&quot; #&gt; [4] &quot;case closure&quot; #&gt; [5] &quot;civil sidewalks&quot; #&gt; [6] &quot;courtesy report&quot; #&gt; [7] &quot;disorderly conduct&quot; #&gt; [8] &quot;drug offense&quot; #&gt; [9] &quot;drug violation&quot; #&gt; [10] &quot;embezzlement&quot; #&gt; [11] &quot;family offense&quot; #&gt; [12] &quot;fire report&quot; #&gt; [13] &quot;forgery and counterfeiting&quot; #&gt; [14] &quot;fraud&quot; #&gt; [15] &quot;gambling&quot; #&gt; [16] &quot;homicide&quot; #&gt; [17] &quot;human trafficking (a), commercial sex acts&quot; #&gt; [18] &quot;human trafficking, commercial sex acts&quot; #&gt; [19] &quot;juvenile offenses&quot; #&gt; [20] &quot;larceny theft&quot; #&gt; [21] &quot;liquor laws&quot; #&gt; [22] &quot;lost property&quot; #&gt; [23] &quot;malicious mischief&quot; #&gt; [24] &quot;miscellaneous investigation&quot; #&gt; [25] &quot;missing person&quot; #&gt; [26] &quot;motor vehicle theft&quot; #&gt; [27] &quot;motor vehicle theft?&quot; #&gt; [28] &quot;non-criminal&quot; #&gt; [29] &quot;offences against the family and children&quot; #&gt; [30] &quot;other&quot; #&gt; [31] &quot;other miscellaneous&quot; #&gt; [32] &quot;other offenses&quot; #&gt; [33] &quot;prostitution&quot; #&gt; [34] &quot;rape&quot; #&gt; [35] &quot;recovered vehicle&quot; #&gt; [36] &quot;robbery&quot; #&gt; [37] &quot;sex offense&quot; #&gt; [38] &quot;stolen property&quot; #&gt; [39] &quot;suicide&quot; #&gt; [40] &quot;suspicious&quot; #&gt; [41] &quot;suspicious occ&quot; #&gt; [42] &quot;traffic collision&quot; #&gt; [43] &quot;traffic violation arrest&quot; #&gt; [44] &quot;vandalism&quot; #&gt; [45] &quot;vehicle impounded&quot; #&gt; [46] &quot;vehicle misplaced&quot; #&gt; [47] &quot;warrant&quot; #&gt; [48] &quot;weapons carrying etc&quot; #&gt; [49] &quot;weapons offence&quot; #&gt; [50] &quot;weapons offense&quot; "],
["webscraping-with-rvest.html", "6 Webscraping with rvest 6.1 Scraping one page 6.2 Cleaning the webscraped data 6.3 Fixing names", " 6 Webscraping with rvest You may come across data online that are relevant to your interests or research (for example, past students at Penn have scraped data from sex offender registries and sporting information from Wikipedia). Not all online data is in a tidy, downloadable format such as a .csv or .rda file. Here we’ll learn how to grab data from a webpage - as our example we’ll be scraping data on movie ticket sales. For our purposes we will be using the package rvest. This package makes it relatively easy to scrape data from websites, especially when that data is already in a table on the page as our data will be. If you haven’t done so before, make sure to install rvest. install.packages(&quot;rvest&quot;) And every time you start R, if you want to use rvest you must tell R so by using library(). library(rvest) #&gt; Loading required package: xml2 We will be scraping movie ticket data from the website The-Numbers. This site has daily information on how much money each movie in theaters made that day. The data includes the name of the movie, the number of theaters it played in, how much it made that day, how much it made since it started playing, and how many days it has been in theaters. Conveniently, this is all found in a single table on that page. Here is a screenshot of data from July 4th, 2018 and here is a link to that page. 6.1 Scraping one page In later lessons we’ll learn how to scrape an entire year of data from this site. For now, we’ll focus on just getting data from July 4th, 2018. The first step to scraping a page is to read in that page’s information to R using the function read_html() from the rvest package. The input for the () is the URL of the page we want to scrape. In a later lesson, we will manipulate this URL to be able to scrape data from many pages. read_html(&quot;http://www.the-numbers.com/box-office-chart/daily/2018/07/04&quot;) #&gt; {xml_document} #&gt; &lt;html&gt; #&gt; [1] &lt;head&gt;\\n&lt;!-- Global site tag (gtag.js) - Google Analytics --&gt;&lt;script ... #&gt; [2] &lt;body&gt;\\n\\r\\n&lt;script&gt;\\r\\n window.fbAsyncInit = function() {\\r\\n F ... When running the above code, it returns an XML Document. The rvest package is well suited for interpreting this and turning it into something we already know how to work with. To be able to work on this data, we need to save the output of read_html() into an object which we’ll call “movie_data” since that is our end goal. movie_data &lt;- read_html(&quot;http://www.the-numbers.com/box-office-chart/daily/2018/07/04&quot;) We now need to select only a small part of page which has the relevant information - in this case the data in the table. Right click somewhere in the table and then click “Inspect Element”. This will open up a tab on the screen that allows you to see the building blocks on that page. When you move your cursor over parts of this tab, the parts of the page it relates to will be highlighted in blue. We want want all of the data from the table so move your cursor to where it starts with “&lt;table”. Doing so will highlight the entire table in blue. Right click the “table” area and click Copy then CSS Selector. That will copy what we need. Essentially this says which part of the page is the table and allows us grab only that part from the XML Document we made earlier. We will use the function html_nodes() to grab the part of the page (based on the CSS selectors) that we want. The input for this function is first the object made from read_html() (which we called “movie_data”) and then we can paste the text we copied from the website (putting it in quotes). Note that when doing this in Google Chrome, you follow the same steps except click “Copy selector” rather than “CSS Selector”. The value copied also differs between Chrome and Firefox though the result is the same in our code. movie_data &lt;- html_nodes(movie_data, &quot;#page_filling_chart &gt; center:nth-child(2) &gt; table&quot;) Since we are getting data from a table, we need to tell rvest that the format of the scraped data is a table. We do with using html_table() and our input in the () is the the object made in the function html_nodes(). movie_data &lt;- html_table(movie_data) By default, rvest returns a list. We prefer to work with data.frames so we’re going to grab the first element in this list which is the data we want. Unlike with a vector or a data.frame, we can’t use normal square bracket notation [] for lists. Instead we need double square brackets [[]]. movie_data &lt;- movie_data[[1]] Take a look at the webpage and compare it to the data set you’ve now created. All the values should now match. head(movie_data) Movie Distributor Gross Change 1 1 (1) Jurassic World: Fallen Kingdom Universal $11,501,395 -3% 2 2 (2) Incredibles 2 Walt Disney $9,646,015 -6% 3 3 new The First Purge Universal $9,305,875 4 4 (3) Sicario: Day of the Soldado Sony Pictures $2,577,639 n/c 5 5 (4) Uncle Drew Lionsgate $2,177,946 -13% 6 6 (5) Ocean’s 8 Warner Bros. $2,093,164 +14% Thtrs. Per Thtr. Total Gross Days 1 4,485 $2,564 $297,672,320 13 2 4,410 $2,187 $468,190,380 20 3 3,031 $3,070 $9,305,875 1 4 3,055 $844 $26,320,689 6 5 2,742 $794 $21,729,447 6 6 3,426 $611 $120,300,214 27 tail(movie_data) Movie Distributor Gross Change Thtrs. 43 - (-) Beast Roadside Attractions $1,332 -18% 14 44 - (-) On Chesil Beach Bleecker Street $1,305 -2% 10 45 - (-) Let The Sunshine In Sundance Selects $1,098 +104% 4 46 - (-) Super Troopers 2 20th Century Fox $718 -44% 21 47 - (-) Summer of 67 Self Distributed $450 +254% 1 48 - (-) Chappaquiddick Entertainment Studi… $445 -44% 6 Per Thtr. Total Gross Days 43 $95 $798,923 55 44 $131 $733,899 48 45 $275 $855,165 69 46 $34 $30,608,780 76 47 $450 $6,196 6 48 $74 $17,387,545 90 We have now successfully scraped a website! The “movie_data” object is a data.frame object that we are familiar with from looking at the Chicago and UCR data so we can subset and manipulate it like we’ve done before. 6.2 Cleaning the webscraped data Let’s check what the max value is in the “Gross” column which says how much the movie made on that day. max(movie_data$Gross) #&gt; [1] &quot;$9,646,015&quot; So the most money a movie made is about $9.6 million. Is that right? We can check either the website or the data using View() to see if there are any more successful movies (conveniently, the table is already sorted by how much the movie made). No! The most successful movie made $11.5 million, not $9.5 million. So why did max() say the top value is 9.6 million? Let’s take another look at the values in the “Gross” column. head(movie_data$Gross) #&gt; [1] &quot;$11,501,395&quot; &quot;$9,646,015&quot; &quot;$9,305,875&quot; &quot;$2,577,639&quot; &quot;$2,177,946&quot; #&gt; [6] &quot;$2,093,164&quot; The values are not actually numeric type. If a value is numeric in R it would only have numbers, not dollar signs or commas like we see here. It also would not be in quotes, R’s way of saying “this value is a character type”. So what we have to do is turn these values into numeric type. The way to convert a character type into a numeric type is the function as.numeric(). Let’s take a look at the very first value in that column, “$11,501,395”. as.numeric(&quot;$11,501,395&quot;) #&gt; Warning: NAs introduced by coercion #&gt; [1] NA Running as.numeric() on that value returns NA because it doesn’t know how to handle the dollar sign and comma. If we remove those, it will work as expected. as.numeric(&quot;11501395&quot;) #&gt; [1] 11501395 We can use gsub() which we learned earlier in Chapter 5 to delete the dollar sign and commas from our values. After that we can use as.numeric() to fix that column. (alternatively we could use the function parse_number() from the readr package, but this is a good example of using regular expressions) Remember that the syntax of gsub() is gsub(\"find\", \"replace\", string_to_fix) First we will remove the comma. We want to use gsub() to find all commas and replace it with nothing (deleting it). To indicate nothing we just use quotes without anything in it. gsub(&quot;,&quot;, &quot;&quot;, &quot;$11,501,395&quot;) #&gt; [1] &quot;$11501395&quot; Now to do the dollar sign. Remember that in gsub() and grep() the $ is a special character indicating that whatever precedes it is the last character. To tell R we want the $ literally, we use two backslashes before it - this is how to deal with all special characters, not just dollar signs. gsub(&quot;\\\\$&quot;, &quot;&quot;, &quot;$11,501,395&quot;) #&gt; [1] &quot;11,501,395&quot; Each of these gsub()s work alone. We need to combine them to remove both the dollar sign and the comma. We have two choices for this. The first choice is to use the | operator which tells gsub() to replace the value on the left or right side of the | symbol (or both if both are present). gsub(&quot;,|\\\\$&quot;, &quot;&quot;, &quot;$11,501,395&quot;) #&gt; [1] &quot;11501395&quot; The second choice is to do them separately and save the results into an object that we use in the second gsub(). Let’s first save our value \"“$11,501,395” into an object we call “x” and then run both gsub() statements we wrote earlier, using “x” (without quotes since it is an object) as our value and saving the results back into “x”. For those not very comfortable with regular expressions, this is the better way of doing it as you can deal with simpler gsub() expressions than above. x &lt;- &quot;$11,501,395&quot; x &lt;- gsub(&quot;,&quot;, &quot;&quot;, x) x &lt;- gsub(&quot;\\\\$&quot;, &quot;&quot;, x) x #&gt; [1] &quot;11501395&quot; Finally we can use as.numeric() on the result to turn it into a numeric type. as.numeric(x) #&gt; [1] 11501395 Now we have code that works on a single value, let’s do it for the entire “Gross” column and turn it numeric. movie_data$Gross &lt;- gsub(&quot;,|\\\\$&quot;, &quot;&quot;, movie_data$Gross) movie_data$Gross &lt;- as.numeric(movie_data$Gross) We can look at the first 6 rows in that column and check the max value to see if our code worked. head(movie_data$Gross) #&gt; [1] 11501395 9646015 9305875 2577639 2177946 2093164 max(movie_data$Gross) #&gt; [1] 11501395 6.3 Fixing names If we run names() on our data we will see that there is a column with a space in the name “Total Gross”. This is an issue because it is difficult to select a function with a space in the name. names(movie_data) #&gt; [1] &quot;&quot; &quot;&quot; &quot;Movie&quot; &quot;Distributor&quot; &quot;Gross&quot; #&gt; [6] &quot;Change&quot; &quot;Thtrs.&quot; &quot;Per Thtr.&quot; &quot;Total Gross&quot; &quot;Days&quot; Trying to do so using the dollar sign notation causes an error. head(movie_data$Total Gross) #&gt; Error: &lt;text&gt;:1:23: unexpected symbol #&gt; 1: head(movie_data$Total Gross #&gt; ^ To select it we need to put the name in between tick marks `` so R knows to include the value after the space as part of the column name. head(movie_data$`Total Gross`) #&gt; [1] &quot;$297,672,320&quot; &quot;$468,190,380&quot; &quot;$9,305,875&quot; &quot;$26,320,689&quot; #&gt; [5] &quot;$21,729,447&quot; &quot;$120,300,214&quot; An alternative is to change the column name using both names() and gsub() together to remove the space. Running names() returns the name of every column. If we assign something to the names() it will actually change the column names to whatever we assign it. What we want to do is use gsub() to replace all spaces in column names with something else - either with nothing or a value R understands as part of a name such as an underscore. gsub(&quot; &quot;, &quot;&quot;, names(movie_data)) #&gt; [1] &quot;&quot; &quot;&quot; &quot;Movie&quot; &quot;Distributor&quot; &quot;Gross&quot; #&gt; [6] &quot;Change&quot; &quot;Thtrs.&quot; &quot;PerThtr.&quot; &quot;TotalGross&quot; &quot;Days&quot; If we assign the results of that gsub() to the names(), it will change the names to the values resulting from gsub(). names(movie_data) &lt;- gsub(&quot; &quot;, &quot;&quot;, names(movie_data)) We can check to make sure it worked by again running names(). names(movie_data) #&gt; [1] &quot;&quot; &quot;&quot; &quot;Movie&quot; &quot;Distributor&quot; &quot;Gross&quot; #&gt; [6] &quot;Change&quot; &quot;Thtrs.&quot; &quot;PerThtr.&quot; &quot;TotalGross&quot; &quot;Days&quot; We have now scraped a single page of movie data. In the next lessons we will learn how to scrape multiple pages. 6.3.1 Exercises Turn the columns “Thtrs.” and “TotalGross” into numeric type. What was the average number of theaters that a movie played in? How many more theaters did the top movie (by number of theaters) play in than average? How many fewer theaters did the bottom movie (by number of theaters) play in than average? How big is the difference in theaters as the mean number of theaters played in and the median? Which should we use? "],
["functions.html", "7 Functions 7.1 A simple function 7.2 Adding parameters 7.3 Making a function to scrape movie data", " 7 Functions So far we have been writing code to handle specific situations such as subsetting a single data.frame. In cases where you want to reuse the code it is unwise to simply copy and paste the code and make minor changes to handle the new data. Instead we want something that is able to take multiple values and perform the same action (subset, aggregate, make a plot, webscrape, etc) on those values. Code where you can input a value (such as a data.frame) and some (often optional) instructions on how to handle that data, and have the code run on the value is called a function. We’ve used other people’s function before, such as c() or mean() or grep(). Think of it like a stapler - you put the paper in a push down and it staples the paper together. It doesn’t matter what papers you are using, it always staples them together. If you needed to buy a new stapler every time you needed to staple something you’d quickly have way too many staples (and waste a bunch of money). An important benefit is that you can use this function again and again to help solve other problems. If, for example, you have code that cleans data from Philadelphia’s crime data set, if you wanted to use it for Chicago’s crime data, making a single function is much easier (to read and to fix if there is an issue) than copying the code. If you wanted to use it for 20 cities, copy and pasting code quickly becomes a terrible solution - functions work much better. If you did copy and paste 20 times and you found a bug, then you’d have to fix the bug 20 times. With a function you would change the code once. 7.1 A simple function We’ll start with a simple function that takes a number and returns that number plus the value 2. add_2 &lt;- function(number) { number &lt;- number + 2 return(number) } The syntax (how we write it) of a function is function_name &lt;- function(parameters) { code return(output) } There are five essential parts of a function function_name - This is just the name we give to the function. It can be anything but, like when making other objects, call it something where it is easy to remember what it does. parameters - Here is where we say what goes into the function. In most cases you will want to put some data in and expect something new out. For example, for the function mean() you put in a vector of numbers in the () section and it returns the mean of those numbers. Here is also where you can put any options to affect how the code is run. code - This is the code you write to do the thing you want the function to do. In the above example our code is number &lt;- number + 2. For any number inputted, our code adds 2 to it and saves it back into the object number. return - This is something new in this class, here you use return() and inside the () you put the object you want to be outputted. In our example we have “number” inside the return() as that’s what we want to come out of the function. It is not always necessary to end your function with return() but is highly recommended to make sure you’re outputting what it is you want to output. If you save the output of a function (such as by `x &lt;- mean(1:3)) it will save the output to the variable assigned. Otherwise it will print out the results in the console. The final piece is the structure of your function. After the function_name (whatever it is you call it) you always need the text “&lt;- function()” where the parameters (if any) are in the (). After the closing parentheses put a “{” and at the very end of the function, after the return(), close those squiggly brackets with a “}”. The “&lt;- function()” tells R that you are making a function rather than some other type of object. And the “{” and “}” tell R that all the code in between are part of that function. Our function here adds 2 to any number we input. add_2(2) #&gt; [1] 4 add_2(5) #&gt; [1] 7 7.2 Adding parameters Let’s add a single parameter which multiplies the result by 5 if selected. add_2 &lt;- function(number, times_5 = FALSE) { number &lt;- number + 2 return(number) } Now we have added a parameter called “time_5” to the () part of the function and set it the be FALSE by default. Right now it doesn’t do anything so we need to add code to say what happens if it is TRUE (remember in R true and false must always be all capital letters). add_2 &lt;- function(number, times_5 = FALSE) { number &lt;- number + 2 if (times_5 == TRUE) { number &lt;- number * 5 } return(number) } Now our code says if the parameter “times_5” is TRUE, then do the thing in the squiggly brackets {} below. Note that we use the same squiggly brackets as when making the entire function. That just tells R that the code in those brackets belong together. Let’s try out our function. add_2(2) #&gt; [1] 4 It returns 4, as expected. Since the parameter “times_t” is defaulted to FALSE, we don’t need to specify that parameter if we want it to stay FALSE. When we don’t tell the function that we want it to be TRUE, the code in our “if statement” doesn’t run. When we set “times_t” to TRUE, it runs that code. add_2(2, times_5 = TRUE) #&gt; [1] 20 7.3 Making a function to scrape movie data In 6.1 we wrote some code to scrape data from the website The-Numbers for a single day. We are going to turn that code into a function here. The benefit is that our input to the function will be a date and then it returns the scraped data for that date. If we want multiple dates (and for webscraping you usually do), we just change the date we input without changing the code at all. We used the rvest package so we need to tell R want to use it again. library(rvest) #&gt; Loading required package: xml2 Let’s start by writing a shell of the function - everything but the code. We can call it “scrape_movie_data” (though any name would work), add in the “&lt;- function()” and put “date” (without quotes) in the () as our input for the function is a date. We want the function to return the movie data for that date so we include return(movie_data). And don’t forget the “{” after the end of the function() and “}” at the very end of the function. scrape_movie_data &lt;- function(date) { return(movie_data) } Now we need to add the code that takes the date, scrapes the website, and saves that data into an object called “movie_data”. Since we have the code from an earlier lesson, we can copy and paste that code into the function and make a small change to get a working function. scrape_movie_data &lt;- function(date) { movie_data &lt;- read_html(&quot;http://www.the-numbers.com/box-office-chart/daily/2018/07/04&quot;) movie_data &lt;- html_nodes(movie_data, &quot;#page_filling_chart &gt; center:nth-child(2) &gt; table&quot;) movie_data &lt;- html_table(movie_data) movie_data &lt;- movie_data[[1]] return(movie_data) } The part inside the () of read_html() is the URL of the page we want to scrape. This is the part of the function that will change based on our input. Specifically, just the date will change, the rest of the URL up to the date section stays the same every time (we know this just by clicking through dates on the website and seeing how the URL changes). We want to make it so the date inputted is the date used in the URL of the page to scrape. So let’s split up the URL into two pieces - the part that stays constant and the part that changes. Constant - “http://www.the-numbers.com/box-office-chart/daily/” Changes - “2018/07/04” And now let’s make variables with these values. Constant &lt;- &quot;http://www.the-numbers.com/box-office-chart/daily/&quot; Changes &lt;- &quot;2018/07/04&quot; We can use paste() to combine these two and set the parameter sep to \"\" so there are no spaces between the url and the date (the function paste0() is the same as paste() but defaults set to \"\" so we could use that if we wanted). We will save the result of paste() as an object called “url_date” but it doesn’t matter what we name it. paste(Constant, Changes, sep = &quot;&quot;) #&gt; [1] &quot;http://www.the-numbers.com/box-office-chart/daily/2018/07/04&quot; Inside our function code we need to make the “Constant” variable but let’s rename it “url” since that better describes what it is. Since the date is what is inputted into the function, we don’t need to make that variable. Our paste() function is the same as above but with with these new variable names - since the parameter inputted is called “date” that is the variable name we need to include in the paste(). And we can call it a new name - “url_date” - in the code just to simplify things. Then put this variable in the () of read_html() and it will go to the proper page based on the date we input. scrape_movie_data &lt;- function(date) { url &lt;- &quot;http://www.the-numbers.com/box-office-chart/daily/&quot; url_date &lt;- paste(url, date, sep = &quot;&quot;) movie_data &lt;- read_html(url_date) movie_data &lt;- html_nodes(movie_data, &quot;#page_filling_chart &gt; center:nth-child(2) &gt; table&quot;) movie_data &lt;- html_table(movie_data) movie_data &lt;- movie_data[[1]] return(movie_data) } Now we can try it for a new date, let’s say July 4th, 2015. We will save it in the object “july_2015” just to avoid it printing out every single row when the function is done. july_2015 &lt;- scrape_movie_data(&quot;2015/7/4&quot;) head(july_2015) #&gt; Movie Distributor Gross Change Thtrs. #&gt; 1 1 (2) Jurassic World Universal $8,539,045 +31% 3,737 #&gt; 2 2 (1) Inside Out Walt Disney $8,209,548 +19% 4,158 #&gt; 3 3 (-) Terminator: Genisys Paramount Pictures $7,883,583 3,758 #&gt; 4 4 (5) Ted 2 Universal $2,896,320 -21% 3,448 #&gt; 5 5 (-) Magic Mike XXL Warner Bros. $2,512,969 3,355 #&gt; 6 6 (6) Max Warner Bros. $1,891,378 +28% 2,870 #&gt; Per Thtr. Total Gross Days #&gt; 1 $2,285 $547,667,605 23 #&gt; 2 $1,974 $236,889,029 16 #&gt; 3 $2,098 $34,029,282 4 #&gt; 4 $840 $54,725,070 9 #&gt; 5 $749 $23,815,016 4 #&gt; 6 $659 $23,323,044 9 In the next lesson we’ll use “for loops” to scrape several years of data using the function we just made. "],
["for-loops.html", "8 For loops 8.1 Basic for loops 8.2 Scraping multiple days of movie data", " 8 For loops We will often want to perform the same task on a number of different items, such as cleaning every column in a data set. On effective way to do this is through “for loops”. Earlier in this course we learned how to scrape a website containing information on movies. We did so for a single date, if we wanted to get movie data for a week or a years-worth of data, typing out each date would be excessively slow, even with the function we made in Section @ref(#movie_function). In this lesson we will use a for loop to scrape movie data for a an entire year of dates. 8.1 Basic for loops We’ll start with a simple example, making R print the numbers 1-10. for (i in 1:10) { print(i) } #&gt; [1] 1 #&gt; [1] 2 #&gt; [1] 3 #&gt; [1] 4 #&gt; [1] 5 #&gt; [1] 6 #&gt; [1] 7 #&gt; [1] 8 #&gt; [1] 9 #&gt; [1] 10 The basic concept of a for loop is you have some code that you need to run many times with slight changes to a value or values in the code - somewhat like a function. Like a function, all the code you want to use goes in between the { and } squiggly brackets. And you loop through all the values you specify - meaning the code runs once for each of those values. Let’s look closer at the (i in 1:10). The i is simply a placeholder object which takes the value 1:10 each iteration of the loop. It’s not necessary to call it i but that is convention in programming to do so. It takes the value of whatever follows the in which can range from a vector of strings to numbers to lists of data.frames. Especially when you’re an early learner of R it could help to call the i something informative to you about what value it has. Let’s go through a few examples with different names for i and different values it is looping through. for (a_number in 1:10) { print(a_number) } #&gt; [1] 1 #&gt; [1] 2 #&gt; [1] 3 #&gt; [1] 4 #&gt; [1] 5 #&gt; [1] 6 #&gt; [1] 7 #&gt; [1] 8 #&gt; [1] 9 #&gt; [1] 10 animals &lt;- c(&quot;cat&quot;, &quot;dog&quot;, &quot;gorilla&quot;, &quot;buffalo&quot;, &quot;lion&quot;, &quot;snake&quot;) for (animal in animals) { print(animal) } #&gt; [1] &quot;cat&quot; #&gt; [1] &quot;dog&quot; #&gt; [1] &quot;gorilla&quot; #&gt; [1] &quot;buffalo&quot; #&gt; [1] &quot;lion&quot; #&gt; [1] &quot;snake&quot; Now let’s make our code a bit more complicated, adding the number 2 every loop. for (a_number in 1:10) { print(a_number + 2) } #&gt; [1] 3 #&gt; [1] 4 #&gt; [1] 5 #&gt; [1] 6 #&gt; [1] 7 #&gt; [1] 8 #&gt; [1] 9 #&gt; [1] 10 #&gt; [1] 11 #&gt; [1] 12 We’re keeping the results inside of print() since for loops do not print the results by default. Let’s try combining this with some subsetting using square bracket notation []. We will look through every value in “numbers” a vector we will make with the values 1:10 and replace each value with it’s value plus 2. The object we’re looping through is “numbers”. But we’re actually looping through every index it has, hence the 1:length(numbers). That is saying, i takes the value of each index in “numbers” which is useful when we want to change that element. length(numbers) finds how long the vector “numbers” is (were this a data.frame we could use nrow()) to find how many elements it has. In the code we take the value at each index numbers[i] and add 2 to it. numbers &lt;- 1:10 for (i in 1:length(numbers)) { numbers[i] &lt;- numbers[i] + 2 } numbers #&gt; [1] 3 4 5 6 7 8 9 10 11 12 We can also include functions we made in for loops. Here’s a function we made last lesson which adds 2 to each inputted number. add_2 &lt;- function(number) { number &lt;- number + 2 return(number) } Let’s put that in the loop. for (i in 1:length(numbers)) { numbers[i] &lt;- add_2(numbers[i]) } numbers #&gt; [1] 5 6 7 8 9 10 11 12 13 14 8.2 Scraping multiple days of movie data Below is the function copied from the Section (#movie_function) where we made a function that took a single date and scraped the site The-Numbers for movie ticket sales data for that day. If we wanted to get data from multiple days, we would need to run the function multiple times. Here we will use a for loop to get data for an entire year. scrape_movie_data &lt;- function(date) { url &lt;- &quot;http://www.the-numbers.com/box-office-chart/daily/&quot; url_date &lt;- paste(url, date, sep = &quot;&quot;) movie_data &lt;- read_html(url_date) movie_data &lt;- html_nodes(movie_data, &quot;#page_filling_chart &gt; center:nth-child(2) &gt; table&quot;) movie_data &lt;- html_table(movie_data) movie_data &lt;- movie_data[[1]] return(movie_data) } With any for loop you need to figure out what is going to be changing, in this case it is the date. And since we want a year’s worth of movie data, we need to make an object with an entire year of dates. We can use the function seq() in association with the lubridate package to make that object. seq() produces a vector of every value between two points (either numbers or Dates) based on the increments we specify, in this case daily. We want a year of data, from January 1th, 2018 to December 31th, 2018 so those will be our start and end points. And we want Dates returned so we will use the ymd() function from lubridate to turn those values into dates. library(lubridate) #&gt; #&gt; Attaching package: &#39;lubridate&#39; #&gt; The following object is masked from &#39;package:base&#39;: #&gt; #&gt; date year_of_dates &lt;- seq(ymd(&quot;2018-1-1&quot;), ymd(&quot;2018-12-31&quot;), by = &quot;days&quot;) Check the first 6 values to see if it did it right. head(year_of_dates) #&gt; [1] &quot;2018-01-01&quot; &quot;2018-01-02&quot; &quot;2018-01-03&quot; &quot;2018-01-04&quot; &quot;2018-01-05&quot; #&gt; [6] &quot;2018-01-06&quot; It worked. However, there is one important problem. We need to make sure the url is exactly correct for the page we want to scrape. In the object “year_of_dates” it uses “-”; in the website we are scraping, it uses “/”. It may seem like a minor point but if we try to use “-” instead of “/” we will have an error. Luckily, we know enough gsub() to quickly replace all “-” with “/”. year_of_dates &lt;- gsub(&quot;-&quot;, &quot;/&quot;, year_of_dates) Now we can write the for loop to go through every single date in “year_of_dates” and use the function scrape_movie_data we made to scrape data for that date. for (date in year_of_dates) { movie_data &lt;- scrape_movie_data(date) } Don’t run this yet because there are two issues remaining. The first is that if we run it as it is, it will will scrape the website for each date, save the results into the object “movie_data” and keep overwriting this object for each date. We need to create an object that doesn’t get overwritten every iteration of the loop. A solution is to create an object outside of the for loop and every time the for loop iterates (in our case runs for a single date) we add the data scraped that time to this object. I prefer to call the object outside the loop something_final and the object that gets overwritten something_temp, where “something” is a descriptive word for the data. In this case we will use “movie_data_final” and “movie_data_temp”. We start by creating the object “movie_data_final” and saying it gets the value data.frame(). That’s just a way to say it is a data.frame type but is empty (hence the () being empty). Now we need some way to add the “movie_data_temp” data to “movie_data_final” for each date. We will use the function rbind() which allow us to combine two data.frames together. Think of it like the c() function but for data.frames. So every iteration of the loop we scrape a single date then add those results to the “movie_data_final” object. movie_data_final &lt;- data.frame() for (date in year_of_dates) { movie_data_temp &lt;- scrape_movie_data(date) movie_data_final &lt;- rbind(movie_data_final, movie_data_temp) } The second issue is that there is no variable indicating what day it that was scraped. When adding many days together, we need a variable to be able to distinguish the day. This can easily be fixed by making a column in the data which says the date. When we used gsub() on “year_of_dates” we changed it from a Date type to a character type. Let’s change it back in the new variable we made by putting it in ymd() before saving to to the column. movie_data_final &lt;- data.frame() for (date in year_of_dates) { movie_data_temp &lt;- scrape_movie_data(date) movie_data_temp$date &lt;- ymd(date) movie_data_final &lt;- rbind(movie_data_final, movie_data_temp) } Now we are ready to run the for loop and get movie data for an entire year. "],
["reading-and-writing-data.html", "9 Reading and Writing Data 9.1 Reading Data into R 9.2 Writing Data", " 9 Reading and Writing Data So far in these lessons we’ve used data from a number of sources but which all came as .rda files which is the standard R data format. Many data sets, particularly older government data, will not come as .rda file but rather as Excel, Stata, SAS, SPSS, or fixed-width ASCII files. In this brief lesson we’ll cover how to read these formats into R as well as how to save data into these formats. Since many criminologists do not use R, it is important to be able to save the data in the language they use to be able to collaborate with them. Fixed-width ASCII files are not very common and require a bit more effort than the other formats so we’ll leave those until Chapter @ref(#nibrs) where we discuss in detail how to use this type of data. In this lesson we’ll use data about officer-involved shootings. In Chapter @ref(#ois_graphs) we’ll return to this data set to practice graphing. 9.1 Reading Data into R 9.1.1 R As we’ve seen earlier, to read in data with a .rda or .rdata extension you use the function load() with the file name (including the extension) in quotation marks inside of the parentheses. This loads the data into R and calls the object the name it was when it was saved. Therefore we do not need to give it a name ourselves. For each of the other types of data we’ll need to assign a name to the data we’re reading in so it has a name. Whereas we’ve done x &lt;- 2 to say x gets the value of 2, now we’d do x &lt;- DATA where DATA is the way to load in the data and x will get the entire data.frame read in. 9.1.2 Excel To read in Excel files, those ending in .csv, we can use the function read_csv() from the package readr (the function read.csv() is included in R by default so doesn’t require any packages but is far slower than read_csv() so we will not use it). install.packages(&quot;readr&quot;) library(readr) The input in the () is the file name ending in “.csv”. As it is telling R to read a file on the computer, the whole name must be in quotes. Unlike loading an .rda file using load(), there is no name for the object that gets read in so we must assign the data a name. We can using “shootings” as it’s relatively descriptive and easy for us to write. shootings &lt;- read_csv(&quot;data/fatal-police-shootings-data.csv&quot;) #&gt; Parsed with column specification: #&gt; cols( #&gt; id = col_double(), #&gt; name = col_character(), #&gt; date = col_date(format = &quot;&quot;), #&gt; manner_of_death = col_character(), #&gt; armed = col_character(), #&gt; age = col_double(), #&gt; gender = col_character(), #&gt; race = col_character(), #&gt; city = col_character(), #&gt; state = col_character(), #&gt; signs_of_mental_illness = col_logical(), #&gt; threat_level = col_character(), #&gt; flee = col_character(), #&gt; body_camera = col_logical() #&gt; ) read_csv() also reads in data to an object called a tibble which is very similar to a data.frame but has some differences in displaying the data. If we run head() on the data it doesn’t show all columns. This is useful to avoid accidentally printing out a massive amounts of columns. head(shootings) #&gt; # A tibble: 6 x 14 #&gt; id name date manner_of_death armed age gender race city #&gt; &lt;dbl&gt; &lt;chr&gt; &lt;date&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 3 Tim ~ 2015-01-02 shot gun 53 M A Shel~ #&gt; 2 4 Lewi~ 2015-01-02 shot gun 47 M W Aloha #&gt; 3 5 John~ 2015-01-03 shot and Taser~ unar~ 23 M H Wich~ #&gt; 4 8 Matt~ 2015-01-04 shot toy ~ 32 M W San ~ #&gt; 5 9 Mich~ 2015-01-04 shot nail~ 39 M H Evans #&gt; 6 11 Kenn~ 2015-01-04 shot gun 18 M W Guth~ #&gt; # ... with 5 more variables: state &lt;chr&gt;, signs_of_mental_illness &lt;lgl&gt;, #&gt; # threat_level &lt;chr&gt;, flee &lt;chr&gt;, body_camera &lt;lgl&gt; We can convert it to a data.frame using the function as.data.frame() though that isn’t strictly necessary since tibbles and data.frames operate so similarly. shootings &lt;- as.data.frame(shootings) 9.1.3 Stata For the remaining three data types we’ll use the package haven. install.packages(&quot;haven&quot;) library(haven) haven follows the same syntax for each data type and is the same as with read_csv() - for each data type we simply include the file name (in quotes, with the extension) and designate an name to get the data. Like with read_csv() the functions to read data through haven all start with read_ and end with the extension you’re reading in. read_dta() - Stata file, extension “dta” read_sas() - SAS file, extension “sas” read_sav() - SPSS file, extension “sav” To read the data as a .dta format we can copy the code to read it as a .csv but change .csv to .dta. shootings &lt;- read_dta(&quot;data/fatal-police-shootings-data.dta&quot;) Since we called this new data “shootings”, R overwrote that object (without warning us!). This is useful because we often want to subset or aggregate data and call it by the same name to avoid making too many objects to keep track of, but watch out for accidentally overwriting an object without noticing! 9.1.4 SAS shootings &lt;- read_sas(&quot;data/fatal-police-shootings-data.sas&quot;) 9.1.5 SPSS shootings &lt;- read_sav(&quot;data/fatal-police-shootings-data.sav&quot;) 9.2 Writing Data When we’re done with a project (or an important part of a project) or when we need to send data to someone, we need to save the data we’ve worked on in a suitable format. For each format, we are saving the data in we will follow the same syntax of function_name(data, \"file_name\") As usual we start with the function name. Then inside the parentheses we have the name of the object we are saving (as it refers to an object in R we do not use quotations) and then the file name, in quotes, ending with the extension you want. For saving an .rda file we use the save() function, otherwise we follow the syntax of write_ ending with the file extension. write_csv() - Excel file, extension “csv” write_dta() - Stata file, extension “dta” write_sas() - SAS file, extension “sas” write_sav() - SPSS file, extension “sav” As with reading the data, write_csv() comes from the readr package while the other formats are from the haven package. 9.2.1 R For saving an .rda file we must set the parameter “file” to be the name we’re saving. For the other types of data they use the parameter “path” rather than “file” but it is not necessary to call them explicitly. save(shootings, file = &quot;data/shootings.rda&quot;) 9.2.2 Excel write_csv(shootings, &quot;data/shootings.csv&quot;) 9.2.3 Stata write_dta(shootings, &quot;data/shootings.dta&quot;) 9.2.4 SAS write_sas(shootings, &quot;data/shootings.sas&quot;) 9.2.5 SPSS write_sav(shootings, &quot;data/shootings.sav&quot;) "],
["scraping-data-from-pdfs.html", "10 Scraping data from PDFs 10.1 Downloading officer-involved Shooting Files 10.2 Scraping information from the page 10.3 Extracting data from PDFs", " 10 Scraping data from PDFs Many government agencies will release reports as PDF files with useful data included as tables in the PDF rather than in a more readily accessible form such as a .csv file. This makes it difficult to use as we can’t simply load the PDF into R and start working on the data as we’ve done before. We need to take the data inside the PDF and turn it into a format that R can understand. In Chapter @ref(#scrape-table) we will work on grabbing an entire table from a PDF, in this lesson we will just grab a line of text from the PDF. For this lesson we’ll use data on officer-involved shootings from the Philadelphia Police Department’s website available here. The site contains information about each shooting such as the location and date - which we will scrape from the website - as well as information inside each shooting’s descriptive PDF which we will learn to scrape here. Our goal here and in the following lessons is to see how the number of officer-involved shootings changed over time and see where in Philadelphia they occurred. For this we need two pieces of information: the date each shooting occurred, and the location of each shooting. 10.1 Downloading officer-involved Shooting Files We will use the package rvest which we used to webscrape movie data to help download these files and to get some information off the web page. As always, we need to use library() to tell R we are going to use functions from this package. library(rvest) #&gt; Loading required package: xml2 The last time we used rvest we did so to get information about movie ticket sales by grabbing data from a table on the page. In this case we are using it for two purposes: to get the link of each PDF on the page to download and to get the address of each incident. Each year of data has its own table with a link to the PDF and the street address of where the shooting took place. For years after 2012 it also includes some useful information about the shooting but we will not be using that information in this lesson. First we need to get the links of each PDF to download. Since links are simply a special type of text on the page, we can use a similar method to webscraping movie data to get all of the links. Again we start with using read_html() to read in the page to R and we will save that in an object called “links” since that is what we want to end up with. links &lt;- read_html(&quot;http://www.phillypolice.com/ois/&quot;) In this case we don’t need to look on the site to determine the CSS selector, we simply use “a” which will find all links on the page. html_attr(\"href\") converts the XML code for the links to text which we can understand. links &lt;- html_nodes(links, &quot;a&quot;) links &lt;- html_attr(links, &quot;href&quot;) Now we can take a look at the results and check how many results there are. head(links) #&gt; [1] &quot;https://www.phillypolice.com/&quot; &quot;/news/index.html&quot; #&gt; [3] &quot;/districts-units/index.html&quot; &quot;/accountability/index.html&quot; #&gt; [5] &quot;/programs-services/index.html&quot; &quot;/forms/index.html&quot; length(links) #&gt; [1] 521 There are 521 results and of the first 6 none of them are PDFs. This makes sense as our code grabbed every single link on the page, PDF or not. We need a way to subset these links to just those that are PDFs. Since we know that every PDF will end with the text “.pdf” we can use grep() to subset the links to only return those which include “.pdf” in the name. Sometimes the .pdf extension is written .PDF so we will set the parameter ignore.case to TRUE to ignore capitalization. links &lt;- links[grep(&quot;.pdf&quot;, links, ignore.case = TRUE)] head(links) #&gt; [1] &quot;/assets/directives/D10.1.pdf&quot; #&gt; [2] &quot;/assets/directives/D10.2-UseOfModerateLimitedForce.pdf&quot; #&gt; [3] &quot;/assets/directives/D10.3-UseOfLessLethalForce.pdf&quot; #&gt; [4] &quot;/assets/directives/D10.4-UseOfForceReviewBoard.pdf&quot; #&gt; [5] &quot;/assets/crime-maps-stats/officer-involved-shootings/master-report-ois.pdf&quot; #&gt; [6] &quot;/assets/crime-maps-stats/officer-involved-shootings/master-report-explanations-ois.pdf&quot; This looks better but there are still a few files we don’t want even though they are PDFs. By looking through our list of links, and looking at the website as a comparison, it seems that the PDFs with information on officer shootings have the text “officer-involved-shootings” in the name. We can use grep() again to just grab those links. links &lt;- links[grep(&quot;officer-involved-shootings&quot;, links)] Let’s look at the first 10 links to see what files we still have. links[1:10] #&gt; [1] &quot;/assets/crime-maps-stats/officer-involved-shootings/master-report-ois.pdf&quot; #&gt; [2] &quot;/assets/crime-maps-stats/officer-involved-shootings/master-report-explanations-ois.pdf&quot; #&gt; [3] &quot;/assets/crime-maps-stats/officer-involved-shootings/Citywide-SV-OIS-2019-Q2.pdf&quot; #&gt; [4] &quot;/assets/crime-maps-stats/officer-involved-shootings/Citywide-Gun-Crime-OIS-2019-Q2.pdf&quot; #&gt; [5] &quot;/assets/crime-maps-stats/officer-involved-shootings/ois-19-04.pdf&quot; #&gt; [6] &quot;/assets/crime-maps-stats/officer-involved-shootings/19-06.pdf&quot; #&gt; [7] &quot;/assets/crime-maps-stats/officer-involved-shootings/19-09.pdf&quot; #&gt; [8] &quot;/assets/crime-maps-stats/officer-involved-shootings/19-11.pdf&quot; #&gt; [9] &quot;/assets/crime-maps-stats/officer-involved-shootings/19-13.pdf&quot; #&gt; [10] &quot;/assets/crime-maps-stats/officer-involved-shootings/19-14.pdf&quot; A few of these PDFs are general reports rather than descriptions of specific shootings. We could specifically delete these through subsetting them out but since it is only a few files we can just download them then not use them. Now that we have all the links we need, we can use a for loop to download them. To download files in R we will use the function download.file() which, as the name implies, just downloads a file from the internet to your computer. This function takes two inputs: the parameter url is the URL where the file to download is stored (the links in our case), and parameter destfile is the name we will call the file we download. The links we have do not actually have the full URL we need. Notice that they begin with “/assets” but if you click a link on the web page, the links all start “http://www.phillypolice.com/assets”. In our code we can paste the “http://www.phillypolice.com” part to our link name to make a complete URL to download. Since all the files have a similar pattern, we can use gsub() to make the name shorter than the long link it comes in. Note that for every link the pattern is the the real file name is at the very end and there are a number of categories broken up by forward slashes. For a quick gsub() can use the special character . (the period or dot) to indicate anything and the special character * (asterix) to indicate “0 or more of the previous character” to say find every character up to and including the forward slash and replace it with nothing. Using the very first link as an example, the gsub() removes everything except the very last part of the link. It replaces every character up to and including the latest forward slash with an empty string, leaving a useful file name. gsub(&quot;.*/&quot;, &quot;&quot;, links[1]) #&gt; [1] &quot;master-report-ois.pdf&quot; download.file() downloads the file into the current working directory so make sure it is set to where you want the files to go (for this many files it is wise to make a new folder specifically to hold these files). We will set the parameter mode to “wb”. This isn’t strictly necessary but in some cases R has an issue downloading files and this seems to fix it. Since sometimes scraping data from the same page too often causes a download to fail, we will add the code Sys.sleep(1) which forces R to sleep for 1 second. This slows down the code and makes sure we don’t overload the site. There are 468 files so it will take some time to download them all. setwd(&quot;data/philly_officer_shootings&quot;) for (file in links) { url &lt;- paste(&quot;http://www.phillypolice.com&quot;, file, sep = &quot;&quot;) save_name &lt;- gsub(&quot;.*/&quot;, &quot;&quot;, file) download.file(url = url, destfile = save_name, mode = &quot;wb&quot;) Sys.sleep(1) } 10.2 Scraping information from the page We also want the date and address of every shooting. While that data is available in the PDFs, it isn’t in a consistent format which would make it difficult to get. The webpage we downloaded the PDFs from does contain the address of each shooting in a convenient table so we will scrape the data from there. While the PDFs have the date for every shooting, starting in 2017 the date isn’t in an easy to scrape format so we will scrape the date column that is present for all years starting in 2013. Since we will want to merge the location with the data from the PDF, we will also scrape the Police Shooting Number column so we have something consistent in both the PDF and the scraped data to merge by. As before, we will start by using read_html() to read the page into R. We will call this object “page” as we are going to use it for scraping the location, date, and the shooting number so we don’t want to overwrite the object. page &lt;- read_html(&quot;http://www.phillypolice.com/ois/&quot;) We need to location &lt;- html_nodes(page, &quot;.span3 td+ td , td:nth-child(3)&quot;) To convert that into values we can read, we use the function html_text(). This is similar to html_table() we used before which told R to convert the data as a table. In this case the data are strings so we use html_text(). location &lt;- html_text(location) If we do the same thing for the Shooting Numbers we find that the CSS selector is “td:nth-child(1)” shooting_numbers &lt;- html_nodes(page, &quot;td:nth-child(1)&quot;) shooting_numbers &lt;- html_text(shooting_numbers) Finally we can get the date information. Be careful when selecting date, if you just click on a row in the Date column, it will include the Location column for years 2007-2012. This is because SelectorGadget knows you clicked the second column in a table, but doesn’t know that that means Date in certain tables in Location in others. Click one of the highlighted Location rows in 2007-2012 tables to deselect them. dates &lt;- html_nodes(page, &quot;.span12 td:nth-child(2)&quot;) dates &lt;- html_text(dates) Note that there are 467 values for location and shooting_numbers, 148 values for dates, and 468 values for links of the PDFs we downloaded? Why is this? -1 of the shootings do not have a PDF associated with the shooting so there is no link to that PDF to download. As data from 2007-2012 do not have dates on the table, there is nothing to scrape, leading to many fewer values than the location or shooting_numbers. 10.2.1 Combining the data sets officer_shootings &lt;- data.frame(shooting_number = shooting_numbers, location = location, dates = date, stringsAsFactors = FALSE) #&gt; Error in as.data.frame.default(x[[i]], optional = TRUE): cannot coerce class &#39;&quot;function&quot;&#39; to a data.frame Trying to make a data.frame this way returns an error because while there are 467 shootings, only the shooting number and location variable have all 467 values. Since the dates don’t exist for 2007-2012, we only have 148 values for that data. While there are a few ways to solve this (as is true with nearly every problem in R), we will expand the “dates” object to make it 467 values long. The function rep() is used to repeat values. rep(&quot;hello&quot;, 10) #&gt; [1] &quot;hello&quot; &quot;hello&quot; &quot;hello&quot; &quot;hello&quot; &quot;hello&quot; &quot;hello&quot; &quot;hello&quot; &quot;hello&quot; #&gt; [9] &quot;hello&quot; &quot;hello&quot; Above we repeated the word “hello” 10 times. To solve our issue we need to repeat some value 319 times and add that to the end of the “dates” object to make it 467 values long. For our value we will use NA to indicate that those values are missing. rep(NA, (length(location) - length(dates))) #&gt; [1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA #&gt; [24] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA #&gt; [47] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA #&gt; [70] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA #&gt; [93] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA #&gt; [116] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA #&gt; [139] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA #&gt; [162] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA #&gt; [185] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA #&gt; [208] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA #&gt; [231] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA #&gt; [254] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA #&gt; [277] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA #&gt; [300] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA To combine the “dates” object with all these repeated NA’s we will use c() which combines vectors. Make sure we put “dates” first to maintain the correct order. dates &lt;- c(dates, rep(NA, (length(location) - length(dates)))) And we can now check the length of “dates”. length(dates) #&gt; [1] 467 Since “dates” is 467 values long now, let’s try making the data.frame again. officer_shootings &lt;- data.frame(shooting_number = shooting_numbers, location = location, dates = dates, stringsAsFactors = FALSE) It works. Let’s look at the first 6 values. We can compare our results from the table on the page to make sure we did it correctly. head(officer_shootings) #&gt; shooting_number location dates #&gt; 1 19-04 4900 block of Hazel Avenue 03/06/2019 #&gt; 2 19-06 1300 block of Kater Street 03/28/2019 #&gt; 3 19-09 Bridge Street &amp; Roosevelt Boulevard 04/20/2019 #&gt; 4 19 11 2100 block of Taney Terrace 04/25/2019 #&gt; 5 19-13 1800 block of N. Broad Street 05/11/2019 #&gt; 6 19 14 3400 block of G Street 05/20/2019 And for good measure we can look at the bottom 6 rows, expecting NAs for the dates column. tail(officer_shootings) #&gt; shooting_number location dates #&gt; 462 07-83 5224 Wayne Ave &lt;NA&gt; #&gt; 463 07-84 1500 block of N. Frazier St &lt;NA&gt; #&gt; 464 07-85 2300 block of N. 16th St &lt;NA&gt; #&gt; 465 07-88 100 block of Chestnut St &lt;NA&gt; #&gt; 466 07-93 2900 block of Mascher St &lt;NA&gt; #&gt; 467 07-94 5400 block of Erdrick St &lt;NA&gt; 10.3 Extracting data from PDFs We scraped dates for shootings from 2013 and more recent and now need to get the dates for 2012 and before. We will do so by scraping the PDFs and taking the line that says the date of the shooting. For this we will use the package pdftools which lets R scrape PDFs. install.packages(&quot;pdftools&quot;) library(pdftools) 10.3.1 Scraping a single PDF pdf_text() lets us scrape the text from a PDF. The input in the () is the name (in quotes as it is saying to R, go to the file on the computer) of the PDF to be read. Make sure your working directory is set to where the file is. As an example we will look at the last shooting in 2016 which we called “16-01.pdf”. setwd(&quot;data/philly_officer_shootings&quot;) pdf &lt;- pdf_text(&quot;16-01.pdf&quot;) pdf #&gt; [1] &quot;PS# 16-01\\r\\n1/07/16\\r\\nOn Thursday, January 7, 2016, at approximately 11:41 P.M., a uniformed\\r\\nofficer in a marked police vehicle was traveling north in the 300 block of S.\\r\\n60th Street, when he observed a male approaching his vehicle near the\\r\\nintersection of 60th and Spruce Streets. The male was armed with a firearm.\\r\\nWithout warning, the offender discharged the firearm, striking the officer as\\r\\nhe remained seated inside his police vehicle. The offender advanced to the\\r\\ndriver’s door of the police vehicle and leaned in through the shattered\\r\\nwindow, still discharging his firearm at the officer. The offender then fled on\\r\\nfoot, but continued to discharge his weapon at the officer. The officer exited\\r\\nhis police vehicle and returned fire striking the offender. The offender was\\r\\napprehended by responding officers in the 5900 block of Delancey Street.\\r\\nThe officer was transported to Penn-Presbyterian Hospital where he was\\r\\nadmitted.\\r\\nThe offender was transported to the Hospital of the University of\\r\\nPennsylvania for treatment.\\r\\nThe offender’s firearm, a Glock, 9MM, semi-automatic pistol, which had been\\r\\nreported stolen, was recovered empty, with the slide locked to the rear, at the\\r\\nscene.\\r\\nThere were no other injuries as a result of this firearm discharge.\\r\\n *** Information posted in the original summary reflects a preliminary\\r\\nunderstanding of what occurred at the time of the incident. This information\\r\\nis posted shortly after the incident and may be updated as the investigation\\r\\nleads to new information. The DA’s Office is provided all the information\\r\\nfrom the PPD’s investigation prior to their charging decision.\\r\\n&quot; When we print the file we can see that it is a single big block of text. Near the beginning of the text we can see a date, 1/07/16. When comparing the PDF which we can read ourselves on Adobe Acrobat or a web browser, it is clear that all the line breaks in the PDF disappeared when we used pdf_text(). More specifically, the line breaks were replaced by \\n which is R’s way of saying “this is a line break”. We want to grab just the date from this file. Since the file is in a single block of text, we need to break it up based on where there should be a line break (turning each line back into an individual part of the file) and grab only the line with the date. When splitting up a string (which is just what the PDF is now), we can use the function strsplit() which splits up a string based on some pattern. Let’s see a simple example, splitting up the word “criminology” by the letter “n”. Note that it deletes the character it is splitting by! strsplit(&quot;criminology&quot;, split = &quot;n&quot;) #&gt; [[1]] #&gt; [1] &quot;crimi&quot; &quot;ology&quot; It now returns two words “crimi” amd “ology”, the two parts of the word “criminology” on each side of the letter “n”. It returns the value inside a list - which is why you see the [[1]] above the result. To get the value we actually want, we need to get the first element inside that list, using double bracket notation. split &lt;- strsplit(&quot;criminology&quot;, split = &quot;n&quot;) split &lt;- split[[1]] split #&gt; [1] &quot;crimi&quot; &quot;ology&quot; From the pattern we see in the PDF we scraped, and comparing it to the PDF we can see in Adobe Acrobat or a web browser, it is clear that we can use split at the characters \\r\\n and it will give us each line in its own element (for Mac users you may need to split at \\n rather than \\r\\n). Let’s do that and just return the first element so we don’t get a list. Let’s call the object we make “pdf_split”. pdf_split &lt;- strsplit(pdf, split = &quot;\\r\\n&quot;) pdf_split &lt;- pdf_split[[1]] pdf_split #&gt; [1] &quot;PS# 16-01&quot; #&gt; [2] &quot;1/07/16&quot; #&gt; [3] &quot;On Thursday, January 7, 2016, at approximately 11:41 P.M., a uniformed&quot; #&gt; [4] &quot;officer in a marked police vehicle was traveling north in the 300 block of S.&quot; #&gt; [5] &quot;60th Street, when he observed a male approaching his vehicle near the&quot; #&gt; [6] &quot;intersection of 60th and Spruce Streets. The male was armed with a firearm.&quot; #&gt; [7] &quot;Without warning, the offender discharged the firearm, striking the officer as&quot; #&gt; [8] &quot;he remained seated inside his police vehicle. The offender advanced to the&quot; #&gt; [9] &quot;driver’s door of the police vehicle and leaned in through the shattered&quot; #&gt; [10] &quot;window, still discharging his firearm at the officer. The offender then fled on&quot; #&gt; [11] &quot;foot, but continued to discharge his weapon at the officer. The officer exited&quot; #&gt; [12] &quot;his police vehicle and returned fire striking the offender. The offender was&quot; #&gt; [13] &quot;apprehended by responding officers in the 5900 block of Delancey Street.&quot; #&gt; [14] &quot;The officer was transported to Penn-Presbyterian Hospital where he was&quot; #&gt; [15] &quot;admitted.&quot; #&gt; [16] &quot;The offender was transported to the Hospital of the University of&quot; #&gt; [17] &quot;Pennsylvania for treatment.&quot; #&gt; [18] &quot;The offender’s firearm, a Glock, 9MM, semi-automatic pistol, which had been&quot; #&gt; [19] &quot;reported stolen, was recovered empty, with the slide locked to the rear, at the&quot; #&gt; [20] &quot;scene.&quot; #&gt; [21] &quot;There were no other injuries as a result of this firearm discharge.&quot; #&gt; [22] &quot; *** Information posted in the original summary reflects a preliminary&quot; #&gt; [23] &quot;understanding of what occurred at the time of the incident. This information&quot; #&gt; [24] &quot;is posted shortly after the incident and may be updated as the investigation&quot; #&gt; [25] &quot;leads to new information. The DA’s Office is provided all the information&quot; #&gt; [26] &quot;from the PPD’s investigation prior to their charging decision.&quot; We need a way to only take the row with the date. In most cases the second row is the one with the date, however this isn’t true in every case. Therefore, we can’t just grab the second element. We can use grep() to search for a pattern that is unique to the row with the date to get that row. So what pattern does our date have? It is always one or two numbers followed by a / followed again by two numbers, another / and two more numbers. 1/07/16 So our pattern in grep() will be ^[0-9]+/[0-9]+/[0-9]+ The ^ is a special character saying that whatever follows it is the start of the string. [0-9] means any number. The + is a special character which says “one or more of the previous character” so [0-9] means “one or more numbers”. Some files (such as this one) have multiple dates in the text so we want to only get rows starting with a date. By default grep() will return a number indicating the element where it found a match. If we set the parameter value to TRUE, it will print out that element. grep(&quot;^[0-9]+/[0-9]+/[0-9]+&quot;, pdf_split, value = TRUE) #&gt; [1] &quot;1/07/16&quot; 10.3.2 Making a function Since we need to do this process for hundreds of PDFs we will make a function and then for loop through it for every PDF. Here we are following the same steps as scraping the movie data - make code work for a single file/date, turn it into a function to work for any file/date, and write a for loop so it works for every file/date we have. That’s the general process you will use when writing code meant for multiple inputs. Make sure code works first in a specific case (a specific date), then make it work in the general case (any date). When making a function from code you’ve already written, a good method is to just copy all the code so it is together, then start building the function. setwd(here::here(&quot;data/philly_officer_shootings&quot;)) pdf &lt;- pdf_text(&quot;16-01.pdf&quot;) pdf_split &lt;- strsplit(pdf, split = &quot;\\r\\n&quot;) pdf_split &lt;- pdf_split[[1]] grep(&quot;^[0-9]+/[0-9]+/[0-9]+&quot;, pdf_split, value = TRUE) #&gt; [1] &quot;1/07/16&quot; Above is our code to scrape a specific PDF. Now let’s make the standard function skeleton without including any code just yet. We can call the function “get_date_from_pdf” since that is a good description for what our function will do. We want to input a file name and get a date returned. So we will call our parameter in the () “file_name” and our return object “date”. get_date_from_pdf &lt;- function(file_name) { return(date) } Now we can add in our code. get_date_from_pdf &lt;- function(file_name) { setwd(here::here(&quot;data/philly_officer_shootings&quot;)) pdf &lt;- pdf_text(&quot;16-01.pdf&quot;) pdf_split &lt;- strsplit(pdf, split = &quot;\\r\\n&quot;) pdf_split &lt;- pdf_split[[1]] return(date) } There are two steps remaining to turn our code into a working function. As it is, the code still writes pdf_text(\"16-01.pdf\"). We want it to run pdf_text(file_name) on any file we input so let’s change “16-01.pdf” to say “file_name” (not in quotes since it is an object). And we want the function to return an object called “date” which has the date from the PDF. We know the date is printed by the grep() code we wrote, so let’s save that as “date”. get_date_from_pdf &lt;- function(file_name) { setwd(here::here(&quot;data/philly_officer_shootings&quot;)) pdf &lt;- pdf_text(file_name) pdf_split &lt;- strsplit(pdf, split = &quot;\\r\\n&quot;) pdf_split &lt;- pdf_split[[1]] date &lt;- grep(&quot;^[0-9]+/[0-9]+/[0-9]+&quot;, pdf_split, value = TRUE) return(date) } Now let’s try it our using another PDF, let’s say “16-01.pdf”. get_date_from_pdf(&quot;16-01.pdf&quot;) #&gt; [1] &quot;1/07/16&quot; 10.3.3 Looping through every PDF Before we write the for loop let’s think about what our goal is and what we currently have. We have a data set which has a single row for every shooting and information about when and where each shooting took place. The object “officer_shootings” that we made earlier has most of that. It contains the location for every shooting and the date for all of those from 2013-2019. So we want to scrape the PDFs for years prior to 2013 to get the date of each shooting. And we made a function that gives us the date in the file we input. Since we know the dates for 2013-2019 (and 2017-2019 make it hard to get the date from the PDF), we only want to scrape the PDFs from 2007-2012. We need to do two things now: Select only PDFs from 2007-2012 For each PDF figure out a way to select the right row in the “officer_shootings” object to add the date We can take this one piece at a time. First we need to select only PDFs from 2007-2012. The function list.files() will provide a list of every file in the working directory. We will use it to get a list of all files in the folder we stored the PDFs and then subset it to just keep the files we want. Let’s call the object “pdf_files”. setwd(&quot;data/philly_officer_shootings&quot;) pdf_files &lt;- list.files() Looking at head() we can see it is a vector of file names. head(pdf_files) #&gt; [1] &quot;07-01 4400 N 17 ST.pdf&quot; &quot;07-02 2400 N 10 ST.pdf&quot; #&gt; [3] &quot;07-03 1700 N 59 ST.pdf&quot; &quot;07-04 900 MARKET ST.pdf&quot; #&gt; [5] &quot;07-05 2800 E PACIFIC ST.pdf&quot; &quot;07-06 6300 DITMAN ST.pdf&quot; There is a pattern in these names where they start with two characters indicating the year (2016 starts with “PS” then “16” though since we don’t need 2016 data that doesn’t affect this process). We will use this pattern to just get files that start with “0” or begin “10”, “11”, or “12”. We will use grep() and make use of the ^ special character which indicates that the characters following it are the start of the string. We will also use the | special character which indicates “thing on left or right” of the | are both a match. grep(&quot;^0|^10|^11|^12&quot;, pdf_files) #&gt; [1] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 #&gt; [18] 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 #&gt; [35] 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 #&gt; [52] 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 #&gt; [69] 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 #&gt; [86] 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 #&gt; [103] 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 #&gt; [120] 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 #&gt; [137] 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 #&gt; [154] 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 #&gt; [171] 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 #&gt; [188] 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 #&gt; [205] 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 #&gt; [222] 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 #&gt; [239] 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 #&gt; [256] 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 #&gt; [273] 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 #&gt; [290] 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 #&gt; [307] 307 308 309 310 311 312 313 314 315 316 317 This prints out a list of which elements in “pdf_files” are a match. We can use square bracket notation [] subsetting to just keep the elements in “pdf_files” that we want. And let’s save that object as “pdf_files”, overwriting our initial object with just the values we want. This way we minimize the number of objects we need to keep track of. pdf_files &lt;- pdf_files[grep(&quot;^0|^10|^11|^12&quot;, pdf_files)] We have accomplished our first task, getting just the PDFs from 2007-2012. Now we need to find a way to match the correct row in “officer_shootings” with each file. Let’s think again about patterns in the file names. head(pdf_files) #&gt; [1] &quot;07-01 4400 N 17 ST.pdf&quot; &quot;07-02 2400 N 10 ST.pdf&quot; #&gt; [3] &quot;07-03 1700 N 59 ST.pdf&quot; &quot;07-04 900 MARKET ST.pdf&quot; #&gt; [5] &quot;07-05 2800 E PACIFIC ST.pdf&quot; &quot;07-06 6300 DITMAN ST.pdf&quot; Each file name starts with the same 5 character (“year-unique ID”) value indicating the shooting number that we scraped from the table. The files then occasionally have the address of the shooting and end with “.pdf”. This is our match. For each file we want to just keep the first 5 characters which are an exact match to the “shooting_number” column. There are a few ways to do this but we’ll use the function substr() as it well-suited for this task. substr() takes a string and returns nth-mth (inclusive) characters in that string. Let’s see how this works using the word “apple”. substr(&quot;apple&quot;, start = 1, stop = 3) #&gt; [1] &quot;app&quot; Here we input the word “apple” and set the parameter start to 1 and stop to 3. This says, take the word “apple” and return the 1st through the 3rd element (i.e. letter) in that string. This is very useful for taking only a small piece of a string. In our case we just want the first 5 characters in the PDF file name. substr(pdf_files[1], start = 1, stop = 5) #&gt; [1] &quot;07-01&quot; And here we have the officer shooting number for the first PDF which we can use to match with the correct row in the “officer_shootings” file. We can now create the for loop. Let’s start with a skeleton of the for loop then slowly add our code. for (file in pdf_files) { } For loops take the form “for x in some group of x, do this thing”. In our case our “group of x” is the “pdf_files” object, a group of file names. We want the loop to go through every file in “pdf_files”, find the police shooting number from the file name to match with the correct row in “officer_shootings”, get the date from the file, and then put the date in the right row. We can add in the code we wrote to get the police shooting number. for (file in pdf_files) { police_shooting_number &lt;- substr(file, start = 1, stop = 5) } And the code to get the date from the function we made. for (file in pdf_files) { police_shooting_number &lt;- substr(file, start = 1, stop = 5) date &lt;- get_date_from_pdf(file) } Finally we add in code that uses square bracket notation [] to say change the value in the “dates” column in the row where the shooting number matches the shooting number we made from the file name to the date we got from the PDF. The for loop is done and we can run it. for (file in pdf_files) { police_shooting_number &lt;- substr(file, start = 1, stop = 5) date &lt;- get_date_from_pdf(file) officer_shootings$dates[officer_shootings$shooting_number == police_shooting_number] &lt;- date } We have one final thing to do, make the date column Date type. The date in the “dates” column aren’t in the Date format for R which means that while we can easy read it, R doesn’t know that it is a date and can’t do any date-related functions like grabbing the year or months from it. We can use the lubridate package we worked with earlier to turn it into a date. Since this date is in the month-day-year order we will use the function mdy(). library(lubridate) #&gt; #&gt; Attaching package: &#39;lubridate&#39; #&gt; The following object is masked from &#39;package:base&#39;: #&gt; #&gt; date officer_shootings$dates &lt;- mdy(officer_shootings$dates) Now our “officer_shootings” file contains the date and address of every officer-involved shooting in Philadelphia from 2007 to early 2019. 3 of the shootings do not have a PDF associated with it. Let’s remove them since we are unable to verify information on the table. These rows have a value of \"\" in the “shooting_number” column so we’ll subset the “officer_shootings” data.frame to keep only rows where the shooting number is not \"\". officer_shootings &lt;- officer_shootings[officer_shootings$shooting_number != &quot;&quot;, ] We will save the file for now and in Chapter 12 learn how to geocode the address into coordinates that allow us to plot the shootings onto a map of Philadelphia. setwd(here::here(&quot;data&quot;)) save(officer_shootings, file = &quot;officer_shootings.rda&quot;) "],
["scrape-table.html", "11 Scraping Tables from PDFs 11.1 Scraping the first table 11.2 Making a function", " 11 Scraping Tables from PDFs In Chapter 10 we began working on scraping data from a PDF. We read in PDFs from Philadelphia’s officer-involved shooting data and grabbed a single line of text from each PDF. That data was written up like a report, with the date of the incident followed by a description of what happened. In the majority of cases when you want data from a PDF it will be in a table rather than descriptive paragraph. Essentially the data will be an Excel file inside of a PDF. This format is not altogether different than what we did before. We will be using regular expressions and strsplit() again to handle this data. Let’s first take a look at the data we will be scraping. The first step in any PDF scraping should be looking at the PDF and try to think about the best way to approach this particular problem - while all PDF scraping follows a general format you cannot necessarily copy and paste your code, each situation is likely slightly different. Our data is from the U.S. Customs and Border Protection (CBP) and contains a wealth of information about apprehensions and contraband seizures in border sectors. We will be using the Sector Profile 2017 PDF which has information in four tables which we’ll scrape and then combine together. The data was downloaded on the U.S. Customs and Border Protection “Stats and Summaries” page here. If you’re interested in using more of their data, some of it has been cleaned and made available here. The file we want to use is called “usbp_stats_fy2017_sector_profile.pdf” and has four tables in the PDF. Let’s take a look at them one at a time, understanding what variable are available, and what units each row is in. Then we’ll start scraping the tables. The first table is “Sector Profile - Fiscal Year 2017 (Oct. 1st through Sept. 30th)”. Before we even look down more at the table, the title is important. It is for fiscal year 2017, not calendar year 2017 which is more common in the data we usually use. This is important if we ever want to merge this data with other data sets. If possible we would have to get data that is monthly so we can just use October 2016 through September 2017 to match up properly. Now if we look more at the table we can see that each row is a section of the U.S. border. There are three main sections - Coastal, Northern, and Southwest, with subsections of each also available as rows. The bottom row is the sum of all these sections and gives us nationwide data. Many government data will be like this form with sections and subsections in the same table. Watch out when doing mathematical operations! Just summing any of these columns will give you triple the true value due to the presence of nationwide, sectional, and subsectional data. There are 9 columns in the data other than the border section identifier. It looks like we have total apprehensions, apprehensions for people who are not Mexican citizens, marijuana and cocaine seizures (in pounds), the number of accepted prosecutions (presumably of those apprehended), and the number of CBP agents assaulted. The last two columns have the number of people rescued by CBP and the number of people who died (it is unclear from this data alone if this is solely people in custody or deaths during crossing the border). These two columns are also special as they only have data for the Southwest border. Table 2 has a similar format with each row being a section or subsection. The columns now have the number of juveniles apprehended, subdivided by if they were accompanied by an adult or not, and the number of adults apprehended. The last column is total apprehensions which is a duplicated column as in Table 1. Table 3 follows the same format and the new columns are number of apprehensions by gender. Finally, Table 4 is a bit different in it’s format. The rows are now variables and the columns are the locations. In this table it doesn’t include subsections, only border sections and nationwide total. The data it has available are partially a repeat of Table 1 but with more drug types and the addition of the number of drug seizures and some firearm seizure information. 11.1 Scraping the first table We’ve now seen all four of the tables that we want to scrape so we can begin the process of actually scraping them. Note that each table is similar (particularly Tables 1-3), meaning we can reuse code to scrape as well as clean the data. That means that we will want to write some functions to make our work easier and avoid copy and pasting code three times. As earlier, we will use the pdf_text() function from the pdftools package to scrape the PDFs. library(pdftools) We can save the output of the pdf_text() function as “border_patrol” and we’ll use it for each table. border_patrol &lt;- pdf_text(&quot;data/usbp_stats_fy2017_sector_profile.pdf&quot;) We can take a look at the head() of the result. head(border_patrol) #&gt; [1] &quot; United States Border Patrol\\r\\n Sector Profile - Fiscal Year 2017 (Oct. 1st through Sept. 30th)\\r\\n Agent Other Than Mexican Marijuana Cocaine Accepted\\r\\n SECTOR Staffing*\\r\\n Apprehensions\\r\\n Apprehensions (pounds) (pounds) Prosecutions\\r\\n Assaults Rescues Deaths\\r\\n Miami 111 2,280 1,646 2,253 231 292 1 N/A N/A\\r\\n New Orleans 63 920 528 21 6 10 0 N/A N/A\\r\\n Ramey 38 388 387 3 2,932 89 0 N/A N/A\\r\\n Coastal Border Sectors Total 212 3,588 2,561 2,277 3,169 391 1 N/A **** N/A ****\\r\\n Blaine 296 288 237 0 0 9 0 N/A N/A\\r\\n Buffalo 277 447 293 228 2 37 2 N/A N/A\\r\\n Detroit 408 1,070 322 124 0 85 1 N/A N/A\\r\\n Grand Forks 189 496 202 0 0 40 2 N/A N/A\\r\\n Havre 183 39 28 98 0 2 0 N/A N/A\\r\\n Houlton 173 30 30 17 0 2 0 N/A N/A\\r\\n Spokane 230 208 67 68 0 24 0 N/A N/A\\r\\n Swanton 292 449 359 531 1 103 6 N/A N/A\\r\\n Northern Border Sectors Total 2,048 3,027 1,538 1,066 3 302 11 N/A **** N/A ****\\r\\n Big Bend (formerly Marfa) 500 6,002 3,346 40,852 45 2,847 11 26 1\\r\\n Del Rio 1,391 13,476 6,156 9,482 62 8,022 12 99 18\\r\\n El Centro 870 18,633 5,812 5,554 484 1,413 34 4 2\\r\\n El Paso 2,182 25,193 15,337 34,189 140 6,996 54 44 8\\r\\n Laredo 1,666 25,460 7,891 69,535 757 6,119 31 1,054 83\\r\\n Rio Grande Valley (formerly McAllen) 3,130 137,562 107,909 260,020 1,192 7,979 422 1,190 104\\r\\n San Diego 2,199 26,086 7,060 10,985 2,903 3,099 84 48 4\\r\\n Tucson 3,691 38,657 12,328 397,090 331 20,963 93 750 72\\r\\n Yuma 859 12,847 10,139 30,181 261 2,367 33 6 2\\r\\n Southwest Border Sectors Total** 16,605 303,916 175,978 857,888 6,174 59,805 774 3,221 294\\r\\n Nationwide Total*** 19,437 310,531 180,077 861,231 9,346 60,498 786 3,221 294\\r\\n* Agent staffing statistics depict FY17 on-board personnel data as of 9/30/2017\\r\\n** Southwest Border Sectors staffing statistics include: Big Bend, Del Rio, El Centro, El Paso, Laredo, Rio Grande Valley, San Diego, Tucson, Yuma, and the Special Operations Group.\\r\\n*** Nationwide staffing statistics include: All on-board Border Patrol agents in CBP\\r\\n**** Rescue and Death statistics are not tracked for Northern and Coastal Border Sectors.\\r\\n&quot; #&gt; [2] &quot; United States Border Patrol\\r\\n Juvenile (0-17 Years Old) and Adult Apprehensions - Fiscal Year 2017 (Oct. 1st through Sept. 30th)\\r\\n Accompanied Unaccompanied Total Total Total\\r\\n SECTOR Juveniles Juveniles Juveniles Adults Apprehensions\\r\\nMiami 19 42 61 2,219 2,280\\r\\nNew Orleans 1 22 23 897 920\\r\\nRamey 7 1 8 380 388\\r\\nCoastal Border Sectors Total 27 65 92 3,496 3,588\\r\\nBlaine 29 7 36 252 288\\r\\nBuffalo 3 3 6 441 447\\r\\nDetroit 5 11 16 1,054 1,070\\r\\nGrand Forks 5 4 9 487 496\\r\\nHavre 1 3 4 35 39\\r\\nHoulton 1 8 9 21 30\\r\\nSpokane 3 0 3 205 208\\r\\nSwanton 18 10 28 421 449\\r\\nNorthern Border Sectors Total 65 46 111 2,916 3,027\\r\\nBig Bend (formerly Marfa) 506 811 1,317 4,685 6,002\\r\\nDel Rio 1,348 1,349 2,697 10,779 13,476\\r\\nEl Centro 968 1,531 2,499 16,134 18,633\\r\\nEl Paso 4,642 3,926 8,568 16,625 25,193\\r\\nLaredo 477 2,033 2,510 22,950 25,460\\r\\nRio Grande Valley (formerly McAllen) 27,222 23,708 50,930 86,632 137,562\\r\\nSan Diego 1,639 1,551 3,190 22,896 26,086\\r\\nTucson 1,088 3,659 4,747 33,910 38,657\\r\\nYuma 3,241 2,867 6,108 6,739 12,847\\r\\nSouthwest Border Sectors Total 41,131 41,435 82,566 221,350 303,916\\r\\nNationwide Total 41,223 41,546 82,769 227,762 310,531\\r\\n&quot; #&gt; [3] &quot; United States Border Patrol\\r\\n Apprehensions by Gender - Fiscal Year 2017 (Oct. 1st through Sept. 30th)\\r\\n SECTOR Female Male Total Apprehensions\\r\\nMiami 219 2,061 2,280\\r\\nNew Orleans 92 828 920\\r\\nRamey 65 323 388\\r\\nCoastal Border Sectors Total 376 3,212 3,588\\r\\nBlaine 97 191 288\\r\\nBuffalo 69 378 447\\r\\nDetroit 78 992 1,070\\r\\nGrand Forks 56 440 496\\r\\nHavre 13 26 39\\r\\nHoulton 17 13 30\\r\\nSpokane 17 191 208\\r\\nSwanton 106 343 449\\r\\nNorthern Border Sectors Total 453 2,574 3,027\\r\\nBig Bend (formerly Marfa) 985 5,017 6,002\\r\\nDel Rio 2,622 10,854 13,476\\r\\nEl Centro 2,791 15,842 18,633\\r\\nEl Paso 7,364 17,829 25,193\\r\\nLaredo 3,651 21,809 25,460\\r\\nRio Grande Valley (formerly McAllen) 50,306 87,256 137,562\\r\\nSan Diego 4,117 21,969 26,086\\r\\nTucson 4,693 33,964 38,657\\r\\nYuma 4,328 8,519 12,847\\r\\nSouthwest Border Sectors Total 80,857 223,059 303,916\\r\\nNationwide Total 81,686 228,845 310,531\\r\\n&quot; #&gt; [4] &quot; United States Border Patrol\\r\\n Apprehensions / Seizure Statistics - Fiscal Year 2017 (Oct. 1st through Sept. 30th)\\r\\n Apprehension/Seizure Type Coastal Border Sectors Northern Border Sectors Southwest Border Sectors Nationwide Total\\r\\n Apprehensions 3,588 3,027 303,916 310,531\\r\\n Other Than Mexican Apprehensions 2,561 1,538 175,978 180,077\\r\\n Marijuana (pounds) 2,277 1,066 857,888 861,231\\r\\n Cocaine (pounds) 3,169 3 6,174 9,346\\r\\n Heroin (ounces) 0 62 15,182 15,244\\r\\n Methamphetamine (pounds) 23 32 10,273 10,328\\r\\n Ecstasy (pounds) 0 0 1 1\\r\\n Other Drugs* (pounds) 0 14 554 568\\r\\n Marijuana Seizures 113 255 9,371 9,739\\r\\n Cocaine Seizures 33 46 463 542\\r\\n Heroin Seizures 0 29 219 248\\r\\n Methamphetamine Seizures 2 68 809 879\\r\\n Ecstasy Seizures 1 2 48 51\\r\\n Other Drugs* Seizures 6 99 735 840\\r\\n Conveyances 86 79 7,388 7,553\\r\\n Firearms 9 45 369 423\\r\\n Ammunition (rounds) 217 384 13,938 14,539\\r\\n Currency (value) $325,129 $374,282 $5,169,593 $5,869,004\\r\\n*Other Drugs include: All USBP drug seizures excluding marijuana, cocaine, heroin, methamphetamine, and ecstasy (MDMA).\\r\\nCoastal Border Sectors include: Miami, New Orleans, and Ramey, Puerto Rico.\\r\\nNorthern Border Sectors include: Blaine, Buffalo, Detroit, Grand Forks, Havre, Houlton, Spokane and Swanton.\\r\\nSouthwest Border Sectors include: Big Bend, Del Rio, El Centro, El Paso, Laredo, Rio Grande Valley, San Diego, Tucson, and Yuma.\\r\\nDrug quantities are rounded to the nearest whole number\\r\\n&quot; If you look closely in this huge amount of text output, you can see that it is a vector with each element being an element in the vector. We can see this further by checking the length() of “border_patrol” and just looking at the first element. length(border_patrol) #&gt; [1] 4 It is four elements long, one for each table. border_patrol[1] #&gt; [1] &quot; United States Border Patrol\\r\\n Sector Profile - Fiscal Year 2017 (Oct. 1st through Sept. 30th)\\r\\n Agent Other Than Mexican Marijuana Cocaine Accepted\\r\\n SECTOR Staffing*\\r\\n Apprehensions\\r\\n Apprehensions (pounds) (pounds) Prosecutions\\r\\n Assaults Rescues Deaths\\r\\n Miami 111 2,280 1,646 2,253 231 292 1 N/A N/A\\r\\n New Orleans 63 920 528 21 6 10 0 N/A N/A\\r\\n Ramey 38 388 387 3 2,932 89 0 N/A N/A\\r\\n Coastal Border Sectors Total 212 3,588 2,561 2,277 3,169 391 1 N/A **** N/A ****\\r\\n Blaine 296 288 237 0 0 9 0 N/A N/A\\r\\n Buffalo 277 447 293 228 2 37 2 N/A N/A\\r\\n Detroit 408 1,070 322 124 0 85 1 N/A N/A\\r\\n Grand Forks 189 496 202 0 0 40 2 N/A N/A\\r\\n Havre 183 39 28 98 0 2 0 N/A N/A\\r\\n Houlton 173 30 30 17 0 2 0 N/A N/A\\r\\n Spokane 230 208 67 68 0 24 0 N/A N/A\\r\\n Swanton 292 449 359 531 1 103 6 N/A N/A\\r\\n Northern Border Sectors Total 2,048 3,027 1,538 1,066 3 302 11 N/A **** N/A ****\\r\\n Big Bend (formerly Marfa) 500 6,002 3,346 40,852 45 2,847 11 26 1\\r\\n Del Rio 1,391 13,476 6,156 9,482 62 8,022 12 99 18\\r\\n El Centro 870 18,633 5,812 5,554 484 1,413 34 4 2\\r\\n El Paso 2,182 25,193 15,337 34,189 140 6,996 54 44 8\\r\\n Laredo 1,666 25,460 7,891 69,535 757 6,119 31 1,054 83\\r\\n Rio Grande Valley (formerly McAllen) 3,130 137,562 107,909 260,020 1,192 7,979 422 1,190 104\\r\\n San Diego 2,199 26,086 7,060 10,985 2,903 3,099 84 48 4\\r\\n Tucson 3,691 38,657 12,328 397,090 331 20,963 93 750 72\\r\\n Yuma 859 12,847 10,139 30,181 261 2,367 33 6 2\\r\\n Southwest Border Sectors Total** 16,605 303,916 175,978 857,888 6,174 59,805 774 3,221 294\\r\\n Nationwide Total*** 19,437 310,531 180,077 861,231 9,346 60,498 786 3,221 294\\r\\n* Agent staffing statistics depict FY17 on-board personnel data as of 9/30/2017\\r\\n** Southwest Border Sectors staffing statistics include: Big Bend, Del Rio, El Centro, El Paso, Laredo, Rio Grande Valley, San Diego, Tucson, Yuma, and the Special Operations Group.\\r\\n*** Nationwide staffing statistics include: All on-board Border Patrol agents in CBP\\r\\n**** Rescue and Death statistics are not tracked for Northern and Coastal Border Sectors.\\r\\n&quot; And this gives us all the values in the first table plus a few sentences at the end detailing some features of the table. At the end of each line (where in the PDF it should end but doesn’t in our data yet) there is a \\r\\n indicating that there should be a new line. As we did last time, we want to use strsplit() to split at the \\n. Let’s save a new object with the value in the first element of “border_patrol”, calling it “sector_profile” as that’s the name of that table, and then using strsplit() on it. strsplit() returns a list so we will also want to keep just the first element of that using double square bracket [[]] notation. sector_profile &lt;- border_patrol[1] sector_profile &lt;- strsplit(sector_profile, &quot;\\r\\n&quot;) sector_profile &lt;- sector_profile[[1]] Now we can look at the first six rows of this data. head(sector_profile) #&gt; [1] &quot; United States Border Patrol&quot; #&gt; [2] &quot; Sector Profile - Fiscal Year 2017 (Oct. 1st through Sept. 30th)&quot; #&gt; [3] &quot; Agent Other Than Mexican Marijuana Cocaine Accepted&quot; #&gt; [4] &quot; SECTOR Staffing*&quot; #&gt; [5] &quot; Apprehensions&quot; #&gt; [6] &quot; Apprehensions (pounds) (pounds) Prosecutions&quot; Notice that there is a lot of empty white space at the beginning of the rows. We want to get rid of that to make our next steps easier. We can use trimws() and put the entire “sector_profile” data in the () and it’ll remove the white space at the ends of each line for us. sector_profile &lt;- trimws(sector_profile) We have more rows than we want so let’s look at the entire data and try to figure out how to keep just the necessary rows. sector_profile #&gt; [1] &quot;United States Border Patrol&quot; #&gt; [2] &quot;Sector Profile - Fiscal Year 2017 (Oct. 1st through Sept. 30th)&quot; #&gt; [3] &quot;Agent Other Than Mexican Marijuana Cocaine Accepted&quot; #&gt; [4] &quot;SECTOR Staffing*&quot; #&gt; [5] &quot;Apprehensions&quot; #&gt; [6] &quot;Apprehensions (pounds) (pounds) Prosecutions&quot; #&gt; [7] &quot;Assaults Rescues Deaths&quot; #&gt; [8] &quot;Miami 111 2,280 1,646 2,253 231 292 1 N/A N/A&quot; #&gt; [9] &quot;New Orleans 63 920 528 21 6 10 0 N/A N/A&quot; #&gt; [10] &quot;Ramey 38 388 387 3 2,932 89 0 N/A N/A&quot; #&gt; [11] &quot;Coastal Border Sectors Total 212 3,588 2,561 2,277 3,169 391 1 N/A **** N/A ****&quot; #&gt; [12] &quot;Blaine 296 288 237 0 0 9 0 N/A N/A&quot; #&gt; [13] &quot;Buffalo 277 447 293 228 2 37 2 N/A N/A&quot; #&gt; [14] &quot;Detroit 408 1,070 322 124 0 85 1 N/A N/A&quot; #&gt; [15] &quot;Grand Forks 189 496 202 0 0 40 2 N/A N/A&quot; #&gt; [16] &quot;Havre 183 39 28 98 0 2 0 N/A N/A&quot; #&gt; [17] &quot;Houlton 173 30 30 17 0 2 0 N/A N/A&quot; #&gt; [18] &quot;Spokane 230 208 67 68 0 24 0 N/A N/A&quot; #&gt; [19] &quot;Swanton 292 449 359 531 1 103 6 N/A N/A&quot; #&gt; [20] &quot;Northern Border Sectors Total 2,048 3,027 1,538 1,066 3 302 11 N/A **** N/A ****&quot; #&gt; [21] &quot;Big Bend (formerly Marfa) 500 6,002 3,346 40,852 45 2,847 11 26 1&quot; #&gt; [22] &quot;Del Rio 1,391 13,476 6,156 9,482 62 8,022 12 99 18&quot; #&gt; [23] &quot;El Centro 870 18,633 5,812 5,554 484 1,413 34 4 2&quot; #&gt; [24] &quot;El Paso 2,182 25,193 15,337 34,189 140 6,996 54 44 8&quot; #&gt; [25] &quot;Laredo 1,666 25,460 7,891 69,535 757 6,119 31 1,054 83&quot; #&gt; [26] &quot;Rio Grande Valley (formerly McAllen) 3,130 137,562 107,909 260,020 1,192 7,979 422 1,190 104&quot; #&gt; [27] &quot;San Diego 2,199 26,086 7,060 10,985 2,903 3,099 84 48 4&quot; #&gt; [28] &quot;Tucson 3,691 38,657 12,328 397,090 331 20,963 93 750 72&quot; #&gt; [29] &quot;Yuma 859 12,847 10,139 30,181 261 2,367 33 6 2&quot; #&gt; [30] &quot;Southwest Border Sectors Total** 16,605 303,916 175,978 857,888 6,174 59,805 774 3,221 294&quot; #&gt; [31] &quot;Nationwide Total*** 19,437 310,531 180,077 861,231 9,346 60,498 786 3,221 294&quot; #&gt; [32] &quot;* Agent staffing statistics depict FY17 on-board personnel data as of 9/30/2017&quot; #&gt; [33] &quot;** Southwest Border Sectors staffing statistics include: Big Bend, Del Rio, El Centro, El Paso, Laredo, Rio Grande Valley, San Diego, Tucson, Yuma, and the Special Operations Group.&quot; #&gt; [34] &quot;*** Nationwide staffing statistics include: All on-board Border Patrol agents in CBP&quot; #&gt; [35] &quot;**** Rescue and Death statistics are not tracked for Northern and Coastal Border Sectors.&quot; Based on the PDF, we want every row from Miami to Nationwide Total. But here we have several rows with the title of the table and the column names, and at the end we have the sentences with some details that we don’t need. To keep only the rows that we want, we can combine grep() and subsetting to find the rows from Miami to Nationwide Total and keep only those rows. We will use grep() to find which row has the text “Miami” and which has the text “Nationwide Total” and keep all rows between them (including those matched rows as well). Since each only appears once in the table we don’t need to worry about handling duplicate results. grep(&quot;Miami&quot;, sector_profile) #&gt; [1] 8 grep(&quot;Nationwide Total&quot;, sector_profile) #&gt; [1] 31 We’ll use square bracket notation to keep all rows between those two values (including each value). Since the data is a vector, not a data.frame, we don’t need a comma. sector_profile &lt;- sector_profile[grep(&quot;Miami&quot;, sector_profile):grep(&quot;Nationwide Total&quot;, sector_profile)] Note that we’re getting rid of the rows which had the column names. It’s easier to make the names ourselves than to deal with that mess. head(sector_profile) #&gt; [1] &quot;Miami 111 2,280 1,646 2,253 231 292 1 N/A N/A&quot; #&gt; [2] &quot;New Orleans 63 920 528 21 6 10 0 N/A N/A&quot; #&gt; [3] &quot;Ramey 38 388 387 3 2,932 89 0 N/A N/A&quot; #&gt; [4] &quot;Coastal Border Sectors Total 212 3,588 2,561 2,277 3,169 391 1 N/A **** N/A ****&quot; #&gt; [5] &quot;Blaine 296 288 237 0 0 9 0 N/A N/A&quot; #&gt; [6] &quot;Buffalo 277 447 293 228 2 37 2 N/A N/A&quot; The data now has only the rows we want but still doesn’t have any columns, it’s currently just a vector of strings. We want to make it into a data.frame to be able to work on it like we usually do. When looking at this data it is clear that where the division between columns is a bunch of white space. Take the first row for example, it says “Miami” then after lots of white spaces “111” than again with “2,280” and so on for the rest of the row. We’ll use this pattern of columns differentiated by white space to make “sector_profile” into a data.frame. We will use the function str_split_fixed() from the stringr package. This function is very similar to strsplit() except you can tell it how many columns to expect. We could have used this package earlier in Section 10 but chose not to to avoid introducing too many new packages in one lesson. install.packages(&quot;stringr&quot;) library(stringr) The syntax of str_split_fixed() is similar to strsplit() except the new parameter of the number of splits to expect. Looking at the PDF shows us that there are 10 columns so that’s the number we’ll use. Our split will be \" {2,}“. That is, a space that occurs two or more times. Since there are sectors with spaces in their name, we can’t have only one space, we need at least two. If you look carefully at the rows with sectors”Coast Border Sectors Total\" and “Northern Border Sectors Total”, the final two columns actually do not have two spaces between them because of the amount of * they have. Normally we’d want to fix this using gsub(), but those values will turn to NA anyway so we won’t bother in this case. sector_profile &lt;- str_split_fixed(sector_profile, &quot; {2,}&quot;, 10) If we check the head() we can see that we have the proper columns now but this still isn’t a data.frame and has no column names. head(sector_profile) #&gt; [,1] [,2] [,3] [,4] [,5] [,6] #&gt; [1,] &quot;Miami&quot; &quot;111&quot; &quot;2,280&quot; &quot;1,646&quot; &quot;2,253&quot; &quot;231&quot; #&gt; [2,] &quot;New Orleans&quot; &quot;63&quot; &quot;920&quot; &quot;528&quot; &quot;21&quot; &quot;6&quot; #&gt; [3,] &quot;Ramey&quot; &quot;38&quot; &quot;388&quot; &quot;387&quot; &quot;3&quot; &quot;2,932&quot; #&gt; [4,] &quot;Coastal Border Sectors Total&quot; &quot;212&quot; &quot;3,588&quot; &quot;2,561&quot; &quot;2,277&quot; &quot;3,169&quot; #&gt; [5,] &quot;Blaine&quot; &quot;296&quot; &quot;288&quot; &quot;237&quot; &quot;0&quot; &quot;0&quot; #&gt; [6,] &quot;Buffalo&quot; &quot;277&quot; &quot;447&quot; &quot;293&quot; &quot;228&quot; &quot;2&quot; #&gt; [,7] [,8] [,9] [,10] #&gt; [1,] &quot;292&quot; &quot;1&quot; &quot;N/A&quot; &quot;N/A&quot; #&gt; [2,] &quot;10&quot; &quot;0&quot; &quot;N/A&quot; &quot;N/A&quot; #&gt; [3,] &quot;89&quot; &quot;0&quot; &quot;N/A&quot; &quot;N/A&quot; #&gt; [4,] &quot;391&quot; &quot;1&quot; &quot;N/A **** N/A ****&quot; &quot;&quot; #&gt; [5,] &quot;9&quot; &quot;0&quot; &quot;N/A&quot; &quot;N/A&quot; #&gt; [6,] &quot;37&quot; &quot;2&quot; &quot;N/A&quot; &quot;N/A&quot; We can make it a data.frame just by putting it in data.frame(). To avoid making the columns into factors, we’ll set the parameter stringsAsFactors to FALSE. And we can assign the columns names using a vector of strings we can make. We’ll use the same column names as in the PDF but in lowercase and replacing spaces and parentheses with underscores. sector_profile &lt;- data.frame(sector_profile, stringsAsFactors = FALSE) names(sector_profile) &lt;- c(&quot;sector&quot;, &quot;agent_staffing&quot;, &quot;apprehensions&quot;, &quot;other_than_mexican_apprehensions&quot;, &quot;marijuana_pounds&quot;, &quot;cocaine_pounds&quot;, &quot;accepted_prosecutions&quot;, &quot;assaults&quot;, &quot;rescues&quot;, &quot;deaths&quot;) We have now take a table from a PDF and successfully scraped it using R to make a data.frame with all of it’s information. head(sector_profile) #&gt; sector agent_staffing apprehensions #&gt; 1 Miami 111 2,280 #&gt; 2 New Orleans 63 920 #&gt; 3 Ramey 38 388 #&gt; 4 Coastal Border Sectors Total 212 3,588 #&gt; 5 Blaine 296 288 #&gt; 6 Buffalo 277 447 #&gt; other_than_mexican_apprehensions marijuana_pounds cocaine_pounds #&gt; 1 1,646 2,253 231 #&gt; 2 528 21 6 #&gt; 3 387 3 2,932 #&gt; 4 2,561 2,277 3,169 #&gt; 5 237 0 0 #&gt; 6 293 228 2 #&gt; accepted_prosecutions assaults rescues deaths #&gt; 1 292 1 N/A N/A #&gt; 2 10 0 N/A N/A #&gt; 3 89 0 N/A N/A #&gt; 4 391 1 N/A **** N/A **** #&gt; 5 9 0 N/A N/A #&gt; 6 37 2 N/A N/A To really be able to work on this we’ll want to clean the columns to turn the values to numeric type but we can leave that until later. For now let’s write a function that replicates much of this work for the next tables. 11.2 Making a function As we’ve done before, we want to take the code we wrote for the specific case of the first table in this PDF and turn it into a function for the general case of other tables in the PDF. Let’s copy the code we used above then convert it to a function. sector_profile &lt;- border_patrol[1] sector_profile &lt;- strsplit(sector_profile, &quot;\\r\\n&quot;) sector_profile &lt;- sector_profile[[1]] sector_profile &lt;- sector_profile[grep(&quot;Miami&quot;, sector_profile):grep(&quot;Nationwide Total&quot;, sector_profile)] sector_profile &lt;- str_split_fixed(sector_profile, &quot; {2,}&quot;, 10) sector_profile &lt;- data.frame(sector_profile, stringsAsFactors = FALSE) names(sector_profile) &lt;- c(&quot;sector&quot;, &quot;agent_staffing&quot;, &quot;apprehensions&quot;, &quot;other_than_mexican_apprehensions&quot;, &quot;marijuana_pounds&quot;, &quot;cocaine_pounds&quot;, &quot;accepted_prosecutions&quot;, &quot;assaults&quot;, &quot;rescues&quot;, &quot;deaths&quot;) "],
["geocoding.html", "12 Geocoding 12.1 Geocoding a single address 12.2 Making a function 12.3 Geocoding officer shooting locations", " 12 Geocoding In Chapter 10 we got the address of every officer-involved shooting in Philadelphia. To be able to graph where each shooting occurred we need to convert the addresses into geographic coordinates, a process called geocoding. This type of activity is common in research studying the effect of place. For example, several recent studies have looked at the effect of marijuana dispensaries on crime around the dispensary. For these analyses they find the coordinates of each crime in the city and see if it occurred in a certain distance from the dispensary. Many crime data sets provide the coordinates of where each occurred, however sometimes the coordinates are missing - and other data such as marijuana dispensary locations give only the address - meaning that we need a way to find the coordinates of these locations. 12.1 Geocoding a single address In this chapter we will cover using the free geocoder from ArcGIS, a software that people frequently use when dealing primarily with mapping projects. Google Maps used to be easily usable in R but since 2018 requires an account to use it’s geocoder so we will not be using it. The URL for geocoding using ArcGIS is the following: https://geocode.arcgis.com/arcgis/rest/services/World/GeocodeServer/findAddressCandidates?f=json&amp;singleLine=ADDRESS&amp;outFields=Match_addr,Addr_type where instead of “ADDRESS” we put in the address whose coordinates we want. As an example, let’s look at Penn’s McNeil Building. https://geocode.arcgis.com/arcgis/rest/services/World/GeocodeServer/findAddressCandidates?f=json&amp;singleLine=38th%20St%20and%20Walnut%20St,%20Philadelphia,%20PA&amp;outFields=Match_addr,Addr_type Including spaces in the address causes errors so all spaces need to be replaced with %20. Let’s see what data we get back from this URL. Enter the URL above in your browser and you’ll see these results. It gives us a page with several important values. For our purposes we want the “lat” and “lon” sections which are the latitude and longitude parts of a location’s coordinates. This data is stored on the page in a JSON format which is a convenient (for computers to read) way data is stored online. We can concert it to a data.frame that we’re more familiar with using the package jsonlite. install.packages(&quot;jsonlite&quot;) We will use the fromJSON() function and enter in the URL right in the (). library(jsonlite) fromJSON(&quot;https://geocode.arcgis.com/arcgis/rest/services/World/GeocodeServer/findAddressCandidates?f=json&amp;singleLine=38th%20St%20and%20Walnut%20St,%20Philadelphia,%20PA&amp;outFields=Match_addr,Addr_type&quot;) #&gt; $spatialReference #&gt; $spatialReference$wkid #&gt; [1] 4326 #&gt; #&gt; $spatialReference$latestWkid #&gt; [1] 4326 #&gt; #&gt; #&gt; $candidates #&gt; address #&gt; 1 S 38th St &amp; Walnut St, Philadelphia, Pennsylvania, 19104 #&gt; 2 Walnut St, Philadelphia, Pennsylvania, 19102 #&gt; 3 Walnut St, Philadelphia, Pennsylvania, 19107 #&gt; 4 Walnut St, Philadelphia, Pennsylvania, 19139 #&gt; 5 Walnut St, Philadelphia, Pennsylvania, 19104 #&gt; 6 Walnut St, Philadelphia, Pennsylvania, 19106 #&gt; 7 Walnut St, Philadelphia, Pennsylvania, 19103 #&gt; 8 E State St &amp; N Walnut St, Kennett Square, Pennsylvania, 19348 #&gt; 9 E State St &amp; S Walnut St, Kennett Square, Pennsylvania, 19348 #&gt; 10 State Rd &amp; Walnut Ln, Telford, Pennsylvania, 18969 #&gt; 11 State Rd &amp; Walnut Ave E, Bensalem, Pennsylvania, 19020 #&gt; 12 Walnut St, Middleport, Pennsylvania, 17953 #&gt; 13 E Street Rd &amp; N Walnut Rd, Kennett Square, Pennsylvania, 19348 #&gt; location.x location.y score #&gt; 1 -75.19868 39.95362 99.61 #&gt; 2 -75.16610 39.94957 89.84 #&gt; 3 -75.15921 39.94872 89.84 #&gt; 4 -75.22944 39.95745 89.84 #&gt; 5 -75.19633 39.95332 89.84 #&gt; 6 -75.14852 39.94737 89.84 #&gt; 7 -75.17449 39.95063 89.84 #&gt; 8 -75.70560 39.84894 88.18 #&gt; 9 -75.70500 39.84917 88.18 #&gt; 10 -75.32272 40.33865 87.85 #&gt; 11 -74.97302 40.06046 87.54 #&gt; 12 -76.08395 40.72661 87.25 #&gt; 13 -75.70581 39.87566 87.23 #&gt; attributes.Match_addr #&gt; 1 S 38th St &amp; Walnut St, Philadelphia, Pennsylvania, 19104 #&gt; 2 Walnut St, Philadelphia, Pennsylvania, 19102 #&gt; 3 Walnut St, Philadelphia, Pennsylvania, 19107 #&gt; 4 Walnut St, Philadelphia, Pennsylvania, 19139 #&gt; 5 Walnut St, Philadelphia, Pennsylvania, 19104 #&gt; 6 Walnut St, Philadelphia, Pennsylvania, 19106 #&gt; 7 Walnut St, Philadelphia, Pennsylvania, 19103 #&gt; 8 E State St &amp; N Walnut St, Kennett Square, Pennsylvania, 19348 #&gt; 9 E State St &amp; S Walnut St, Kennett Square, Pennsylvania, 19348 #&gt; 10 State Rd &amp; Walnut Ln, Telford, Pennsylvania, 18969 #&gt; 11 State Rd &amp; Walnut Ave E, Bensalem, Pennsylvania, 19020 #&gt; 12 Walnut St, Middleport, Pennsylvania, 17953 #&gt; 13 E Street Rd &amp; N Walnut Rd, Kennett Square, Pennsylvania, 19348 #&gt; attributes.Addr_type extent.xmin extent.ymin extent.xmax extent.ymax #&gt; 1 StreetInt -75.19968 39.95262 -75.19768 39.95462 #&gt; 2 StreetName -75.16710 39.94857 -75.16510 39.95057 #&gt; 3 StreetName -75.16021 39.94772 -75.15821 39.94972 #&gt; 4 StreetName -75.23044 39.95645 -75.22844 39.95845 #&gt; 5 StreetName -75.19733 39.95232 -75.19533 39.95432 #&gt; 6 StreetName -75.14952 39.94637 -75.14752 39.94837 #&gt; 7 StreetName -75.17549 39.94963 -75.17349 39.95163 #&gt; 8 StreetInt -75.70660 39.84794 -75.70460 39.84994 #&gt; 9 StreetInt -75.70600 39.84817 -75.70400 39.85017 #&gt; 10 StreetInt -75.32372 40.33765 -75.32172 40.33965 #&gt; 11 StreetInt -74.97402 40.05946 -74.97202 40.06146 #&gt; 12 StreetName -76.08495 40.72561 -76.08295 40.72761 #&gt; 13 StreetInt -75.70681 39.87466 -75.70481 39.87666 It returns a list of objects. This is a named list meaning that we can grab the part of the list we want using dollar sign notation as if it were a column in a data.frame. In this case we want the part of the object called “candidates”. To avoid having a very long line of code, let’s call the list fromJSON() returns “address_coordinate” and grab the “candidates” object from that list. address_coordinates &lt;- fromJSON(&quot;https://geocode.arcgis.com/arcgis/rest/services/World/GeocodeServer/findAddressCandidates?f=json&amp;singleLine=38th%20St%20and%20Walnut%20St,%20Philadelphia,%20PA&amp;outFields=Match_addr,Addr_type&quot;) address_coordinates$candidates #&gt; address #&gt; 1 S 38th St &amp; Walnut St, Philadelphia, Pennsylvania, 19104 #&gt; 2 Walnut St, Philadelphia, Pennsylvania, 19102 #&gt; 3 Walnut St, Philadelphia, Pennsylvania, 19107 #&gt; 4 Walnut St, Philadelphia, Pennsylvania, 19139 #&gt; 5 Walnut St, Philadelphia, Pennsylvania, 19104 #&gt; 6 Walnut St, Philadelphia, Pennsylvania, 19106 #&gt; 7 Walnut St, Philadelphia, Pennsylvania, 19103 #&gt; 8 E State St &amp; N Walnut St, Kennett Square, Pennsylvania, 19348 #&gt; 9 E State St &amp; S Walnut St, Kennett Square, Pennsylvania, 19348 #&gt; 10 State Rd &amp; Walnut Ln, Telford, Pennsylvania, 18969 #&gt; 11 State Rd &amp; Walnut Ave E, Bensalem, Pennsylvania, 19020 #&gt; 12 Walnut St, Middleport, Pennsylvania, 17953 #&gt; 13 E Street Rd &amp; N Walnut Rd, Kennett Square, Pennsylvania, 19348 #&gt; location.x location.y score #&gt; 1 -75.19868 39.95362 99.61 #&gt; 2 -75.16610 39.94957 89.84 #&gt; 3 -75.15921 39.94872 89.84 #&gt; 4 -75.22944 39.95745 89.84 #&gt; 5 -75.19633 39.95332 89.84 #&gt; 6 -75.14852 39.94737 89.84 #&gt; 7 -75.17449 39.95063 89.84 #&gt; 8 -75.70560 39.84894 88.18 #&gt; 9 -75.70500 39.84917 88.18 #&gt; 10 -75.32272 40.33865 87.85 #&gt; 11 -74.97302 40.06046 87.54 #&gt; 12 -76.08395 40.72661 87.25 #&gt; 13 -75.70581 39.87566 87.23 #&gt; attributes.Match_addr #&gt; 1 S 38th St &amp; Walnut St, Philadelphia, Pennsylvania, 19104 #&gt; 2 Walnut St, Philadelphia, Pennsylvania, 19102 #&gt; 3 Walnut St, Philadelphia, Pennsylvania, 19107 #&gt; 4 Walnut St, Philadelphia, Pennsylvania, 19139 #&gt; 5 Walnut St, Philadelphia, Pennsylvania, 19104 #&gt; 6 Walnut St, Philadelphia, Pennsylvania, 19106 #&gt; 7 Walnut St, Philadelphia, Pennsylvania, 19103 #&gt; 8 E State St &amp; N Walnut St, Kennett Square, Pennsylvania, 19348 #&gt; 9 E State St &amp; S Walnut St, Kennett Square, Pennsylvania, 19348 #&gt; 10 State Rd &amp; Walnut Ln, Telford, Pennsylvania, 18969 #&gt; 11 State Rd &amp; Walnut Ave E, Bensalem, Pennsylvania, 19020 #&gt; 12 Walnut St, Middleport, Pennsylvania, 17953 #&gt; 13 E Street Rd &amp; N Walnut Rd, Kennett Square, Pennsylvania, 19348 #&gt; attributes.Addr_type extent.xmin extent.ymin extent.xmax extent.ymax #&gt; 1 StreetInt -75.19968 39.95262 -75.19768 39.95462 #&gt; 2 StreetName -75.16710 39.94857 -75.16510 39.95057 #&gt; 3 StreetName -75.16021 39.94772 -75.15821 39.94972 #&gt; 4 StreetName -75.23044 39.95645 -75.22844 39.95845 #&gt; 5 StreetName -75.19733 39.95232 -75.19533 39.95432 #&gt; 6 StreetName -75.14952 39.94637 -75.14752 39.94837 #&gt; 7 StreetName -75.17549 39.94963 -75.17349 39.95163 #&gt; 8 StreetInt -75.70660 39.84794 -75.70460 39.84994 #&gt; 9 StreetInt -75.70600 39.84817 -75.70400 39.85017 #&gt; 10 StreetInt -75.32372 40.33765 -75.32172 40.33965 #&gt; 11 StreetInt -74.97402 40.05946 -74.97202 40.06146 #&gt; 12 StreetName -76.08495 40.72561 -76.08295 40.72761 #&gt; 13 StreetInt -75.70681 39.87466 -75.70481 39.87666 The “candidates” is a data.frame which includes 12 (slightly) different coordinates for our address. The first one is the one we want and if you look at the “score” column you can see it has the highest score of those 12. The ArcGIS geocoder provides a number of potential coordinates for an inputted address and ranks them in order of how confident it is that this is the address you want. Since we just want the top address - the “most confident” one - so we will just keep the first row. Since we are grabbing the first row of a data.frame, our square bracket notation must be [row, column]. For row we put 1 since we want the first row. Since we want every column we can leave it blank but make sure to keep the comma. address_coordinates &lt;- fromJSON(&quot;https://geocode.arcgis.com/arcgis/rest/services/World/GeocodeServer/findAddressCandidates?f=json&amp;singleLine=38th%20St%20and%20Walnut%20St,%20Philadelphia,%20PA&amp;outFields=Match_addr,Addr_type&quot;) address_coordinates &lt;- address_coordinates$candidates address_coordinates &lt;- address_coordinates[1, ] address_coordinates #&gt; address location.x #&gt; 1 S 38th St &amp; Walnut St, Philadelphia, Pennsylvania, 19104 -75.19868 #&gt; location.y score #&gt; 1 39.95362 99.61 #&gt; attributes.Match_addr #&gt; 1 S 38th St &amp; Walnut St, Philadelphia, Pennsylvania, 19104 #&gt; attributes.Addr_type extent.xmin extent.ymin extent.xmax extent.ymax #&gt; 1 StreetInt -75.19968 39.95262 -75.19768 39.95462 This data.frame has something we’ve never seen before. It has columns that are themselves data.frames. For example, the column “location” is a data.frame with the x- and y-coordinates that we want. We can select this exactly as we do with any column but instead of returning a vector of values it returns a data.frame. address_coordinates$location #&gt; x y #&gt; 1 -75.19868 39.95362 Since our end goal was to get the coordinates of an address, the data.frame in the “location” column is exactly what we want. It took a few steps but now we have code that returns the coordinates of an address. 12.2 Making a function We want to geocode every single address from the officer-involved shooting data. As with most things where we do the same thing many times except for one minor change - here, the address being geocoded - we will make a function to help us. Let’s start by copying the code used to geocode a single address. address_coordinates &lt;- fromJSON(&quot;https://geocode.arcgis.com/arcgis/rest/services/World/GeocodeServer/findAddressCandidates?f=json&amp;singleLine=38th%20St%20and%20Walnut%20St,%20Philadelphia,%20PA&amp;outFields=Match_addr,Addr_type&quot;) address_coordinates &lt;- address_coordinates$candidates address_coordinates &lt;- address_coordinates[1, ] address_coordinates$location #&gt; x y #&gt; 1 -75.19868 39.95362 Now we can make the skeleton of a function without including any code. What do we want to input to the function and what do we want it to return? We want it so we input an address and it returns the coordinates of that address. We can call the function “geocode_address”, the input “address” and the returning value “address_coordinates” just to stay consistent with the code we already wrote. geocode_address &lt;- function(address) { return(address_coordinates) } Now we can add the code. geocode_address &lt;- function(address) { address_coordinates &lt;- fromJSON(&quot;https://geocode.arcgis.com/arcgis/rest/services/World/GeocodeServer/findAddressCandidates?f=json&amp;singleLine=38th%20St%20and%20Walnut%20St,%20Philadelphia,%20PA&amp;outFields=Match_addr,Addr_type&quot;) address_coordinates &lt;- address_coordinates$candidates address_coordinates &lt;- address_coordinates[1, ] address_coordinates$location return(address_coordinates) } Finally we need to replace the value in fromJSON() which is for a specific address with something that works for any address we input. Since the URL is in the form https://geocode.arcgis.com/arcgis/rest/services/World/GeocodeServer/findAddressCandidates?f=json&amp;singleLine=ADDRESS&amp;outFields=Match_addr,Addr_type we can use the paste() function to combine the address inputted with the URL format. There is one step necessary before that, however. Since spaces cause issues in the data, we need to replace every space in the address with %20. We can do that using gsub() which is perfect for replacing characters. Let’s try a simple example using gsub() before including it in our function. We just want to find every \" \" and replace it with “%20”. We will use the address for the McNeil Building as the example. gsub(&quot; &quot;, &quot;%20&quot;, &quot;38th St and Walnut St, Philadelphia, PA&quot;) #&gt; [1] &quot;38th%20St%20and%20Walnut%20St,%20Philadelphia,%20PA&quot; It works so we can use the code to fix the address before putting it in the URL. To avoid having very long lines of code, we can break down the code into smaller pieces. We want to use paste() to combine the parts of the URL with the address and have that as the input in fromJSON(). Let’s do that in two steps. First we do the paste(), saving it in an object we can call “url”, and then use “url” as our input in fromJSON(). Since we do not want spaces in the URL, we need to set the sep parameter in paste() to \"\". geocode_address &lt;- function(address) { address &lt;- gsub(&quot; &quot;, &quot;%20&quot;, address) url &lt;- paste(&quot;https://geocode.arcgis.com/arcgis/rest/services/World/GeocodeServer/findAddressCandidates?f=json&amp;singleLine=&quot;, address, &quot;&amp;outFields=Match_addr,Addr_type&quot;, sep = &quot;&quot;) address_coordinates &lt;- fromJSON(url) address_coordinates &lt;- address_coordinates$candidates address_coordinates &lt;- address_coordinates[1, ] address_coordinates &lt;- address_coordinates$location return(address_coordinates) } We can try it using the same address we did earlier, “38th St and Walnut St, Philadelphia, PA”, the address of Penn’s McNeil Building. geocode_address(&quot;38th St and Walnut St, Philadelphia, PA&quot;) #&gt; x y #&gt; 1 -75.19868 39.95362 It returns the same data.frame as earlier so our function works! 12.3 Geocoding officer shooting locations We now have a function capable of returning the coordinates of every location in our officer-involved shooting data. We can write a for loop to go through every row of data and get the coordinates for that row’s location. Let’s load in the officer shooting data we made earlier. setwd(here::here(&quot;data&quot;)) load(&quot;officer_shootings.rda&quot;) Before we do that we need to fix some issues in the locations column. The main issue is that several of the shootings have the location labeled as “withheld” in the table we scraped but the address does exist inside the PDF itself. Let’s check first how many times the word “withheld” (with the W capitalized or not) or an empty string \"\" exists in the “location” column. table(officer_shootings$location %in% c(&quot;&quot;, &quot;withheld&quot;, &quot;Withheld&quot;)) #&gt; #&gt; FALSE TRUE #&gt; 449 15 Above we are saying “how many times do the values”“,”withheld“, or”Withheld\" appear in the column “location”. The answer is 15 times. We can print out the shooting number of the rows with one of those values to make it easy to check the PDF. We can use square bracket [] subsetting to return the rows in the “shooting_number” column where the location is one of those values above. officer_shootings$shooting_number[officer_shootings$location %in% c(&quot;&quot;, &quot;withheld&quot;, &quot;Withheld&quot;)] #&gt; [1] &quot;16-18&quot; &quot;16-26&quot; &quot;10-06&quot; &quot;09-25&quot; &quot;09-27&quot; &quot;09-76&quot; &quot;08-06&quot; &quot;08-18&quot; #&gt; [9] &quot;08-30&quot; &quot;08-35&quot; &quot;08-40&quot; &quot;08-60&quot; &quot;08-70&quot; &quot;08-74&quot; &quot;07-27&quot; We will also use square bracket [] notation to replace the value in the “location” column with the correct address that we read manually in the PDF. Let’s start with the first shooting in the list, number “16-18”. Using square bracket notation we can see which value is in the “location” column for the row whose “shooting_number” is “16-18”. officer_shootings$location[officer_shootings$shooting_number == &quot;16-18&quot;] #&gt; [1] &quot;withheld&quot; Looking into the PDF we can see that the correct address is “3200 block of Wellington Street”. Let’s assign that address to the “location” column in the row for that shooting. officer_shootings$location[officer_shootings$shooting_number == &quot;16-18&quot;] &lt;- &quot;3200 block of Wellington Street&quot; And we can check if it worked. officer_shootings$location[officer_shootings$shooting_number == &quot;16-18&quot;] #&gt; [1] &quot;3200 block of Wellington Street&quot; We need to do the same for the other 14 values with missing locations. Several of these text descriptions of the incidents contain the location information. Let’s fill those in. officer_shootings$location[officer_shootings$shooting_number == &quot;08-06&quot;] &lt;- &quot;200 block of Clapier Street&quot; officer_shootings$location[officer_shootings$shooting_number == &quot;08-18&quot;] &lt;- &quot;900 block of E. Slocum Street&quot; officer_shootings$location[officer_shootings$shooting_number == &quot;08-30&quot;] &lt;- &quot;700 block of W. Rockland Street&quot; officer_shootings$location[officer_shootings$shooting_number == &quot;08-40&quot;] &lt;- &quot;5400 Jefferson Street&quot; officer_shootings$location[officer_shootings$shooting_number == &quot;08-60&quot;] &lt;- &quot;3000 Memphis Street&quot; officer_shootings$location[officer_shootings$shooting_number == &quot;08-70&quot;] &lt;- &quot;1300 block of S. 29th Street&quot; officer_shootings$location[officer_shootings$shooting_number == &quot;08-74&quot;] &lt;- &quot;5600 block of N. Mascher Street&quot; officer_shootings$location[officer_shootings$shooting_number == &quot;10-06&quot;] &lt;- &quot;Howard and Grange Street&quot; Six shootings (“07-27”, “08-35”, “09-25”, “09-27”, “09-76”, “16-26”) do not have an address in the PDF so we can’t fix them. Shooting number “17-08” is a strange one. The description says that there were shootings at two locations because the suspect fled after the first shooting. Since the second shooting was in Delaware, we will use the address of the first shooting, “5600 Whitby Avenue”. officer_shootings$location[officer_shootings$shooting_number == &quot;17-08&quot;] &lt;- &quot;5600 Whitby Avenue&quot; Shooting number “15-06” is unusual as it has quotes around the “A”. This will cause issues when geocoding so we need to remove those quotes. The “A” probably refers to A Street so we can replace it as such. officer_shootings$location[officer_shootings$shooting_number == &quot;15-06&quot;] &lt;- &quot;A Street &amp; Somerset Street&quot; There are a few more issues we can use gsub() to fix. Some of the addresses say “xxx block of”. We need to remove \" block of\" from the text. A few addresses also say “Rear Alley of” or “near” an address. We can delete those words as well. We can do this using three separate gsub()s or in a single gsub() using the | which stands for “or”. The | says look for things on the left or right of the |. For all our values we want to replace them with nothing, or in gsub() terms, an empty string \"\". officer_shootings$location &lt;- gsub(&quot; block of|Rear Alley of |near &quot;, &quot;&quot;, officer_shootings$location, ignore.case = TRUE) We must paste the string “, Philadelphia, PA” to the end of each address so when we geocode it ArcGIS knows these addresses are in Philly. officer_shootings$location &lt;- paste(officer_shootings$location, &quot;, Philadelphia, PA&quot;, sep = &quot;&quot;) There are still some addresses that require manual fixing, such as the one reading “5700 N. Park street/5700 N. Broad street”. Since this work requires reading through each address and seeing if it is accurate and can be rewritten, I won’t dwell on it any further. This kind of work, manually checking data, is important even when using a programming language like R. R can only do what we tell it to do and isn’t smart enough to recognize an issue that we can easily see. Since I am not going to clean the remaining street issues, we will likely not be able to geocode those addresses. How big of an issue is this? In an example like this where we have fewer than 500 events, it can be important if we fail to geocode even a few dozen shootings. So this kind of data would mean manually inspecting and correction the data is important. If instead you look at crime data with millions of rows, it likely wouldn’t be worth it to manually inspect so many values. We can now write a for loop to go through every row in our data and geocode that address. The function geocode_address() we made returns a data.frame with one column for the longitude and one for the latitude. To make it so we only work with the data.frame “officer_shootings” we can save the output of geocode_address() to a temporary file and add each of the columns it produces to a column in “officer_shootings”. We need to make columns for the coordinates in “officer_shootings” now to be filled in during the for loop. We can call them “lon” and “lat” for the longitude and latitude values we get from the coordinates. When making a new column which you will fill through a for loop, it is a good assign to start by assigning the column NA. That way any row that you don’t fill in the loop (such as if there is no match for the address), will still be NA. NAs are easy to detect in your data for future subsetting or to ignore in a mathematical operation. officer_shootings$lon &lt;- NA officer_shootings$lat &lt;- NA Let’s start with an example using the first row. Inputting the address from the first row gives a data.frame with the coordinates. Let’s now save that output to an object we call “temp”. temp &lt;- geocode_address(officer_shootings$location[1]) temp #&gt; x y #&gt; 1 -75.22087 39.95046 We can use square bracket [] notation to assign the value from the “x” column of “temp” to our “lon” column in “officers_shootings” and do the same for the “y” and “lat” columns. Since we got the address from the first row, we need to put the coordinates in the first row so they are with the right address. officer_shootings$lon[1] &lt;- temp$x officer_shootings$lat[1] &lt;- temp$y And we can check the first 6 rows to make sure the first row is the only one with values in these new columns. head(officer_shootings) #&gt; shooting_number location #&gt; 1 19-04 4900 Hazel Avenue, Philadelphia, PA #&gt; 2 19-06 1300 Kater Street, Philadelphia, PA #&gt; 3 19-09 Bridge Street &amp; Roosevelt Boulevard, Philadelphia, PA #&gt; 4 19 11 2100 Taney Terrace, Philadelphia, PA #&gt; 5 19-13 1800 N. Broad Street, Philadelphia, PA #&gt; 6 19 14 3400 G Street, Philadelphia, PA #&gt; dates lon lat #&gt; 1 2019-03-06 -75.22087 39.95046 #&gt; 2 2019-03-28 NA NA #&gt; 3 2019-04-20 NA NA #&gt; 4 2019-04-25 NA NA #&gt; 5 2019-05-11 NA NA #&gt; 6 2019-05-20 NA NA Since we are geocoding a lot of addresses, this may take some time. for (i in 1:nrow(officer_shootings)) { temp &lt;- geocode_address(officer_shootings$location[i]) officer_shootings$lon[i] &lt;- temp$x officer_shootings$lat[i] &lt;- temp$y } Now it appears that we have longitude and latitude for every incident. We should check that they all look sensible. summary(officer_shootings$lat) #&gt; Min. 1st Qu. Median Mean 3rd Qu. Max. #&gt; -20.57 39.96 39.99 39.80 40.02 53.61 summary(officer_shootings$lon) #&gt; Min. 1st Qu. Median Mean 3rd Qu. Max. #&gt; -122.86 -75.19 -75.16 -73.62 -75.13 121.05 What is odd about these results? There are no NA values in either column! That does not make sense because we know some of the rows have non-addresses such as “withheld”. What happened is that when ArcGIS couldn’t find an address match it just gave us the generic coordinates for the city of Philly. Normally we would need to remove those rows but we will keep them in for now and look at the strange pattern caused by this in the section on mapping. Another check is to make a simple scatterplot of the data. Since all the shootings occurred in Philly, they should be relatively close to each other. If there are dots far from the rest, that is probably a geocoding issue. plot(officer_shootings$lon, officer_shootings$lat) Most points are clustered around 39-40 degrees latitude and -75 degrees longitude with some exceptions. This is likely due to a geocoding issue with our geocoder finding the wrong address. For your own research, and considering the small number of values in this data, you should check the address to try to get them all geocoded properly. Here, we will simply remove all rows outside this -75 longitude and 39-40 latitude range. Let’s keep only rows with a latitude lower than 45 and a longitude less than -70 and higher than -76 officer_shootings &lt;- officer_shootings[officer_shootings$lat &lt; 45, ] officer_shootings &lt;- officer_shootings[officer_shootings$lon &lt; -70, ] officer_shootings &lt;- officer_shootings[officer_shootings$lon &gt; -76, ] Now we can check the summary() function again to see if all the values are in their normal ranges. summary(officer_shootings$lat) #&gt; Min. 1st Qu. Median Mean 3rd Qu. Max. #&gt; 39.89 39.97 39.99 39.99 40.02 40.10 summary(officer_shootings$lon) #&gt; Min. 1st Qu. Median Mean 3rd Qu. Max. #&gt; -75.30 -75.19 -75.16 -75.16 -75.13 -74.98 These values look correct. We can make another scatterplot as a second check. plot(officer_shootings$lon, officer_shootings$lat) Two shootings have inaccurate latitudes. Let’s drop any latitude that is greater than 39. officer_shootings &lt;- officer_shootings[officer_shootings$lat &gt; 39, ] To finish this lesson we want to save the “officer_shootings” data.frame to use in future lessons. I am going to make a new object called “officer_shootings_geocoded” that is a copy of “officer_shootings” just so I can rerun this lesson and it will work properly (as it should start without any geocoded values). If this was a real project you would likely just save the object as “officer_shootings” to have fewer objects to manage. officer_shootings_geocoded &lt;- officer_shootings setwd(here::here(&quot;data&quot;)) save(officer_shootings_geocoded, file = &quot;officer_shootings_geocoded.rda&quot;) In the next lesson we’ll start mapping these shootings. For now, here is a map of every shooting we managed to geocode. library(ggmap) philly_map &lt;- ggmap(get_map(c(-75.288486, 39.868285, -74.950965, 40.138251), source = &quot;stamen&quot;)) philly_map + geom_point(aes(x = lon, y = lat), data = officer_shootings, alpha = 0.5, color = &quot;darkred&quot;, size = 1) #&gt; Warning: Removed 2 rows containing missing values (geom_point). "],
["graphing-intro.html", "13 Graphing with ggplot2 13.1 What does the data look like? 13.2 Graphing data 13.3 Time-Series Plots 13.4 Color blindness", " 13 Graphing with ggplot2 We’ve made some simple graphs earlier, in this lesson we will use the package ggplot2 to make simple and elegant looking graphs. The ‘gg’ part of ggplot2 stands for ‘grammar of graphics’ which is the idea that most graphs can be made using the same few ‘pieces’. We’ll get into those pieces during this lesson. For a useful cheatsheet for this package see here install.packages(&quot;ggplot2&quot;) library(ggplot2) When working with new data, It’s often useful to quickly graph the data to try to understand what you’re working with. It is also useful when understanding how much to trust the data. The data we will work on is data about alcohol consumption in U.S. states from 1977-2016 from the National Institute of Health. It contains the per capita alcohol consumption for each state for every year. More details on the data are available here. Their method to determine per capita consumption is amount of alcohol sold / number of people aged 14+ living in the state. We’ll return to this method at the end to discuss how much we trust the data. Now we need to load the data. load(&quot;data/apparent_per_capita_alcohol_consumption.rda&quot;) The name of the file is quite long so for convenience let’s copy it to a new object with a better name. alcohol &lt;- apparent_per_capita_alcohol_consumption The original data has every state, region, and the US as a whole. For this lesson we’re using data subsetted to just include states. For now let’s just look at Pennsylvania. penn_alcohol &lt;- alcohol[alcohol$state == &quot;pennsylvania&quot;, ] 13.1 What does the data look like? Before graphing, it’s helpful to see what the data includes. An important thing to check is what variables are available and the units of these variables. names(penn_alcohol) #&gt; [1] &quot;state&quot; #&gt; [2] &quot;year&quot; #&gt; [3] &quot;ethanol_beer_gallons_per_capita&quot; #&gt; [4] &quot;ethanol_wine_gallons_per_capita&quot; #&gt; [5] &quot;ethanol_spirit_gallons_per_capita&quot; #&gt; [6] &quot;ethanol_all_drinks_gallons_per_capita&quot; #&gt; [7] &quot;number_of_beers&quot; #&gt; [8] &quot;number_of_glasses_wine&quot; #&gt; [9] &quot;number_of_shots_liquor&quot; #&gt; [10] &quot;number_of_drinks_total&quot; summary(penn_alcohol) #&gt; state year ethanol_beer_gallons_per_capita #&gt; Length:40 Length:40 Min. :1.210 #&gt; Class :character Class :character 1st Qu.:1.310 #&gt; Mode :character Mode :character Median :1.350 #&gt; Mean :1.346 #&gt; 3rd Qu.:1.380 #&gt; Max. :1.450 #&gt; ethanol_wine_gallons_per_capita ethanol_spirit_gallons_per_capita #&gt; Min. :0.1700 Min. :0.4500 #&gt; 1st Qu.:0.1875 1st Qu.:0.5050 #&gt; Median :0.2100 Median :0.5950 #&gt; Mean :0.2250 Mean :0.5910 #&gt; 3rd Qu.:0.2350 3rd Qu.:0.6725 #&gt; Max. :0.3300 Max. :0.7400 #&gt; ethanol_all_drinks_gallons_per_capita number_of_beers #&gt; Min. :1.850 Min. :286.8 #&gt; 1st Qu.:2.035 1st Qu.:310.5 #&gt; Median :2.200 Median :320.0 #&gt; Mean :2.163 Mean :319.0 #&gt; 3rd Qu.:2.315 3rd Qu.:327.1 #&gt; Max. :2.390 Max. :343.7 #&gt; number_of_glasses_wine number_of_shots_liquor number_of_drinks_total #&gt; Min. :33.74 Min. : 93.43 Min. :394.7 #&gt; 1st Qu.:37.21 1st Qu.:104.85 1st Qu.:434.1 #&gt; Median :41.67 Median :123.54 Median :469.3 #&gt; Mean :44.65 Mean :122.71 Mean :461.4 #&gt; 3rd Qu.:46.64 3rd Qu.:139.63 3rd Qu.:493.9 #&gt; Max. :65.49 Max. :153.64 Max. :509.9 head(penn_alcohol) #&gt; state year ethanol_beer_gallons_per_capita #&gt; 1521 pennsylvania 2016 1.31 #&gt; 1522 pennsylvania 2015 1.31 #&gt; 1523 pennsylvania 2014 1.32 #&gt; 1524 pennsylvania 2013 1.34 #&gt; 1525 pennsylvania 2012 1.36 #&gt; 1526 pennsylvania 2011 1.37 #&gt; ethanol_wine_gallons_per_capita ethanol_spirit_gallons_per_capita #&gt; 1521 0.33 0.72 #&gt; 1522 0.32 0.70 #&gt; 1523 0.32 0.70 #&gt; 1524 0.31 0.68 #&gt; 1525 0.31 0.67 #&gt; 1526 0.30 0.66 #&gt; ethanol_all_drinks_gallons_per_capita number_of_beers #&gt; 1521 2.36 310.5185 #&gt; 1522 2.33 310.5185 #&gt; 1523 2.34 312.8889 #&gt; 1524 2.33 317.6296 #&gt; 1525 2.34 322.3704 #&gt; 1526 2.33 324.7407 #&gt; number_of_glasses_wine number_of_shots_liquor number_of_drinks_total #&gt; 1521 65.48837 149.4891 503.4667 #&gt; 1522 63.50388 145.3366 497.0667 #&gt; 1523 63.50388 145.3366 499.2000 #&gt; 1524 61.51938 141.1841 497.0667 #&gt; 1525 61.51938 139.1079 499.2000 #&gt; 1526 59.53488 137.0316 497.0667 So each row of the data is a single year of data for Pennsylvania. It includes alcohol consumption for wine, liquor, beer, and total drinks - both as gallons of ethanol (a hard unit to interpret) and more traditional measures such as glasses of wine. The original data only included the gallons of ethanol data which I converted to the more understandable units. If you encounter data with odd units, it is a good idea to convert it to something easier to understand - especially if you intend to show someone else the data or results! 13.2 Graphing data To make a simple plot using ggplot(), all you need to do is specify the data set and the variables you want to plot. From there you add on pieces of the graph using the + symbol and then specify what you want added. For ggplot() we need to specify 4 things The data set - this is the very first thing you’ll write The x-axis variable The y-axis variable The type of graph - e.g. line, point, etc. Some useful types of graphs are geom_point() - A point graph, can be used for scatter plots geom_line() - A line graph geom_smooth() - Adds a regression line to the graph +geom_bar() - A barplot 13.3 Time-Series Plots Let’s start with a time-series of beer consumption in Pennsylvania. In time-series plots the x-axis is always the time variable while the y-axis is the variable whose trend over time is what we’re interested in. When you see a graph showing crime rates over time, this is the type of graph you’re looking at. The code below starts by writing our data set name. Then says what our x- and y-axis variables are called. The x- and y-axis variables are within parentheses of the function called aes(). aes() stands for aesthetic and what’s included inside here describes how the graph will look. It’s not intuitive to remember, but you need to included this. ggplot(penn_alcohol, aes(x = year, y = number_of_beers)) Note that on the x-axis it prints out every single year and makes it completely unreadable. That is because the “year” column is a character type, so R thinks each year is its own category. It prints every single year because it thinks we want every category shown. To fix this we can make the column numeric and ggplot() will be smarter about printing fewer years. penn_alcohol$year &lt;- as.numeric(penn_alcohol$year) ggplot(penn_alcohol, aes(x = year, y = number_of_beers)) When we run it we get our graph. It includes the variable names for each axis and shows the range of data through the tick marks. What is missing is the actual data. For that we need to specify what type of graph it is. We literally add it with the + followed by the type of graph we want. Make sure that the + is at the end of a line, not the start of one. Starting a line with the + will not work. Let’s start with point and line graphs. ggplot(penn_alcohol, aes(x = year, y = number_of_beers)) + geom_point() ggplot(penn_alcohol, aes(x = year, y = number_of_beers)) + geom_line() We can also combine different types of graphs. ggplot(penn_alcohol, aes(x = year, y = number_of_beers)) + geom_point() + geom_line() It looks like there’s a huge change in beer consumption over time. But look at where they y-axis starts. It starts around 280 so really that change is only ~60 beers. That’s because when graphs don’t start at 0, it makes small changes appear big. We can fix this by forcing the y-axis to begin at 0. We can add expand_limits(y = 0) to the graph to say that the value 0 must always appear on the y-axis, even if no data is close to that value. ggplot(penn_alcohol, aes(x = year, y = number_of_beers)) + geom_point() + geom_line() + expand_limits(y = 0) Now that graphs shows what looks like nearly no change even though that is also not true. Which graph is best? It’s hard to say. Inside the types of graphs we can change how it is displayed. As with using plot(), we can specify the color and size of our lines or points. ggplot(penn_alcohol, aes(x = year, y = number_of_beers)) + geom_line(color = &quot;forestgreen&quot;, size = 1.3) Some other useful features are changing the axis labels and the graph title. Unlike in plot() we do not need to include it in the () of ggplot() but must use their own functions to add them to the graph. xlab() - x-axis label ylab() - y-axis label ggtitle() - graph title ggplot(penn_alcohol, aes(x = year, y = number_of_beers)) + geom_line(color = &quot;forestgreen&quot;, size = 1.3) + xlab(&quot;Year&quot;) + ylab(&quot;Number of Beers&quot;) + ggtitle(&quot;PA Annual Beer Consumption Per Capita (1977-2016)&quot;) Making a scatter plot simply requires changing the x-axis from year to another numerical variable and using geom_point(). ggplot(penn_alcohol, aes(x = number_of_shots_liquor, y = number_of_beers)) + geom_point() This graph shows us that when liquor consumption increases, beer consumption also usually increases. While scatterplots can help show the relationship between variables, we lose the information of how consumption changes over time. Many time-series plots show multiple variables over the same time period (e.g. murder and robbery over time). There are ways to change the data itself to make creating graphs like this easier, but let’s stick with the data we currently have and just change ggplot(). Start with a normal line graph, this time looking at wine. ggplot(penn_alcohol, aes(x = year, y = number_of_glasses_wine)) + geom_line() Then include a second geom_line() with its own aes() for the second variable. ggplot(penn_alcohol, aes(x = year, y = number_of_glasses_wine)) + geom_line() + geom_line(aes(x = year, y = number_of_shots_liquor)) A problem with this is that both lines are the same color. We need to set a color for each line, and do so within aes(). Instead of providing a color name, we need to provide the name the color will have in the legend. Do so for both lines. ggplot(penn_alcohol, aes(x = year, y = number_of_glasses_wine, color = &quot;Glasses of Wine&quot;)) + geom_line() + geom_line(aes(x = year, y = number_of_shots_liquor, color = &quot;Shots of of Liquor&quot;)) We can change the legend title by using the function labs() and changing the value “color” to what we want the legend title to be. ggplot(penn_alcohol, aes(x = year, y = number_of_glasses_wine, color = &quot;Glasses of Wine&quot;)) + geom_line() + geom_line(aes(x = year, y = number_of_shots_liquor, color = &quot;Shots of of Liquor&quot;)) + labs(color = &quot;Alcohol Type&quot;) Finally, a useful option to to move the legend from the side to the bottom is setting the theme() function to move the “legend.position” to “bottom”. This will allow the graph to be wider. ggplot(penn_alcohol, aes(x = year, y = number_of_glasses_wine, color = &quot;Glasses of Wine&quot;)) + geom_line() + geom_line(aes(x = year, y = number_of_shots_liquor, color = &quot;Shots of of Liquor&quot;)) + labs(color = &quot;Alcohol Type&quot;) + theme(legend.position = &quot;bottom&quot;) 13.4 Color blindness Please keep in mind that some people are color blind so graphs (or maps which we will learn about soon) will be hard to read for these people if we choose the incorrect colors. A helpful site for choosing colors for graphs is colorbrewer2.org This site let’s you select which type of colors you want (sequential and diverging such as shades in a hotspot map, and qualitative such as for data like what we used in this lesson). In the “Only show:” section you can set it to “colorblind safe” to restrict it to colors that allow people with color blindness to read your graph. To the right of this section it shows the HEX codes for each color (a HEX code is just a code that a computer can read and know exactly which color it is). Let’s use an example of a color blind friendly color from the “qualitative” section of ColorBrewer. We have three options on this page (we can change how many colors we want but it defaults to showing 3): green (HEX = #1b9e77), orange (HEX = #d95f02), and purple (HEX = #7570b3). We’ll use the orange and purple colors. To manually set colors in ggplot() we use scale_color_manual(values = c()) and include a vector of color names or HEX codes inside the c(). Doing that using the orange and purple HEX codes will change our graph colors to these two colors. ggplot(penn_alcohol, aes(x = year, y = number_of_glasses_wine, color = &quot;Glasses of Wine&quot;)) + geom_line() + geom_line(aes(x = year, y = number_of_shots_liquor, color = &quot;number_of_shots_liquor&quot;)) + labs(color = &quot;Alcohol Type&quot;) + theme(legend.position = &quot;bottom&quot;) + scale_color_manual(values = c(&quot;#7570b3&quot;, &quot;#d95f02&quot;)) "],
["hotspot-maps.html", "14 Hotspot maps 14.1 A simple map 14.2 What really are maps? 14.3 Making a hotspot map 14.4 Looping through each year", " 14 Hotspot maps Hotspot maps are used to find where events (officer-involved shootings, crimes, liquors stores) are especially prevalent. These maps are frequently used by police departments, particularly in determining where to do hotspot policing (which is focusing patrols on high-crime areas). However, there are significant flaws with these kinds of maps. As we’ll see during this lesson, minor changes to how we make the maps can cause significant differences in interpretation. For example, determining the size of the clusters that make up the hotspots can make it seem like there are much larger or smaller areas with hotspots than there actually are. These clusters are also drawn fairly arbitrarily, without taking into account context such as neighborhoods (In Chapter 15 we’ll make maps that try to account for these types of areas). This makes it more difficult to interpret because even though maps give us the context of location, it can combine different areas in an arbitrary way. We’ll explore these issues in more detail throughout the lesson but keep in mind these risks as you make your own hotspot maps. Here, we will make hotspot maps with our officer_shootings_geocoded crime data. First we need to load the data. load(&quot;data/officer_shootings_geocoded.rda&quot;) 14.1 A simple map To make these maps we will use the package ggmap. install.packages(&quot;ggmap&quot;) library(ggmap) #&gt; Loading required package: ggplot2 #&gt; Google&#39;s Terms of Service: https://cloud.google.com/maps-platform/terms/. #&gt; Please cite ggmap if you use it! See citation(&quot;ggmap&quot;) for details. We’ll start by making the background to our map, showing Philadelphia. We do so using the get_map() function from ggmap which gets a map background from a number of sources. We’ll set the source to “stamen” since Google no longer allows us to get a map without creating an account. The first parameter in get_map() is simply coordinates for Philadelphia to ensure we get a map of the right spot. philly_map &lt;- ggmap(get_map(c(-75.288486, 39.868285, -74.950965, 40.138251), source = &quot;stamen&quot;)) #&gt; Source : http://tile.stamen.com/terrain/12/1191/1548.png #&gt; Source : http://tile.stamen.com/terrain/12/1192/1548.png #&gt; Source : http://tile.stamen.com/terrain/12/1193/1548.png #&gt; Source : http://tile.stamen.com/terrain/12/1194/1548.png #&gt; Source : http://tile.stamen.com/terrain/12/1195/1548.png #&gt; Source : http://tile.stamen.com/terrain/12/1191/1549.png #&gt; Source : http://tile.stamen.com/terrain/12/1192/1549.png #&gt; Source : http://tile.stamen.com/terrain/12/1193/1549.png #&gt; Source : http://tile.stamen.com/terrain/12/1194/1549.png #&gt; Source : http://tile.stamen.com/terrain/12/1195/1549.png #&gt; Source : http://tile.stamen.com/terrain/12/1191/1550.png #&gt; Source : http://tile.stamen.com/terrain/12/1192/1550.png #&gt; Source : http://tile.stamen.com/terrain/12/1193/1550.png #&gt; Source : http://tile.stamen.com/terrain/12/1194/1550.png #&gt; Source : http://tile.stamen.com/terrain/12/1195/1550.png #&gt; Source : http://tile.stamen.com/terrain/12/1191/1551.png #&gt; Source : http://tile.stamen.com/terrain/12/1192/1551.png #&gt; Source : http://tile.stamen.com/terrain/12/1193/1551.png #&gt; Source : http://tile.stamen.com/terrain/12/1194/1551.png #&gt; Source : http://tile.stamen.com/terrain/12/1195/1551.png #&gt; Source : http://tile.stamen.com/terrain/12/1191/1552.png #&gt; Source : http://tile.stamen.com/terrain/12/1192/1552.png #&gt; Source : http://tile.stamen.com/terrain/12/1193/1552.png #&gt; Source : http://tile.stamen.com/terrain/12/1194/1552.png #&gt; Source : http://tile.stamen.com/terrain/12/1195/1552.png philly_map Since we saved the map output into “philly_map” we can reuse this map background for all the maps we’re making in this lesson. This saves us time as we don’t have to wait to download the map every time. Let’s plot the shootings from our data set. Just as with a scatterplot we use the geom_point() function from the ggplot2 package and set our longitude and latitude variables on the x- and y-axis, respectively. philly_map + geom_point(aes(x = lon, y = lat), data = officer_shootings_geocoded) #&gt; Warning: Removed 2 rows containing missing values (geom_point). If we wanted to color the dots we can use “color =” and then select a color. Let’s try it with “forestgreen”. philly_map + geom_point(aes(x = lon, y = lat), data = officer_shootings_geocoded, color = &quot;forestgreen&quot;) #&gt; Warning: Removed 2 rows containing missing values (geom_point). As with other graphs we can change the size of the dot using “size =”. philly_map + geom_point(aes(x = lon, y = lat), data = officer_shootings_geocoded, color = &quot;forestgreen&quot;, size = 0.5) #&gt; Warning: Removed 2 rows containing missing values (geom_point). philly_map + geom_point(aes(x = lon, y = lat), data = officer_shootings_geocoded, color = &quot;forestgreen&quot;, size = 2) #&gt; Warning: Removed 2 rows containing missing values (geom_point). For maps like this - with one point per event - it is hard to tell if any events happen on the same, or nearly the same, location as each point is solid green. We want to make the dots semi-transparent so if multiple shootings happen at the same place that dot will be shaded darker than if only one shooting happened there. To do so we use the parameter “alpha =” which takes an input between 0 and 1 (inclusive). The lower the value the more transparent it is. philly_map + geom_point(aes(x = lon, y = lat), data = officer_shootings_geocoded, color = &quot;forestgreen&quot;, size = 2, alpha = 0.5) #&gt; Warning: Removed 2 rows containing missing values (geom_point). This map is useful because it allows us to easily see where each officer-involved shooting in Philly happened between 2007 and early 2019. There are some limitations though. This shows all shootings in a single map, meaning that any time trends are lost - we’ll address this at the end of the lesson. While you can see some clusters, it is difficult to see if there are any hot spots indicating areas with especially high or low amounts of shootings. You’ll notice that it has a message saying “Removed 2 rows containing missing values (geom_point).” That just means that ggplot() automatically deleted 2 rows that didn’t contain any longitude or latitude data. Most data will have a small number of rows missing values, that is nothing to be concerned about unless the number of missing values gets large enough to affect your data. 14.2 What really are maps? Let’s pause for a moment to think about what a map really is. Below I made a simple scatterplot of our data with one dot per shooting (minus the two without coordinates). Compare this to the map above and you’ll see that they are the same except the map has a useful background while the plot has a blank background. That is all static maps are (in Chapter 16 we’ll learn about interactive maps), scatterplots of coordinates overlayed on a map background. Basically, they are scatterplots with context. And this context is useful, we can interpret the map to see that there are lots of shootings in West Philly but not around University City, for example. The exact same pattern is present in the scatterplot but without the ability to tell “where” a dot is. plot(officer_shootings_geocoded$lon, officer_shootings_geocoded$lat, col = &quot;darkred&quot;) 14.3 Making a hotspot map Now we can start making hotspot maps which help to show areas with clusters of events. We’ll do this using hexagonal bins which are an efficient way of showing clusters of events on a map. Our syntax will be similar to the map above but now we want to use the function stat_binhex() rather than geom_point(). It starts the same as before with aex(x = lon, y = lat) (or whatever the longitude and latitude columns are called in your data), as well as “data = officer_shootings_geocoded” outside of the aes() parameter. There are two new things we need to make the hotspot map. First we can add the parameter “bins = number_of_bins” where “number_of_bins” is a number we select. bins essentially says how large or small we want each cluster of events to be. A smaller value for “bins” says we want more events clustered together, making larger bins. A larger value for bins has each bin be smaller on the map and capture fewer events. This will become more clear with examples. The second thing is to add the function coord_cartesian() which just tells ggplot() we are going to do some spatial analysis in the making of the bins. We don’t need to add any parameters in this. Let’s start with 60 bins and then try some other number of bins to see how it changes the map. philly_map + stat_binhex(aes(x = lon, y = lat), bins = 60, data = officer_shootings_geocoded) + coord_cartesian() #&gt; Coordinate system already present. Adding new coordinate system, which will replace the existing one. #&gt; Warning: Removed 2 rows containing non-finite values (stat_binhex). From this map we can see that most areas which had a shooting had 1-2 shootings in that area (a limitation to this map is it is unclear just how wide these “areas” are). North Philly and North-West Philly have more areas with more shootings, and more shootings overall. But look right in the middle of Center City by City Hall, an area has 8 shootings, the most of any bin. Were there really 8 shootings outside of City Hall? No. Remember those addresses that couldn’t be properly located? The coordinates given to those addresses were to City Hall, causing this weird pattern in our map. What happens when we drop the number of bins to 30? philly_map + stat_binhex(aes(x = lon, y = lat), bins = 30, data = officer_shootings_geocoded) + coord_cartesian() #&gt; Coordinate system already present. Adding new coordinate system, which will replace the existing one. #&gt; Warning: Removed 2 rows containing non-finite values (stat_binhex). Each bin is much larger and covers nearly all of Philadelphia. Be careful with maps like these! This map is so broad that it appears that shootings are ubiquitous across the city. We know from the map showing each shooting as a dot, and that there are &lt;500 shootings, that this is not true. Making maps like this make it easy to mislead the reader, including yourself! What about looking at 100 bins? philly_map + stat_binhex(aes(x = lon, y = lat), bins = 100, data = officer_shootings_geocoded) + coord_cartesian() #&gt; Coordinate system already present. Adding new coordinate system, which will replace the existing one. #&gt; Warning: Removed 2 rows containing non-finite values (stat_binhex). Now each bin is very small and a much smaller area in Philadelphia has had an officer-involved shooting. So what is the right number of bins to use? There is no correct universal answer - you must decide what the goal is with the data you are using. This opens up serious issues for manipulation - intentional or not - of the data as the map is so easily changeable without ever changing the data itself. 14.3.1 Colors To change the bin colors we can use the parameter scale_fill_gradient(). This accepts a color for “low” which is when the events are rare and “high” for the bins with frequent events. We’ll use colors from ColorBrewer, selecting the reddish theme (“3-class OrRd”) from the Multi-hue section of the “sequential” data on the page. philly_map + stat_binhex(aes(x = lon, y = lat), bins = 60, data = officer_shootings_geocoded) + coord_cartesian() + scale_fill_gradient(low = &quot;#fee8c8&quot;, high = &quot;#e34a33&quot;) #&gt; Coordinate system already present. Adding new coordinate system, which will replace the existing one. #&gt; Warning: Removed 2 rows containing non-finite values (stat_binhex). By default it labels the legend as “count”. Since we know these are counts of police shootings let’s relabel that as such. philly_map + stat_binhex(aes(x = lon, y = lat), bins = 60, data = officer_shootings_geocoded) + coord_cartesian() + scale_fill_gradient(&#39;Police Shootings&#39;, low = &quot;#fee8c8&quot;, high = &quot;#e34a33&quot;) #&gt; Coordinate system already present. Adding new coordinate system, which will replace the existing one. #&gt; Warning: Removed 2 rows containing non-finite values (stat_binhex). 14.4 Looping through each year Since our maps show every shooting on the same map, if there are different patterns depending on the year, we can’t pick up those patterns. As a check, let’s write a for loop that maps each year’s data separately. First we need to make a variable with the shooting’s year to be able to subset data for just that year. We can use the year() function from lubridate to do this. library(lubridate) #&gt; #&gt; Attaching package: &#39;lubridate&#39; #&gt; The following object is masked from &#39;package:base&#39;: #&gt; #&gt; date officer_shootings_geocoded$year &lt;- year(officer_shootings_geocoded$dates) As a basic check, let’s just see how many shootings there were each year. table(officer_shootings_geocoded$year) #&gt; #&gt; 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 #&gt; 61 40 55 47 44 59 35 28 21 22 12 12 5 It looks like the general pattern is that shootings are declining. Now we can map each year. We are looping through each year in the data, and reusing the map code before except instead of the full data, we subset data to be only rows matching the year in that iteration of the loop. for (year in unique(officer_shootings_geocoded$year)) { print( philly_map + stat_binhex(aes(x = lon, y = lat), bins = 60, alpha = 0.75, data = officer_shootings_geocoded[officer_shootings_geocoded$year == year, ]) + coord_cartesian() + scale_fill_gradient(&#39;Police Shootings&#39;, low = &quot;#fee8c8&quot;, high = &quot;#e34a33&quot;) + ggtitle(paste(&quot;Philadelphia Police Officer-Involved Shootings, &quot;, year)) ) } #&gt; Coordinate system already present. Adding new coordinate system, which will replace the existing one. #&gt; Coordinate system already present. Adding new coordinate system, which will replace the existing one. #&gt; Coordinate system already present. Adding new coordinate system, which will replace the existing one. #&gt; Coordinate system already present. Adding new coordinate system, which will replace the existing one. #&gt; Coordinate system already present. Adding new coordinate system, which will replace the existing one. #&gt; Coordinate system already present. Adding new coordinate system, which will replace the existing one. #&gt; Coordinate system already present. Adding new coordinate system, which will replace the existing one. #&gt; Warning: Removed 1 rows containing non-finite values (stat_binhex). #&gt; Coordinate system already present. Adding new coordinate system, which will replace the existing one. #&gt; Coordinate system already present. Adding new coordinate system, which will replace the existing one. #&gt; Coordinate system already present. Adding new coordinate system, which will replace the existing one. #&gt; Coordinate system already present. Adding new coordinate system, which will replace the existing one. #&gt; Warning: Removed 1 rows containing non-finite values (stat_binhex). #&gt; Coordinate system already present. Adding new coordinate system, which will replace the existing one. #&gt; Coordinate system already present. Adding new coordinate system, which will replace the existing one. "],
["choropleth-maps.html", "15 Choropleth Maps 15.1 Spatial joins 15.2 Making choropleth maps", " 15 Choropleth Maps In Chapter 14 we made hotspot maps to show which areas in Philadelphia had the most officer-involved shootings. We made the maps in a number of ways and consistently found that shootings were most prevalent in north and west Philly. In this lesson we will make choropleth maps, which are shaded maps where each “unit” is some known area such as a state or neighborhood. Think of election maps where states are colored blue when a Democratic candidate wins that state and red when a Republican candidate wins. These are choropleth maps - each state is colored to indicate something. In this lesson we will continue to work on the officer-involved shooting data and make choropleth maps shaded by the number of shootings in each Census tract (we will define this later in the lesson) in the city. Since we will be working more on the geocoded version of the police shooting data, let’s load it now. load(&quot;data/officer_shootings_geocoded.rda&quot;) The package that we will use to handle geographic data and do most of the work in this lesson is sf. sf is a sophisticated package and does far more than we will cover in this lesson. For more information about the package’s features please see the website for it here. install.packages(&quot;sf&quot;) library(sf) #&gt; Linking to GEOS 3.6.1, GDAL 2.2.3, PROJ 4.9.3 The way sf reads in the shapefiles is through the st_read() function. A shapefile is simialr to a data.frame but has information on how to draw a geographic boundary such as a state. Our input inside the () is a string with the name of the “.shp” file we want to read in (since we are telling R to read a file on the computer rather than an object that exists, it needs to be in quotes). This shapefile contains Census tracts for Philly so we’ll call the object “philly_tracts”. philly_tracts &lt;- st_read(&quot;data/philly_census_tract/Census_Tracts_2010.shp&quot;) #&gt; Reading layer `Census_Tracts_2010&#39; from data source `C:\\Users\\user\\Dropbox\\R_project\\r4crim\\data\\philly_census_tract\\Census_Tracts_2010.shp&#39; using driver `ESRI Shapefile&#39; #&gt; Simple feature collection with 384 features and 14 fields #&gt; geometry type: MULTIPOLYGON #&gt; dimension: XY #&gt; bbox: xmin: -75.28031 ymin: 39.86747 xmax: -74.95575 ymax: 40.13793 #&gt; epsg (SRID): 4326 #&gt; proj4string: +proj=longlat +datum=WGS84 +no_defs Note that when we downloaded the data, it came with multiple files (some with extensions .cpg, .dbf, etc) but we only have the file with the .shp extension inside of st_read(). We still do need all of the files and st_read() is using them even if not explicitly called. So make sure every file downloaded is in the same working directory as the .shp file. As usual when dealing with a new data set, let’s look at the first 6 rows. head(philly_tracts) #&gt; Simple feature collection with 6 features and 14 fields #&gt; geometry type: MULTIPOLYGON #&gt; dimension: XY #&gt; bbox: xmin: -75.24747 ymin: 39.96047 xmax: -75.15853 ymax: 39.98 #&gt; epsg (SRID): 4326 #&gt; proj4string: +proj=longlat +datum=WGS84 +no_defs #&gt; OBJECTID STATEFP10 COUNTYFP10 TRACTCE10 GEOID10 NAME10 #&gt; 1 1 42 101 009400 42101009400 94 #&gt; 2 2 42 101 009500 42101009500 95 #&gt; 3 3 42 101 009600 42101009600 96 #&gt; 4 4 42 101 013800 42101013800 138 #&gt; 5 5 42 101 013900 42101013900 139 #&gt; 6 6 42 101 014000 42101014000 140 #&gt; NAMELSAD10 MTFCC10 FUNCSTAT10 ALAND10 AWATER10 INTPTLAT10 #&gt; 1 Census Tract 94 G5020 S 366717 0 +39.9632709 #&gt; 2 Census Tract 95 G5020 S 319070 0 +39.9658709 #&gt; 3 Census Tract 96 G5020 S 405273 0 +39.9655396 #&gt; 4 Census Tract 138 G5020 S 341256 0 +39.9764504 #&gt; 5 Census Tract 139 G5020 S 562934 0 +39.9750563 #&gt; 6 Census Tract 140 G5020 S 439802 0 +39.9735358 #&gt; INTPTLON10 LOGRECNO geometry #&gt; 1 -075.2322437 10429 MULTIPOLYGON (((-75.22927 3... #&gt; 2 -075.2379140 10430 MULTIPOLYGON (((-75.23536 3... #&gt; 3 -075.2435075 10431 MULTIPOLYGON (((-75.24343 3... #&gt; 4 -075.1771771 10468 MULTIPOLYGON (((-75.17341 3... #&gt; 5 -075.1711846 10469 MULTIPOLYGON (((-75.17313 3... #&gt; 6 -075.1630966 10470 MULTIPOLYGON (((-75.16141 3... The last column is important. In shapefiles the “geometry” column is the one with the instructions to make the map. This data has a single row for each Census tract in the city. So the “geometry” column in each row have a list of coordinates which, if connected in order, make up that tract. Since the “geometry” column contains the instructions to map, we can plot() it to show a map of the data. plot(philly_tracts$geometry) Here we have a map of Philadelphia broken up into little pieces. These pieces are Census tracts. Census tracts are small areas in a city with about 2,500-8,000 people and are used by the U.S. Census Bureau as a rough approximation of a neighborhood. In the head() results there was a section about something called “epsg” and “proj4string”. Let’s talk about that specifically since they are important for working with spatial data. A way to get just those two results in the st_crs() function which is part of sf. Let’s extract the “coordinate reference system” (CRS) for philly_tracts. st_crs(philly_tracts) Coordinate Reference System: EPSG: 4326 proj4string: &quot;+proj=longlat +datum=WGS84 +no_defs&quot; An issue with working with geographic data is that the Earth is not flat. Since the Earth is spherical, there will always be some distortion when trying to plot the data on a flat surface such as a map. To account for this we need to transform the longitude and latitude values we generally have to work properly on a map. We do so by “projecting” our data onto the areas of the Earth we want. This is a complex field with lots of work done on it (both abstractly and for R specifically) so this lesson will be an extremely brief overview of the topic and oversimplify some aspects of it. If we look at the output of st_crs(philly_tracts) we can see that the EPSG is set to 4326 and the proj4string (which ittells us the current map projection) is “+proj=longlat +datum=WGS84 +no_defs”. This CRS, WGS84, is a standard CRS and is the one used whenever you use a GPS to find a location. To find the CRS for certain parts of the world see here. If you search that site for Pennsylvania you’ll see that Pennsylvania South is assigned 2272 which is what we will use to project this data properly. If we want to get the proj4string for 2272 we can use st_crs(2272) #&gt; Coordinate Reference System: #&gt; EPSG: 2272 #&gt; proj4string: &quot;+proj=lcc +lat_1=40.96666666666667 +lat_2=39.93333333333333 +lat_0=39.33333333333334 +lon_0=-77.75 +x_0=600000 +y_0=0 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=us-ft +no_defs&quot; Note the section that says “+units=us-ft”. This means that the units are in feet. Some projections have units in meters so be mindful of this when doing some analysis such as seeing if a point is within X feet of a certain area. Let’s convert our philly_tracts data to coordinate reference system 2272 which is the one assigned to southern Pennsylvania, an area that includes Philadelphia. philly_tracts &lt;- st_transform(philly_tracts, crs = 2272) st_crs(philly_tracts) Coordinate Reference System: EPSG: 2272 proj4string: &quot;+proj=lcc +lat_1=40.96666666666667 +lat_2=39.93333333333333 +lat_0=39.33333333333334 +lon_0=-77.75 +x_0=600000 +y_0=0 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=us-ft +no_defs&quot; 15.1 Spatial joins What we want to do with these Census tracts is to find out which tract each shooting occurred in and sum up the number of shootings per tract. Once we do that we can make a more accurate hotspot map by mapping at the Census tract level and being able to measure shootings-per-tract. A spatial join is very similar to regular joins where we merge two data sets based on common variables (such as state name or unique ID code of a person). In this case it merges based on some shared geographic feature such as if two lines intersect or (as we will do so here) if a point is within some geographic area. Right now our “officer_shootings_geocoded” data is in a data.frame with some info on each shootings and the longitude and latitude of the shooting in separate columns. We want to turn this data.frame into a spatial object to allow us to find which tract each shooting happened in. We can convert it into a spatial object using the st_as_sf() function from sf. Our input is first our data, officer_shootings_geocoded. Then in the coords parameter we put a vector of the column names so the function knows which columns are the longitude and latitude columns to convert to a “geometry” column like we saw in “philly_tracts” earlier. We’ll set the CRS to be the WGS84 standard we saw earlier but we will change it to match the CRS that the Census tract data has. officer_shootings_geocoded &lt;- st_as_sf(officer_shootings_geocoded, coords = c(&quot;lon&quot;, &quot;lat&quot;), crs = &quot;+proj=longlat +ellps=WGS84 +no_defs&quot;) We want our shootings data in the same projection as the tracts data so we need to use st_transform() to change the projection. Since we want the CRS to be the same as in “philly_tracts”, we can set it using st_crs(philly_tracts) to use the right CRS. officer_shootings_geocoded &lt;- st_transform(officer_shootings_geocoded, crs = st_crs(philly_tracts)) Now we can take a look at head() to see if it was projected. head(officer_shootings_geocoded) #&gt; Simple feature collection with 6 features and 3 fields #&gt; geometry type: POINT #&gt; dimension: XY #&gt; bbox: xmin: 2677481 ymin: 226464.5 xmax: 2706666 ymax: 253839.1 #&gt; epsg (SRID): 2272 #&gt; proj4string: +proj=lcc +lat_1=40.96666666666667 +lat_2=39.93333333333333 +lat_0=39.33333333333334 +lon_0=-77.75 +x_0=600000 +y_0=0 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=us-ft +no_defs #&gt; shooting_number location dates #&gt; 1 19-04 4900 Hazel Avenue, Philadelphia, PA 2019-03-06 #&gt; 2 19-06 1300 Kater Street, Philadelphia, PA 2019-03-28 #&gt; 4 19 11 2100 Taney Terrace, Philadelphia, PA 2019-04-25 #&gt; 5 19-13 1800 N. Broad Street, Philadelphia, PA 2019-05-11 #&gt; 6 19 14 3400 G Street, Philadelphia, PA 2019-05-20 #&gt; 7 18-01 2800 Kensington Avenue, Philadelphia, PA 2018-01-13 #&gt; geometry #&gt; 1 POINT (2677481 234962.8) #&gt; 2 POINT (2693626 232671.6) #&gt; 4 POINT (2686095 226464.5) #&gt; 5 POINT (2694910 246343.1) #&gt; 6 POINT (2706666 253839.1) #&gt; 7 POINT (2704596 250717) We can see it is now a “simple feature collection” with the correct projection. And we can see there is a new column called “geometry” just like in “philly_tracts”. The type of data in “geometry” is POINT since our data is just a single location instead of a polygon like in the tracts data. Since we have both the tracts and the shootings data let’s make a quick map to see the data. plot(philly_tracts$geometry) plot(officer_shootings_geocoded$geometry, add = TRUE, col = &quot;red&quot;) Our next step is to combine these two data sets to figure out how many shootings occurred in each Census tract. This will be a multi-step process so let’s plan it out before beginning. Our shooting data is one row for each shooting, our tract data is one row for each tract. Since our goal is to map at the tract-level we need to get the tract where each shooting occurred then aggregate up to the tract-level to get a count of the shootings-per-tract. Then we need to combine that with that the original tract data (since we need the “geometry” column) and we can then map it. Find which tract each shooting happened in Aggregate shooting data until we get one row per tract and a column showing the number of shootings in that tract Combine with the Census tract data Make a map We’ll start by finding the tract where each shooting occurred using the function st_join() which is a function in sf. This does a spatial join and finds the polygon where each point is located in. Since we will be aggregating the data let’s call the output of this function “shootings_agg”. The order in the () is important! For our aggregation we want the output to be at the shooting-level so we start with the “officer_shootings_geocoded” data. In the next step we’ll see why this matters. shootings_agg &lt;- st_join(officer_shootings_geocoded, philly_tracts) Let’s look at the first 6 rows. head(shootings_agg) #&gt; Simple feature collection with 6 features and 17 fields #&gt; geometry type: POINT #&gt; dimension: XY #&gt; bbox: xmin: 2677481 ymin: 226464.5 xmax: 2706666 ymax: 253839.1 #&gt; epsg (SRID): 2272 #&gt; proj4string: +proj=lcc +lat_1=40.96666666666667 +lat_2=39.93333333333333 +lat_0=39.33333333333334 +lon_0=-77.75 +x_0=600000 +y_0=0 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=us-ft +no_defs #&gt; shooting_number location dates #&gt; 1 19-04 4900 Hazel Avenue, Philadelphia, PA 2019-03-06 #&gt; 2 19-06 1300 Kater Street, Philadelphia, PA 2019-03-28 #&gt; 4 19 11 2100 Taney Terrace, Philadelphia, PA 2019-04-25 #&gt; 5 19-13 1800 N. Broad Street, Philadelphia, PA 2019-05-11 #&gt; 6 19 14 3400 G Street, Philadelphia, PA 2019-05-20 #&gt; 7 18-01 2800 Kensington Avenue, Philadelphia, PA 2018-01-13 #&gt; OBJECTID STATEFP10 COUNTYFP10 TRACTCE10 GEOID10 NAME10 #&gt; 1 208 42 101 007900 42101007900 79 #&gt; 2 33 42 101 001500 42101001500 15 #&gt; 4 198 42 101 003600 42101003600 36 #&gt; 5 384 42 101 037700 42101037700 377 #&gt; 6 21 42 101 019200 42101019200 192 #&gt; 7 172 42 101 017702 42101017702 177.02 #&gt; NAMELSAD10 MTFCC10 FUNCSTAT10 ALAND10 AWATER10 INTPTLAT10 #&gt; 1 Census Tract 79 G5020 S 377950 0 +39.9504630 #&gt; 2 Census Tract 15 G5020 S 239383 0 +39.9419037 #&gt; 4 Census Tract 36 G5020 S 964539 0 +39.9279255 #&gt; 5 Census Tract 377 G5020 S 736894 0 +39.9824381 #&gt; 6 Census Tract 192 G5020 S 656913 0 +40.0006393 #&gt; 7 Census Tract 177.02 G5020 S 489258 0 +39.9950621 #&gt; INTPTLON10 LOGRECNO geometry #&gt; 1 -075.2182570 10410 POINT (2677481 234962.8) #&gt; 2 -075.1591158 10356 POINT (2693626 232671.6) #&gt; 4 -075.1920206 10377 POINT (2686095 226464.5) #&gt; 5 -075.1506932 10694 POINT (2694910 246343.1) #&gt; 6 -075.1150648 10519 POINT (2706666 253839.1) #&gt; 7 -075.1231399 10509 POINT (2704596 250717) There are now columns from the Census tracts data which says which tract the shooting happened in. Now we can aggregate up to the tract-level. We just need to aggregate by a unique variable indicating which tract it is, we will then use this to merge with the “philly_tracts” data. Let’s look specifically at the “GEOID10” variable since that is actually important and common in dealing with Census data. And let’s also print out the columns “STATEFP10”, “COUNTYFP10”, and “TRACTCE10”. head(shootings_agg[, c(&quot;STATEFP10&quot;, &quot;COUNTYFP10&quot;, &quot;TRACTCE10&quot;, &quot;GEOID10&quot;)]) #&gt; Simple feature collection with 6 features and 4 fields #&gt; geometry type: POINT #&gt; dimension: XY #&gt; bbox: xmin: 2677481 ymin: 226464.5 xmax: 2706666 ymax: 253839.1 #&gt; epsg (SRID): 2272 #&gt; proj4string: +proj=lcc +lat_1=40.96666666666667 +lat_2=39.93333333333333 +lat_0=39.33333333333334 +lon_0=-77.75 +x_0=600000 +y_0=0 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=us-ft +no_defs #&gt; STATEFP10 COUNTYFP10 TRACTCE10 GEOID10 geometry #&gt; 1 42 101 007900 42101007900 POINT (2677481 234962.8) #&gt; 2 42 101 001500 42101001500 POINT (2693626 232671.6) #&gt; 4 42 101 003600 42101003600 POINT (2686095 226464.5) #&gt; 5 42 101 037700 42101037700 POINT (2694910 246343.1) #&gt; 6 42 101 019200 42101019200 POINT (2706666 253839.1) #&gt; 7 42 101 017702 42101017702 POINT (2704596 250717) The GEOID10 column is a unique identifier for the Census tracts in Philly. It is made up by a few other identifiers at higher geographic levels. All of the GEOID10s here start with the numbers 42 followed by 101. The first two numbers are the state identifiers code, 42, based on Census FIPS codes. FIPS stands for Federal Information Processing Standard and are unique geographic identifiers used in Census data. These codes are used to merge different data sets (e.g. FBI crime data and Census data) together, a task that would be impossible (or very difficult) without a unique ID code in both data sets. The 101 is the county code, as seen in the column “COUNTYFP10”. The remaining numbers vary and indicate which tract it is. When combined it makes an 11 number code that is not repeated for any Census tract in the country. We will return to this code when combining this data with Census data. For now we will use the code to aggregate the number of shootings per Census tract. Remember, the aggregate() command aggregates a numeric value by some categorical value. Here we aggregate the number of shootings per Census tract. So our code will be aggregate(number_shootings ~ GEOID10, data = shootings_agg, FUN = sum) We actually don’t have a variable with the number of shootings so we need to make that. We can simply call it “number_shootings” and give it that value of 1 since each row is only one shooting. shootings_agg$number_shootings &lt;- 1 Now we can write the aggregate() code and save the results back into “shootings_agg”. shootings_agg &lt;- aggregate(number_shootings ~ GEOID10, data = shootings_agg, FUN = sum) Let’s check a summary of the “number_shootings” variable we made. summary(shootings_agg$number_shootings) #&gt; Min. 1st Qu. Median Mean 3rd Qu. Max. #&gt; 1.000 1.000 2.000 2.152 3.000 9.000 The minimum is one shooting per tract, two on average, and 9 in the tract with the most shootings. So what do we make of this data? Well, there are some data issues that cause problems in these results. First, we know that shootings that didn’t get geocoded properly were given the coordinates of City Hall, likely making up that tract with 9 shootings. And then let’s think about the minimum value. Did every single tract in the city have at least one shooting? No, take a look at the number of rows in this data, keeping in mind there should be one row per tract. nrow(shootings_agg) #&gt; [1] 204 And let’s compare it to the “philly_tracts” data. nrow(philly_tracts) #&gt; [1] 384 The shootings data is missing about 180 tracts. That is because if no shooting occurred there, there would never be a matching row in the data so that tract wouldn’t appear in the shooting data. That’s not going to be a major issue here but is something to keep in mind in future research. And given the sensitivity of this issue, is a good reason to carefully check your data before make any conclusions. The data is ready to merge with the “philly_tracts” data. We’ll introduce a new function that makes merging data simple. This function comes from the dplyr package so we need to install and tell R we want to use it using library(). install.packages(&quot;dplyr&quot;) library(dplyr) #&gt; #&gt; Attaching package: &#39;dplyr&#39; #&gt; The following objects are masked from &#39;package:stats&#39;: #&gt; #&gt; filter, lag #&gt; The following objects are masked from &#39;package:base&#39;: #&gt; #&gt; intersect, setdiff, setequal, union The function we will use is left_join() which takes two parameters, the two data sets to join together. left_join(data1, data2) This function joins these data and keeps all of the rows from the left data and every column from both data sets. It combines the data based on any matching columns (matching meaning same column name) in both data sets. Since in our data sets, the column “GEOID10” exists in both, it will merge the data based on that column. There are two other functions that are similar but differ based on which rows they keep. left_join - All rows from Left data and all columns from Left and Right data right_join - All rows from Right data and all columns from Left and Right data full_join - All rows and all columns from Left and Right data We could alternatively use the merge() function which is built into R but that function is slower than the dplyr functions and requires us to manually set the matching columns. We want to keep all rows in “philly_tracts” (keep all tracts) so we can use left_join(philly_tracts, shootings_agg). Let’s save the results into a new data.frame called “philly_tracts_shootings”. philly_tracts_shootings &lt;- left_join(philly_tracts, shootings_agg) #&gt; Joining, by = &quot;GEOID10&quot; If we look at summary() again for “number_shootings” we can see that there are now 180 rows with NAs. These are the tracts where there were no shootings so they weren’t present in the “shootings_agg” data. summary(philly_tracts_shootings$number_shootings) #&gt; Min. 1st Qu. Median Mean 3rd Qu. Max. NA&#39;s #&gt; 1.000 1.000 2.000 2.152 3.000 9.000 180 We need to convert these values to 0. We will use the is.na() function to conditionally find all rows with a NA value in the “number_shootings” column and use square bracket notation to change the value to 0. philly_tracts_shootings$number_shootings[is.na(philly_tracts_shootings$number_shootings)] &lt;- 0 Checking it again we see that the minimum is now 0 and the mean number of shootings drops to about 1.1 per tract. summary(philly_tracts_shootings$number_shootings) #&gt; Min. 1st Qu. Median Mean 3rd Qu. Max. #&gt; 0.000 0.000 1.000 1.143 2.000 9.000 15.2 Making choropleth maps Finally we are ready to make some choropleth maps. For these maps we are going to use ggplot2 again so we need to load it. library(ggplot2) ggplot2’s benefit is you can slowly build graphs or maps and improve the graph at every step. Earlier we used functions such as geom_line() for line graphs and geom_point() for scatter plots. For mapping these polygons we will use geom_sf() which knows how to handle spatial data. As usual we will start with ggplot(), inputting our data first. Then inside of aes (the aesthetics of the graph/map) we use a new parameter fill. In fill we will put in the “number_shootings” column and it will color the polygons (tracts) based on values in that column. Then we can add the geom_sf(). ggplot(philly_tracts_shootings, aes(fill = number_shootings)) + geom_sf() We have now created a choropleth map showing the number of shootings per Census tract in Philly! Based on the legend tracts that are light blue have the most shootings while tracts that are dark blue have the fewest (or none at all). Normally we’d want the opposite, with darker (or brighter) areas signifying a greater amount of whatever the map is showing. We can use scale_fill_gradient() to set the colors to what we want. We input a color for low value and a color for high value and it’ll make the map shade by those colors. ggplot(philly_tracts_shootings, aes(fill = number_shootings)) + geom_sf() + scale_fill_gradient(low = &quot;white&quot;, high = &quot;red&quot;) This gives a much better map and clearly shows the areas where shootings are most common and where there were no shootings. To make this map easier to read and look better, let’s add a title to the map and to the legend. ggplot(philly_tracts_shootings, aes(fill = number_shootings)) + geom_sf() + scale_fill_gradient(low = &quot;white&quot;, high = &quot;red&quot;) + labs(fill = &quot;# of Police Shootings&quot;, title = &quot;Police Shootings in Philadelphia by Census Tract&quot;, subtitle = &quot;January 2007 - mid-2019&quot;) Since the coordinates don’t add anything to the map, let’s get rid of them. ggplot(philly_tracts_shootings, aes(fill = number_shootings)) + geom_sf() + scale_fill_gradient(low = &quot;white&quot;, high = &quot;red&quot;) + labs(fill = &quot;# of Police Shootings&quot;, title = &quot;Police Shootings in Philadelphia by Census Tract&quot;, subtitle = &quot;January 2007 - mid-2019&quot;) + theme(axis.text.x = element_blank(), axis.text.y = element_blank(), axis.ticks = element_blank()) We’ll return to this data in Section ?? for the lesson on interactive maps so we need to save it. save(philly_tracts_shootings, file = &quot;data/philly_tracts_shootings.rda&quot;) "],
["interactive-maps.html", "16 Interactive Maps 16.1 Why do interactive graphs matter? 16.2 Making the interactive map 16.3 Adding popup information 16.4 Dealing with too many markers 16.5 Interactive choropleth maps", " 16 Interactive Maps While maps of data are useful, their ability to show incident-level information is quite limited. They tend to show broad trends - where crime happened in a city - rather than provide information about specific crime incidents. While this is important, there are significant drawbacks about being unable to get important information about an incident without having to check the data. An interactive map excels at showing individual incidents as it allows you to click on a dot and will have a popup giving information about that incident. For this lesson we will continue to use the officer shooting data so let’s load that. load(&quot;data/officer_shootings_geocoded.rda&quot;) 16.1 Why do interactive graphs matter? 16.1.1 Understanding your data The most important thing to learn from this course is that understanding your data is crucial to good research. Making interactive maps is a very useful way to better understand your data as you can immediately see geographic patterns and quickly look at characteristics of those incidents to understand them. In this lesson we will make a map of each officer-involved shooting that lets you click on the shooting and see some information about it. If we see a cluster of shootings, we can click on each shooting to see if they are similar. Though it is possible to find these patterns just looking at the data, it is easier to be able to see a geographic pattern and immediately look at information about each incident. 16.1.2 Police departments use them Interactive maps are popular in large police departments such as Philadelphia and New York City. They allow easy understanding of geographic patterns in the data and, importantly, allow such access to people who do not have the technical skills necessary to create the maps. If nothing else, learning interactive maps will help you with a future job. 16.2 Making the interactive map As usual, let’s take a look at the top 6 rows of the data. head(officer_shootings_geocoded) #&gt; shooting_number location dates #&gt; 1 19-04 4900 Hazel Avenue, Philadelphia, PA 2019-03-06 #&gt; 2 19-06 1300 Kater Street, Philadelphia, PA 2019-03-28 #&gt; 4 19 11 2100 Taney Terrace, Philadelphia, PA 2019-04-25 #&gt; 5 19-13 1800 N. Broad Street, Philadelphia, PA 2019-05-11 #&gt; 6 19 14 3400 G Street, Philadelphia, PA 2019-05-20 #&gt; 7 18-01 2800 Kensington Avenue, Philadelphia, PA 2018-01-13 #&gt; lon lat #&gt; 1 -75.22087 39.95046 #&gt; 2 -75.16355 39.94289 #&gt; 4 -75.19104 39.92646 #&gt; 5 -75.15754 39.98030 #&gt; 6 -75.11482 39.99991 #&gt; 7 -75.12253 39.99151 This data is fairly sparse about information regarding the shooting. All it has is the date and address (which isn’t that useful as location is already covered by the map). The level of detail about the crime may be sparse, but we can still create a map where you can click an incident dot on the map and a popup will tell you when it happened. We will use the package leaflet for our interactive map. leaflet will produce maps similar to Google Maps with circles (or any icon we choose) for each value we add to the map. It allows you to zoom in, scroll around, and provides context to each incident that isn’t available on a static map. install.packages(&quot;leaflet&quot;) library(leaflet) To make a leaflet map we need to run the function leaflet() and add a tile to the map. A tile is simply the background on the map. This website provides a large number of potential tiles to use, though many are not relevant to our purposes of crime mapping. We will use a standard tile from Open Street Maps. This tile gives street names and highlights important features such has parks and large stores which provides useful contexts for looking at the data. The attribution parameter isn’t strictly necessary but it is good form to say where your tile is from. leaflet() %&gt;% addTiles(&#39;http://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png&#39;, attribution = &#39;&amp;copy; &lt;a href=&quot;http://openstreetmap.org&quot;&gt; OpenStreetMap&lt;/a&gt; contributors&#39;) When you run the above code it shows a world map (copied several times). Zoom into it and it’ll start showing relevant features of wherever you’re looking. Note the %&gt;% between the leaflet() function and the addTiles() function. This is called a “pipe” in R and is used like the + in ggplot to combine multiple functions together. This is used heavily in what is called the “tidyverse”, a series of packages that are prominent in modern R and useful for data analysis. We won’t be covering them in this introductory course but for more information on them you can check the tidyverse website. For this lesson you need to know that each piece of the leaflet function must end with %&gt;% for the next line to work. To add the points to the graph we use the function addMarkers() which has two parameters, lng and lat. For both parameters we put the column in which the longitude and latitude are, respectively. leaflet() %&gt;% addTiles(&#39;http://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png&#39;, attribution = &#39;&amp;copy; &lt;a href=&quot;http://openstreetmap.org&quot;&gt; OpenStreetMap&lt;/a&gt; contributors&#39;) %&gt;% addMarkers(lng = officer_shootings_geocoded$lon, lat = officer_shootings_geocoded$lat) It now adds an icon indicating where every shooting in our data is. You can zoom in and scroll around to see more about where the shootings happen. These icons are a bit large, covering nearly all of the city and making it hard to see where shootings happen. To change the icons to circles we can change the function addMarkers() to addCircleMarkers(), keeping the rest of the code the same, leaflet() %&gt;% addTiles(&#39;http://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png&#39;, attribution = &#39;&amp;copy; &lt;a href=&quot;http://openstreetmap.org&quot;&gt; OpenStreetMap&lt;/a&gt; contributors&#39;) %&gt;% addCircleMarkers(lng = officer_shootings_geocoded$lon, lat = officer_shootings_geocoded$lat) This makes the icon into circles but they are still large and cover most of the map. To adjust the size of our icons we use the radius parameter in addMarkers() or addCircleMarkers(). The larger the radius, the larger the icons. leaflet() %&gt;% addTiles(&#39;http://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png&#39;, attribution = &#39;&amp;copy; &lt;a href=&quot;http://openstreetmap.org&quot;&gt; OpenStreetMap&lt;/a&gt; contributors&#39;) %&gt;% addCircleMarkers(lng = officer_shootings_geocoded$lon, lat = officer_shootings_geocoded$lat, radius = 5) Setting the radius option to 5 shrinks the size of the icon a lot. In your own maps you’ll have to fiddle with this option to get it to look the way you want. Let’s move on to adding information about each icon when clicked upon. 16.3 Adding popup information The parameter popup in the addMarkers() or addCircleMarkers() functions lets you input a character value (if not already a character value it will convert it to one) and that will be shown as a popup when you click on the icon. Let’s start simple here by inputting the dates column in our data and then build it up to a more complicated popup. leaflet() %&gt;% addTiles(&#39;http://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png&#39;, attribution = &#39;&amp;copy; &lt;a href=&quot;http://openstreetmap.org&quot;&gt; OpenStreetMap&lt;/a&gt; contributors&#39;) %&gt;% addCircleMarkers(lng = officer_shootings_geocoded$lon, lat = officer_shootings_geocoded$lat, radius = 5, popup = officer_shootings_geocoded$dates) Try clicking around and you’ll see that the data of the incident you clicked on appears over the dot. Though fairly clear in this case, we usually want to have a title indicating what the value in the popup means. We can do this by using the paste() function to combine text explaining the value with the value itself. Let’s add the words “Date of Shooting:” before the date. leaflet() %&gt;% addTiles(&#39;http://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png&#39;, attribution = &#39;&amp;copy; &lt;a href=&quot;http://openstreetmap.org&quot;&gt; OpenStreetMap&lt;/a&gt; contributors&#39;) %&gt;% addCircleMarkers(lng = officer_shootings_geocoded$lon, lat = officer_shootings_geocoded$lat, radius = 5, popup = paste(&quot;Date of Shooting:&quot;,officer_shootings_geocoded$dates)) We don’t have many other columns but we can add the location and shooting number to the popup by adding them to the paste() function we’re using. leaflet() %&gt;% addTiles(&#39;http://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png&#39;, attribution = &#39;&amp;copy; &lt;a href=&quot;http://openstreetmap.org&quot;&gt; OpenStreetMap&lt;/a&gt; contributors&#39;) %&gt;% addCircleMarkers(lng = officer_shootings_geocoded$lon, lat = officer_shootings_geocoded$lat, radius = 5, popup = paste(&quot;Shooting Number:&quot;, officer_shootings_geocoded$shooting_number, &quot;Date:&quot;, officer_shootings_geocoded$dates, &quot;Location:&quot;, officer_shootings_geocoded$location)) Just adding the location text makes it try to print out everything on one line which is hard to read. If we add the text “” where we want a line break it will make one. is the HTML tag for linebreak which is why it works making a new line in this case. leaflet() %&gt;% addTiles(&#39;http://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png&#39;, attribution = &#39;&amp;copy; &lt;a href=&quot;http://openstreetmap.org&quot;&gt; OpenStreetMap&lt;/a&gt; contributors&#39;) %&gt;% addCircleMarkers(lng = officer_shootings_geocoded$lon, lat = officer_shootings_geocoded$lat, radius = 5, popup = paste(&quot;Shooting Number:&quot;, officer_shootings_geocoded$shooting_number, &quot;&lt;br&gt;&quot;, &quot;Date:&quot;, officer_shootings_geocoded$dates, &quot;&lt;br&gt;&quot;, &quot;Location:&quot;, officer_shootings_geocoded$location)) 16.4 Dealing with too many markers Even though we shrunk the size of the circles, it is still rather hard to see any trends as there are so many inicdents and relatively large circles. One solution is to keep shrinking the size of the circles, but this quickly becomes a bad solution when using more frequent data such as a crime data set (Philadelphia data alone has about 200k crimes reported per year). The other solution is to cluster the data into groups where the dots only show if you zoom down. If we add the code clusterOptions = markerClusterOptions() to our addCircleMarkers() it will cluster for us. leaflet() %&gt;% addTiles(&#39;http://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png&#39;, attribution = &#39;&amp;copy; &lt;a href=&quot;http://openstreetmap.org&quot;&gt; OpenStreetMap&lt;/a&gt; contributors&#39;) %&gt;% addCircleMarkers(lng = officer_shootings_geocoded$lon, lat = officer_shootings_geocoded$lat, radius = 5, popup = paste(&quot;Shooting Number:&quot;, officer_shootings_geocoded$shooting_number, &quot;&lt;br&gt;&quot;, &quot;Date:&quot;, officer_shootings_geocoded$dates, &quot;&lt;br&gt;&quot;, &quot;Location:&quot;, officer_shootings_geocoded$location), clusterOptions = markerClusterOptions()) Incidents close to each other are groups together in fairly arbitrary groupings and we can see how large each grouping is by moving our cursor over the circle. Click on the circle or zoom in and and it will show smaller groupings at lower levels of aggregation. Keep clicking or zooming in and it will eventually show each incident as its own circle. This method is very useful at dealing with huge amounts of data as it avoids overflowing the map with too many icons at one time. A downside, however, is that the clusters are created arbitrarily meaning that important context, such as neighborhood, can be lost. 16.5 Interactive choropleth maps In Chapter (choropleth-maps) we worked on choropleth maps which are maps with shaded regions, such as states colored by which political party won them in an election. Here we will make interactive choropleth maps where you can click on a shaded region and see information about that region. We’ll make the same map as before - Census tracts with the number of officer-involved shootings. Let’s load the tract-level officer-involved shooting data we made earlier. load(&quot;data/philly_tracts_shootings.rda&quot;) We’ll begin the leaflet map similar to before but use the function addPolygons() and our input here is the geometry column of philly_tracts_shootings. leaflet() %&gt;% addTiles(&#39;http://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png&#39;, attribution = &#39;&amp;copy; &lt;a href=&quot;http://openstreetmap.org&quot;&gt; OpenStreetMap&lt;/a&gt; contributors&#39;) %&gt;% addPolygons(data = philly_tracts_shootings$geometry) #&gt; Warning: sf layer is not long-lat data #&gt; Warning: sf layer has inconsistent datum (+proj=lcc +lat_1=40.96666666666667 +lat_2=39.93333333333333 +lat_0=39.33333333333334 +lon_0=-77.75 +x_0=600000 +y_0=0 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=us-ft +no_defs). #&gt; Need &#39;+proj=longlat +datum=WGS84&#39; It gives us a blank map because our polygons are projected to Philly’s projection while the leaflet map expects the standard CRS, WGS84 which uses longitude and latitude. So we need to change our projection to that using the st_transform() function from the sf package. library(sf) #&gt; Linking to GEOS 3.6.1, GDAL 2.2.3, PROJ 4.9.3 philly_tracts_shootings &lt;- st_transform(philly_tracts_shootings, crs = &quot;+proj=longlat +ellps=WGS84&quot;) Now let’s try again. leaflet() %&gt;% addTiles(&#39;http://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png&#39;, attribution = &#39;&amp;copy; &lt;a href=&quot;http://openstreetmap.org&quot;&gt; OpenStreetMap&lt;/a&gt; contributors&#39;) %&gt;% addPolygons(data = philly_tracts_shootings$geometry) #&gt; Warning: sf layer has inconsistent datum (+proj=longlat +ellps=WGS84 +no_defs). #&gt; Need &#39;+proj=longlat +datum=WGS84&#39; It made a map with large blue lines indicating each tract. Let’s change the appearance of the graph a bit before making a popup or shading the tracts. The parameter color in addPolygons() changes the color of the lines - let’s change it to black. The lines are also very large, blurring into each other and making the tracts hard to see. We can change the weight parameter to alter the size of these lines - smaller values are smaller lines. Let’s try setting this to 1. leaflet() %&gt;% addTiles(&#39;http://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png&#39;, attribution = &#39;&amp;copy; &lt;a href=&quot;http://openstreetmap.org&quot;&gt; OpenStreetMap&lt;/a&gt; contributors&#39;) %&gt;% addPolygons(data = philly_tracts_shootings$geometry, color = &quot;black&quot;, weight = 1) #&gt; Warning: sf layer has inconsistent datum (+proj=longlat +ellps=WGS84 +no_defs). #&gt; Need &#39;+proj=longlat +datum=WGS84&#39; That looks better and we can clearly distinguish each tract now. As we did earlier, we can add the popup text directly to the function which makes the geographic shapes, in this case addPolygons(). Let’s add the GEOID10 column value - the unique ID code for that tract - and the number of shootings that occurred in that tract. leaflet() %&gt;% addTiles(&#39;http://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png&#39;, attribution = &#39;&amp;copy; &lt;a href=&quot;http://openstreetmap.org&quot;&gt; OpenStreetMap&lt;/a&gt; contributors&#39;) %&gt;% addPolygons(data = philly_tracts_shootings$geometry, col = &quot;black&quot;, weight = 2, popup = paste0(&quot;Tract ID: &quot;, philly_tracts_shootings$GEOID10, &quot;&lt;br&gt;&quot;, &quot;Number of Shootings: &quot;, philly_tracts_shootings$number_shootings)) #&gt; Warning: sf layer has inconsistent datum (+proj=longlat +ellps=WGS84 +no_defs). #&gt; Need &#39;+proj=longlat +datum=WGS84&#39; pal &lt;- colorNumeric(&quot;viridis&quot;, NULL) leaflet() %&gt;% addTiles(&#39;http://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png&#39;, attribution = &#39;&amp;copy; &lt;a href=&quot;http://openstreetmap.org&quot;&gt; OpenStreetMap&lt;/a&gt; contributors&#39;) %&gt;% addPolygons(data = philly_tracts_shootings$geometry, col = &quot;black&quot;, weight = 2, popup = paste0(&quot;Tract ID: &quot;, philly_tracts_shootings$GEOID10, &quot;&lt;br&gt;&quot;, &quot;Number of Shootings: &quot;, philly_tracts_shootings$number_shootings), fillColor = pal(philly_tracts_shootings$number_shootings), fillOpacity = 1) %&gt;% addLegend(pal = pal, values = philly_tracts_shootings$number_shootings, opacity = 1) #&gt; Warning: sf layer has inconsistent datum (+proj=longlat +ellps=WGS84 +no_defs). #&gt; Need &#39;+proj=longlat +datum=WGS84&#39; "],
["ois-graphs.html", "17 More Graphing with ggplot 17.1 Graphing a single variable 17.2 Time Series", " 17 More Graphing with ggplot In this lesson we will continue to explore graphing using ggplot(). While the Philadelphia Police website does have a number of variables available in a table on the site for shootings since 2013, since we did not scrape them initially we’ll turn to a new data set. The data we will use is a data base of officer-involved shootings that result in a death in the United States since January 1st, 2015. This data has been compiled and released by the Washington Post so it will be a useful exercise in exploring data from non-government sources. This data is useful for our purposes as it has a number of variables related to the person who was shot, allowing us to practice making many types of graphs. To explore the data on their website, see here. To examine their methodology, see here. The data initially comes as a .csv file so we’ll use the read_csv() function from the readr package. library(readr) shootings &lt;- read_csv(&quot;data/fatal-police-shootings-data.csv&quot;) #&gt; Parsed with column specification: #&gt; cols( #&gt; id = col_double(), #&gt; name = col_character(), #&gt; date = col_date(format = &quot;&quot;), #&gt; manner_of_death = col_character(), #&gt; armed = col_character(), #&gt; age = col_double(), #&gt; gender = col_character(), #&gt; race = col_character(), #&gt; city = col_character(), #&gt; state = col_character(), #&gt; signs_of_mental_illness = col_logical(), #&gt; threat_level = col_character(), #&gt; flee = col_character(), #&gt; body_camera = col_logical() #&gt; ) Since read_csv() reads files into a tibble object, we’ll turn it into a data.frame just for simplicity. shootings &lt;- as.data.frame(shootings) Now that we have the data read in, let’s look at it. nrow(shootings) #&gt; [1] 4371 ncol(shootings) #&gt; [1] 14 The data has 14 variables and covers over 4,000 shootings. Let’s check out some of the variables, first using head() then using summary() and table(). head(shootings) #&gt; id name date manner_of_death armed age gender #&gt; 1 3 Tim Elliot 2015-01-02 shot gun 53 M #&gt; 2 4 Lewis Lee Lembke 2015-01-02 shot gun 47 M #&gt; 3 5 John Paul Quintero 2015-01-03 shot and Tasered unarmed 23 M #&gt; 4 8 Matthew Hoffman 2015-01-04 shot toy weapon 32 M #&gt; 5 9 Michael Rodriguez 2015-01-04 shot nail gun 39 M #&gt; 6 11 Kenneth Joe Brown 2015-01-04 shot gun 18 M #&gt; race city state signs_of_mental_illness threat_level #&gt; 1 A Shelton WA TRUE attack #&gt; 2 W Aloha OR FALSE attack #&gt; 3 H Wichita KS FALSE other #&gt; 4 W San Francisco CA TRUE attack #&gt; 5 H Evans CO FALSE attack #&gt; 6 W Guthrie OK FALSE attack #&gt; flee body_camera #&gt; 1 Not fleeing FALSE #&gt; 2 Not fleeing FALSE #&gt; 3 Not fleeing FALSE #&gt; 4 Not fleeing FALSE #&gt; 5 Not fleeing FALSE #&gt; 6 Not fleeing FALSE Each row is a single shooting and it includes variables such as the victim’s name, the date of the shooting, demographic information about that person, the shooting city and state, and some information about the incident. It is clear from these first 6 rows that most variables are categorical so we can’t use summary() on them. Let’s use summary() on the date and age columns and then use table() for the rest. summary(shootings$date) #&gt; Min. 1st Qu. Median Mean 3rd Qu. #&gt; &quot;2015-01-02&quot; &quot;2016-02-07&quot; &quot;2017-03-16&quot; &quot;2017-03-18&quot; &quot;2018-04-11&quot; #&gt; Max. #&gt; &quot;2019-06-25&quot; summary(shootings$age) #&gt; Min. 1st Qu. Median Mean 3rd Qu. Max. NA&#39;s #&gt; 6.00 27.00 35.00 36.84 45.00 91.00 182 From this we can see that the data is from January 1st through the middle of 2019 (The Washington Post is continuously updating their data but I downloaded it on June 27th, 2019 which is why June 2019 is the end of our data). From the age column we can see that the average age is about 35 with most people around that range. However, the youngest person is 6 years old while the oldest is 91. Additionally, 182 rows have missing values for this variable. Now we can use table() to see how often each value appears in each variable. We don’t want to do this for city or name as there would be too many values, but it will work for the other columns. Let’s start with manner_of_death. table(shootings$manner_of_death) #&gt; #&gt; shot shot and Tasered #&gt; 4146 225 To turn these counts into percentages we can divide the results by the number of rows in our data and multiply by 100. table(shootings$manner_of_death) / nrow(shootings) * 100 #&gt; #&gt; shot shot and Tasered #&gt; 94.852437 5.147563 Now it is clear to see that in 95% of shootings, officers used a gun and in 5% of shootings they also used a Taser. As this is data on officer shooting deaths, this is unsurprising. Let’s take a look at whether the victim was armed. table(shootings$armed) / nrow(shootings) * 100 #&gt; #&gt; air conditioner ax #&gt; 0.02287806 0.48043926 #&gt; barstool baseball bat #&gt; 0.02287806 0.27453672 #&gt; baseball bat and bottle baseball bat and fireplace poker #&gt; 0.02287806 0.02287806 #&gt; baton bayonet #&gt; 0.09151224 0.02287806 #&gt; BB gun bean-bag gun #&gt; 0.06863418 0.02287806 #&gt; beer bottle blunt object #&gt; 0.06863418 0.11439030 #&gt; bow and arrow box cutter #&gt; 0.02287806 0.22878060 #&gt; brick carjack #&gt; 0.04575612 0.02287806 #&gt; chain chain saw #&gt; 0.04575612 0.04575612 #&gt; chainsaw chair #&gt; 0.02287806 0.04575612 #&gt; claimed to be armed contractor&#39;s level #&gt; 0.02287806 0.02287806 #&gt; cordless drill crossbow #&gt; 0.02287806 0.20590254 #&gt; crowbar fireworks #&gt; 0.06863418 0.02287806 #&gt; flagpole flashlight #&gt; 0.02287806 0.02287806 #&gt; garden tool glass shard #&gt; 0.02287806 0.06863418 #&gt; gun gun and car #&gt; 55.43353924 0.11439030 #&gt; gun and knife gun and sword #&gt; 0.34317090 0.02287806 #&gt; gun and vehicle guns and explosives #&gt; 0.04575612 0.06863418 #&gt; hammer hand torch #&gt; 0.22878060 0.02287806 #&gt; hatchet hatchet and gun #&gt; 0.18302448 0.04575612 #&gt; incendiary device knife #&gt; 0.04575612 14.96225120 #&gt; lawn mower blade machete #&gt; 0.04575612 0.86936628 #&gt; machete and gun meat cleaver #&gt; 0.02287806 0.06863418 #&gt; metal hand tool metal object #&gt; 0.02287806 0.09151224 #&gt; metal pipe metal pole #&gt; 0.25165866 0.04575612 #&gt; metal rake metal stick #&gt; 0.02287806 0.06863418 #&gt; motorcycle nail gun #&gt; 0.02287806 0.02287806 #&gt; oar pellet gun #&gt; 0.02287806 0.02287806 #&gt; pen pepper spray #&gt; 0.02287806 0.02287806 #&gt; pick-axe piece of wood #&gt; 0.06863418 0.06863418 #&gt; pipe pitchfork #&gt; 0.13726836 0.04575612 #&gt; pole pole and knife #&gt; 0.04575612 0.04575612 #&gt; rock samurai sword #&gt; 0.09151224 0.02287806 #&gt; scissors screwdriver #&gt; 0.06863418 0.18302448 #&gt; sharp object shovel #&gt; 0.11439030 0.06863418 #&gt; spear stapler #&gt; 0.02287806 0.02287806 #&gt; straight edge razor sword #&gt; 0.06863418 0.34317090 #&gt; Taser tire iron #&gt; 0.41180508 0.02287806 #&gt; toy weapon unarmed #&gt; 3.54609929 6.36010066 #&gt; undetermined unknown weapon #&gt; 4.30107527 1.25829330 #&gt; vehicle vehicle and gun #&gt; 1.57858614 0.02287806 #&gt; walking stick wrench #&gt; 0.02287806 0.02287806 This is fairly hard to interpret as it is sorted alphabetically when we’d prefer it to be sorted by most common weapon. It also doesn’t round the percents. Let’s solve these two issues using sort() and round(). We could just wrap our initial code inside each of these functions but to avoid making too complicated code, we save the results in a temp object and incrementally use sort() and round() on that. We’ll round to two decimal places by setting the parameter digits to 2. temp &lt;- table(shootings$armed) / nrow(shootings) * 100 temp &lt;- sort(temp) temp &lt;- round(temp, digits = 2) temp #&gt; #&gt; air conditioner barstool #&gt; 0.02 0.02 #&gt; baseball bat and bottle baseball bat and fireplace poker #&gt; 0.02 0.02 #&gt; bayonet bean-bag gun #&gt; 0.02 0.02 #&gt; bow and arrow carjack #&gt; 0.02 0.02 #&gt; chainsaw claimed to be armed #&gt; 0.02 0.02 #&gt; contractor&#39;s level cordless drill #&gt; 0.02 0.02 #&gt; fireworks flagpole #&gt; 0.02 0.02 #&gt; flashlight garden tool #&gt; 0.02 0.02 #&gt; gun and sword hand torch #&gt; 0.02 0.02 #&gt; machete and gun metal hand tool #&gt; 0.02 0.02 #&gt; metal rake motorcycle #&gt; 0.02 0.02 #&gt; nail gun oar #&gt; 0.02 0.02 #&gt; pellet gun pen #&gt; 0.02 0.02 #&gt; pepper spray samurai sword #&gt; 0.02 0.02 #&gt; spear stapler #&gt; 0.02 0.02 #&gt; tire iron vehicle and gun #&gt; 0.02 0.02 #&gt; walking stick wrench #&gt; 0.02 0.02 #&gt; brick chain #&gt; 0.05 0.05 #&gt; chain saw chair #&gt; 0.05 0.05 #&gt; gun and vehicle hatchet and gun #&gt; 0.05 0.05 #&gt; incendiary device lawn mower blade #&gt; 0.05 0.05 #&gt; metal pole pitchfork #&gt; 0.05 0.05 #&gt; pole pole and knife #&gt; 0.05 0.05 #&gt; BB gun beer bottle #&gt; 0.07 0.07 #&gt; crowbar glass shard #&gt; 0.07 0.07 #&gt; guns and explosives meat cleaver #&gt; 0.07 0.07 #&gt; metal stick pick-axe #&gt; 0.07 0.07 #&gt; piece of wood scissors #&gt; 0.07 0.07 #&gt; shovel straight edge razor #&gt; 0.07 0.07 #&gt; baton metal object #&gt; 0.09 0.09 #&gt; rock blunt object #&gt; 0.09 0.11 #&gt; gun and car sharp object #&gt; 0.11 0.11 #&gt; pipe hatchet #&gt; 0.14 0.18 #&gt; screwdriver crossbow #&gt; 0.18 0.21 #&gt; box cutter hammer #&gt; 0.23 0.23 #&gt; metal pipe baseball bat #&gt; 0.25 0.27 #&gt; gun and knife sword #&gt; 0.34 0.34 #&gt; Taser ax #&gt; 0.41 0.48 #&gt; machete unknown weapon #&gt; 0.87 1.26 #&gt; vehicle toy weapon #&gt; 1.58 3.55 #&gt; undetermined unarmed #&gt; 4.30 6.36 #&gt; knife gun #&gt; 14.96 55.43 Now it is a little easier to interpret. In over half of the cases the victim was carrying a gun. 15% of the time they had a knife. And 6% of the time they were unarmed. In 4% of cases there is no data on any weapon. That leaves about 20% of cases where one of the many rare weapons were used, including some that overlap with one of the more common categories. Think about how you’d graph this data. There are 85 unique values in this column though only 7 of them are common enough to appear more than 1% of the time. Should we graph all of them? That’d overwhelm any graph. For a useful graph we would need to combine many of these into a single category - possibly called “other weapons”. And how do we deal with values where they could meet multiple larger categories? There is not always a clear answer for these types of questions. It depends on what data you’re interested in, the goal of the graph, the target audience, and personal preference. Let’s keep exploring the data by looking at gender and race. table(shootings$gender) / nrow(shootings) * 100 #&gt; #&gt; F M #&gt; 4.667124 95.218485 Nearly all of the shootings are of a man. Given that we saw most shootings involved a person with a weapon and that most violent crimes are committed by men, this shouldn’t be too surprising. temp &lt;- table(shootings$race) / nrow(shootings) * 100 temp &lt;- sort(temp) temp &lt;- round(temp, digits = 2) temp #&gt; #&gt; O N A H B W #&gt; 0.87 1.46 1.62 16.45 22.90 44.89 White people are the most likely to be killed by police followed by Black people and Hispanic people. We can do a simple cross-tab to see if there the relationship between gender and race. table(shootings$gender, shootings$race) #&gt; #&gt; A B H N O W #&gt; F 3 42 21 5 3 107 #&gt; M 68 959 697 59 35 1853 One annoying thing with these two variables is that it doesn’t spell out the name. Instead of “Female”, for example, it has “F”. For our graphs we want to spell out the words so it is clear to viewers. We’ll fix this issue, and the issue of having many weapon categories, as we graph each variable. We’ve spent some time looking at the data so now we’re ready to make the graphs. We need to load the ggplot2 package. library(ggplot2) 17.1 Graphing a single variable 17.1.1 Numeric variable As a reminder, the benefit of using ggplot() is we can start with a simple plot and build our way up to more complicated graphs. ggplot(shootings, aes(x = age)) + geom_density() #&gt; Warning: Removed 182 rows containing non-finite values (stat_density). ggplot(shootings, aes(x = age)) + geom_histogram() #&gt; `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. #&gt; Warning: Removed 182 rows containing non-finite values (stat_bin). 17.1.2 Categorical variable ggplot(shootings, aes(x = race)) + geom_bar() race_order &lt;- names(sort(table(shootings$race), decreasing = TRUE)) ggplot(shootings, aes(x = race)) + geom_bar() + scale_x_discrete(limits = race_order) #&gt; Warning: Removed 516 rows containing non-finite values (stat_count). For bar graphs it is often useful to flip the graph so each value is a row in the graph rather than a column. This also makes it much easier to read the value name. race_order &lt;- names(sort(table(shootings$race))) ggplot(shootings, aes(x = race)) + geom_bar(aes(y = (..count..)/sum(..count..))) + coord_flip() + scale_x_discrete(limits = race_order) #&gt; Warning: Removed 516 rows containing non-finite values (stat_count). race_order &lt;- names(sort(table(shootings$race))) ggplot(shootings, aes(x = race)) + geom_bar(aes(y = (..count..)/sum(..count..))) + coord_flip() + scale_x_discrete(limits = race_order) + scale_y_continuous(labels = scales::percent) #&gt; Warning: Removed 516 rows containing non-finite values (stat_count). We can reuse this code to make a similar graph for the gender variable. race_order &lt;- names(sort(table(shootings$gender))) ggplot(shootings, aes(x = gender)) + geom_bar(aes(y = (..count..)/sum(..count..))) + coord_flip() + scale_x_discrete(limits = race_order) + scale_y_continuous(labels = scales::percent) #&gt; Warning: Removed 5 rows containing non-finite values (stat_count). 17.2 Time Series library(lubridate) #&gt; #&gt; Attaching package: &#39;lubridate&#39; #&gt; The following object is masked from &#39;package:base&#39;: #&gt; #&gt; date shootings$dummy &lt;- 1 shootings$month_year &lt;- floor_date(shootings$date, unit = &quot;month&quot;) shootings$year &lt;- year(shootings$date) monthly_shootings &lt;- aggregate(dummy ~ month_year, data = shootings, FUN = sum) ggplot(monthly_shootings, aes(x = month_year, y = dummy)) + geom_line() yearly_shootings &lt;- aggregate(dummy ~ year, data = shootings, FUN = sum) ggplot(yearly_shootings, aes(x = year, y = dummy)) + geom_line() ggplot(yearly_shootings[yearly_shootings$year != 2019, ], aes(x = year, y = dummy)) + geom_line() yearly_shootings &lt;- aggregate(dummy ~ month_year, data = shootings[shootings$armed == &quot;unarmed&quot;, ], FUN = sum) ggplot(yearly_shootings, aes(x = month_year, y = dummy)) + geom_line() "],
["r-markdown.html", "18 R Markdown 18.1 Code 18.2 Figures and Tables 18.3 Making the output file", " 18 R Markdown R Markdown can help by reducing the number of things you have to think about. This guide can be used as an introduction to R Markdown, specifically for people working on a research thesis. Markdown works nearly identical to Word. The major difference is that it allows R code and you have to do more formatting yourself. If you do use Markdown, the main advice is to ignore formatting until the end! Just ignore formatting until you absolutely need to. It is easiest to output to an HTML file until you are ready to format. HTML generally ignores formatting issues (such as figure alignment) that PDF or Word encounter. d As seen above, you make a new R Markdown file using the same menu as making an R Script file, but now select R Markdown.... From here it’ll open up a window where you select the title, author, and type of output. You can always change all three of these selections right in the Markdown file. Selecting PDF may require you to download additional software to get it to output - some OS may already have the software installed. For a nice guide to using PDF with R Markdown, see here. Formatting is also trickier in PDF than in HTML or Word. When you click OK, it will open a new R Markdown file that is already populated with example plain text and code. You can delete this entirely or modify what’s there to work with what you need. The default R Markdown file Let’s start with the text and its formatting. The first line of text shows two pound signs (#) followed by “R Markdown”. When a line start with # it means that that line is a header. Sections of the thesis should start with an # to indicate a new section. There are 6 types of headers and each is smaller than the previous one (1 is biggest, 6 is smallest). Header 1 has one # (e.g. # Header 1), header 6 has 6 # (e.g. ###### Header 6). Headers after header 1 are good for making subsections. New paragraphs can be made by ending a line with two spaces (or, for simplicity you can just have an entire blank line between paragraphs). Though it is not common in academic writing, you can make a word (or words) italic by surrounding it by a single asterix or underscore, like so (*so*) and so (_so_). To bold a word (or words), use two asterix, like so (**so**) and so (__so__). Include a block quote by starting a line with &gt; followed by your quote This is a block quoted. Good for multiline quotes. You can make tables using formatting in the text, but it’s easier to do so using code. We will see that soon. Remembering all the formatting rules gets tricky and is not a good use of your time or effort. Refer to this reference guide for all the rules (such as how to include links in text). The reference guide includes more formatting options than noted here. This section of the free book R for Data Science is also an excellent resource. Again, focus on the content - write as if you were just using Word. Worry about formatting last. 18.1 Code The reason R Markdown is useful is because you can include code output in the file. Here is an example before we get into using code in Markdown. Below is an arbitrary graph. plot(1:100, type = &quot;h&quot;, col = &quot;yellow&quot;, main = &quot;Awful graph title&quot;) If you had put this graph in your Word document and decided to change it you would have to replace it every time you made a change. While this is a minor procedure, it adds up if you have many graphs or decide to change the graph frequently. Below is the same graph with just the title and color changed. If this were my thesis, I could have changed the original code and been assured that the most up-to-date graph (or table, etc.) is always the one included with the thesis. Change the code and never think about it. plot(1:100, type = &quot;h&quot;, col = &quot;blue&quot;, main = &quot;Great graph title!&quot;) 18.1.1 Only use code to make output Code in R Markdown is for showing results. This means only include the code that makes the graphs, tables (including regression output), etc.. The code to read in data and clean it should remain in your R Scripts. The code you do include here should only read in the cleaned data and create the output to include in the document. The terminology used here will be chunks. This just means pieces of R code included among the plain text. All code must be in these chunks to be run. Inside a chunk, you can run any code you like. To make a chunk, click Insert and then R. It will add a chunk wherever your cursor is. If you do not have the R Markdown file in the same folder as your data, you’ll need to set the working directory in a chunk before reading the data. However, once a working directory is set, or data is read, it applies for all following chunks. You will also need to run any packages (using library()) to use them in a chunk. Adding a new code chunk A code chunk Notice the three ` at the top and bottom of the chunk. Don’t touch these! They tell R that anything in it is a chunk (i.e. that R should run the code). Inside the squiggly brackets are instructions about how the code is outputted. Here you can specify, among other things (see reference guide for more), if the code will be outputted or just the output itself, captions for tables or graphs, and formatting for output. Include all of these options after the r in the squiggly brackets. Multiple options must be separated by a comma (just like options in normal R functions). The most common option is echo which says whether to show the code in the document or not. For the thesis you only want to show the output, not the code so include echo = FALSE. Here’s an example, first with default options then with echo = FALSE. print(&quot;Hello&quot;) #&gt; [1] &quot;Hello&quot; #&gt; [1] &quot;Hello&quot; Though you can’t see it unless looking at the Markdown file, there are two code chunks, the second which has the echo = FALSE option. That is why you only see the code “print(”Hello“)” above the first result. When you make the output file (called “knitting” the file), all code chunks will run and you will see the output included in the document. To run the code inside of RStudio, click the green right-arrow at the top-right of each chunk. This will run all code in that chunk. Run the code in a chunk 18.2 Figures and Tables Above was a code chunk that makes a graph. The only addition you will likely make to this type of code is to add a caption. Do this by adding the option fig.cap = \"\" with the caption in the quotes. Figure 18.1: This is an example figure caption Note the figure caption is in the chunk options section (squiggly brackets) There a number of packages that change how tables are displayed. We will use the basic knitr package. The easiest way to make a table in Markdown is to make a data.frame with all the data (and column names) you want and then show that data.frame. For this example we will subset the mtcars data (which is included in R) to just the first 5 rows and columns. The kable function from the knitr package will then make a nice looking table. With kable you can add the caption directly in the kable() function rather than using fig.cap =\"\" in the chunk. The option echo is set to TRUE here so you can see the code without looking at the Markdown file itself. library(knitr) mtcars_small &lt;- mtcars[1:5, 1:5] kable(mtcars_small, caption = &quot;This is an example table caption&quot;) Table 18.1: This is an example table caption mpg cyl disp hp drat Mazda RX4 21.0 6 160 110 3.90 Mazda RX4 Wag 21.0 6 160 110 3.90 Datsun 710 22.8 4 108 93 3.85 Hornet 4 Drive 21.4 6 258 110 3.08 Hornet Sportabout 18.7 8 360 175 3.15 18.3 Making the output file To create the Word or PDF output click Knit and it will create the output in the format set in the very top. To change this format click the white down-arrow directly to the right of Knit and it will drop-down a menu with output options. Click the option you want and it will output it in that format and change that to the new default. Sometimes it takes a while for it to output, so be patient. And sometimes it fails so just try to output again. Change the output format Markdown has many more options than presented here. This lesson should get you through the thesis. If you are interested in Markdown, there are great resources online. "],
["introduction.html", "19 Introduction", " 19 Introduction At this point you have learned how to read in data, manipulate it to get just the parts you want or to aggregate it to the level you want, and visualize it through maps or graphs. You’ve done so using data sets that are commonly used in criminological research. In the next several chapters we will be introducing a number of other data - or looking deeper into data we’ve already seen - that is common in criminology. While these chapters do use R a bit to explore or read in the data, they are primarily a discussion of what the data has and what they don’t have. Some of the data sets are difficult to read into R, requiring more steps than you may be useful, so these chapters will discuss how to get that data into R. "],
["ucr.html", "20 Uniform Crime Report (UCR) Data - Offenses Known and Clearances by Arrest 20.1 Exploring the UCR data 20.2 ORIs - Unique agency identifies 20.3 Hierarchy Rule 20.4 Which crimes are included 20.5 Actual offenses, clearances, and unfounded offenses", " 20 Uniform Crime Report (UCR) Data - Offenses Known and Clearances by Arrest The Uniform Crime Reports (UCR) are an collection of agency-level crime data published by the FBI. There are a number of different data sets included in the UCR including crime, arrests, hate crimes, arson, property stolen. We’ll be using the Offenses Known and Clearances by Arrest data set, which is the most commonly used data set in the UCR and is used as a shorthand for UCR data. In this lesson we’ll use “UCR” and “Offenses Known and Clearances by Arrest” interchangeably but keep in mind that doing so is technically incorrect. You can read more about the UCR program and all the data sets it includes on the National Archive of Criminal Justice Data page here. You can also check out my site Crime Data Tool which visualizes several of the UCR data sets and has some info in the FAQ explaining the data. Nearly every police agency in the United States - approximately 18,000 agencies including state, local (city, county, college), tribal and federal police departments - now reports their data to the FBI which compiles are releases the UCR data. This data is available since 1960 though early years have many fewer agencies reporting than do so in later years. The data file has annual data on the number of crimes reported, the number of crimes cleared, the number cleared where all offenders are under age 18, and the number of unfounded crimes. We’ll discuss each of this a bit further as we dive into the data. Agencies report the monthly number of each crime though the data we’ll work with has aggregated that to annual counts. Due to it’s longevity (it has data since 1960) and ubiquity (almost every agency reports and has done so for many years) it is a popular data set for criminologists. 20.1 Exploring the UCR data We are going to work with the combined annual count of crimes for every year available - 1960-2017 - which I’ve made available here. The FBI releases the data as a single file per year and each file has monthly counts of crime. This data set does some cleaning for us by aggregating yearly and making it a single file for the whole time period. The first step when working with this UCR data is loading it into R. As with loading any data, make sure that your working directory path is correctly set using setwd() so R knows which folder the data is in. load(&quot;data/offenses_known_yearly_1960_2017.rda&quot;) Let’s start with a basic examination of the data. First, how big it is, what variables it has, and what the units are. ncol(offenses_known_yearly_1960_2017) #&gt; [1] 159 nrow(offenses_known_yearly_1960_2017) #&gt; [1] 959010 names(offenses_known_yearly_1960_2017) #&gt; [1] &quot;ori&quot; &quot;ori9&quot; #&gt; [3] &quot;agency_name&quot; &quot;state&quot; #&gt; [5] &quot;state_abb&quot; &quot;year&quot; #&gt; [7] &quot;number_of_months_reported&quot; &quot;fips_state_code&quot; #&gt; [9] &quot;fips_county_code&quot; &quot;fips_state_county_code&quot; #&gt; [11] &quot;fips_place_code&quot; &quot;fips_state_place_code&quot; #&gt; [13] &quot;agency_type&quot; &quot;agency_subtype_1&quot; #&gt; [15] &quot;agency_subtype_2&quot; &quot;crosswalk_agency_name&quot; #&gt; [17] &quot;census_name&quot; &quot;population&quot; #&gt; [19] &quot;population_group&quot; &quot;country_division&quot; #&gt; [21] &quot;juvenile_age&quot; &quot;core_city_indication&quot; #&gt; [23] &quot;last_update&quot; &quot;fbi_field_office&quot; #&gt; [25] &quot;followup_indication&quot; &quot;zip_code&quot; #&gt; [27] &quot;covered_by_ori&quot; &quot;agency_count&quot; #&gt; [29] &quot;date_of_last_update&quot; &quot;month_included_in&quot; #&gt; [31] &quot;special_mailing_group&quot; &quot;special_mailing_address&quot; #&gt; [33] &quot;first_line_of_mailing_address&quot; &quot;second_line_of_mailing_address&quot; #&gt; [35] &quot;third_line_of_mailing_address&quot; &quot;fourth_line_of_mailing_address&quot; #&gt; [37] &quot;officers_killed_by_felony&quot; &quot;officers_killed_by_accident&quot; #&gt; [39] &quot;officers_assaulted&quot; &quot;actual_murder&quot; #&gt; [41] &quot;actual_manslaughter&quot; &quot;actual_rape_total&quot; #&gt; [43] &quot;actual_rape_by_force&quot; &quot;actual_rape_attempted&quot; #&gt; [45] &quot;actual_robbery_total&quot; &quot;actual_robbery_with_a_gun&quot; #&gt; [47] &quot;actual_robbery_with_a_knife&quot; &quot;actual_robbery_other_weapon&quot; #&gt; [49] &quot;actual_robbery_unarmed&quot; &quot;actual_assault_total&quot; #&gt; [51] &quot;actual_assault_with_a_gun&quot; &quot;actual_assault_with_a_knife&quot; #&gt; [53] &quot;actual_assault_other_weapon&quot; &quot;actual_assault_unarmed&quot; #&gt; [55] &quot;actual_assault_simple&quot; &quot;actual_burg_total&quot; #&gt; [57] &quot;actual_burg_force_entry&quot; &quot;actual_burg_nonforce_entry&quot; #&gt; [59] &quot;actual_burg_attempted&quot; &quot;actual_theft_total&quot; #&gt; [61] &quot;actual_mtr_veh_theft_total&quot; &quot;actual_mtr_veh_theft_car&quot; #&gt; [63] &quot;actual_mtr_veh_theft_truck&quot; &quot;actual_mtr_veh_theft_other&quot; #&gt; [65] &quot;actual_all_crimes&quot; &quot;actual_assault_aggravated&quot; #&gt; [67] &quot;actual_index_violent&quot; &quot;actual_index_property&quot; #&gt; [69] &quot;actual_index_total&quot; &quot;tot_clr_murder&quot; #&gt; [71] &quot;tot_clr_manslaughter&quot; &quot;tot_clr_rape_total&quot; #&gt; [73] &quot;tot_clr_rape_by_force&quot; &quot;tot_clr_rape_attempted&quot; #&gt; [75] &quot;tot_clr_robbery_total&quot; &quot;tot_clr_robbery_with_a_gun&quot; #&gt; [77] &quot;tot_clr_robbery_with_a_knife&quot; &quot;tot_clr_robbery_other_weapon&quot; #&gt; [79] &quot;tot_clr_robbery_unarmed&quot; &quot;tot_clr_assault_total&quot; #&gt; [81] &quot;tot_clr_assault_with_a_gun&quot; &quot;tot_clr_assault_with_a_knife&quot; #&gt; [83] &quot;tot_clr_assault_other_weapon&quot; &quot;tot_clr_assault_unarmed&quot; #&gt; [85] &quot;tot_clr_assault_simple&quot; &quot;tot_clr_burg_total&quot; #&gt; [87] &quot;tot_clr_burg_force_entry&quot; &quot;tot_clr_burg_nonforce_entry&quot; #&gt; [89] &quot;tot_clr_burg_attempted&quot; &quot;tot_clr_theft_total&quot; #&gt; [91] &quot;tot_clr_mtr_veh_theft_total&quot; &quot;tot_clr_mtr_veh_theft_car&quot; #&gt; [93] &quot;tot_clr_mtr_veh_theft_truck&quot; &quot;tot_clr_mtr_veh_theft_other&quot; #&gt; [95] &quot;tot_clr_all_crimes&quot; &quot;tot_clr_assault_aggravated&quot; #&gt; [97] &quot;tot_clr_index_violent&quot; &quot;tot_clr_index_property&quot; #&gt; [99] &quot;tot_clr_index_total&quot; &quot;clr_18_murder&quot; #&gt; [101] &quot;clr_18_manslaughter&quot; &quot;clr_18_rape_total&quot; #&gt; [103] &quot;clr_18_rape_by_force&quot; &quot;clr_18_rape_attempted&quot; #&gt; [105] &quot;clr_18_robbery_total&quot; &quot;clr_18_robbery_with_a_gun&quot; #&gt; [107] &quot;clr_18_robbery_with_a_knife&quot; &quot;clr_18_robbery_other_weapon&quot; #&gt; [109] &quot;clr_18_robbery_unarmed&quot; &quot;clr_18_assault_total&quot; #&gt; [111] &quot;clr_18_assault_with_a_gun&quot; &quot;clr_18_assault_with_a_knife&quot; #&gt; [113] &quot;clr_18_assault_other_weapon&quot; &quot;clr_18_assault_unarmed&quot; #&gt; [115] &quot;clr_18_assault_simple&quot; &quot;clr_18_burg_total&quot; #&gt; [117] &quot;clr_18_burg_force_entry&quot; &quot;clr_18_burg_nonforce_entry&quot; #&gt; [119] &quot;clr_18_burg_attempted&quot; &quot;clr_18_theft_total&quot; #&gt; [121] &quot;clr_18_mtr_veh_theft_total&quot; &quot;clr_18_mtr_veh_theft_car&quot; #&gt; [123] &quot;clr_18_mtr_veh_theft_truck&quot; &quot;clr_18_mtr_veh_theft_other&quot; #&gt; [125] &quot;clr_18_all_crimes&quot; &quot;clr_18_assault_aggravated&quot; #&gt; [127] &quot;clr_18_index_violent&quot; &quot;clr_18_index_property&quot; #&gt; [129] &quot;clr_18_index_total&quot; &quot;unfound_murder&quot; #&gt; [131] &quot;unfound_manslaughter&quot; &quot;unfound_rape_total&quot; #&gt; [133] &quot;unfound_rape_by_force&quot; &quot;unfound_rape_attempted&quot; #&gt; [135] &quot;unfound_robbery_total&quot; &quot;unfound_robbery_with_a_gun&quot; #&gt; [137] &quot;unfound_robbery_with_a_knife&quot; &quot;unfound_robbery_other_weapon&quot; #&gt; [139] &quot;unfound_robbery_unarmed&quot; &quot;unfound_assault_total&quot; #&gt; [141] &quot;unfound_assault_with_a_gun&quot; &quot;unfound_assault_with_a_knife&quot; #&gt; [143] &quot;unfound_assault_other_weapon&quot; &quot;unfound_assault_unarmed&quot; #&gt; [145] &quot;unfound_assault_simple&quot; &quot;unfound_burg_total&quot; #&gt; [147] &quot;unfound_burg_force_entry&quot; &quot;unfound_burg_nonforce_entry&quot; #&gt; [149] &quot;unfound_burg_attempted&quot; &quot;unfound_theft_total&quot; #&gt; [151] &quot;unfound_mtr_veh_theft_total&quot; &quot;unfound_mtr_veh_theft_car&quot; #&gt; [153] &quot;unfound_mtr_veh_theft_truck&quot; &quot;unfound_mtr_veh_theft_other&quot; #&gt; [155] &quot;unfound_all_crimes&quot; &quot;unfound_assault_aggravated&quot; #&gt; [157] &quot;unfound_index_violent&quot; &quot;unfound_index_property&quot; #&gt; [159] &quot;unfound_index_total&quot; We can see this is a very big file - 159 columns and nearly a million rows! Normally we’d use the head() function to see the first 6 rows of every column but since this data has so many columns we won’t do that as it’d be hard to read. Instead we can use View() to open what’s essentially an Excel file showing our data. This is useful to quickly glance at the data but is limited as it can bias us to believe that the first several rows are representative of the data. But, for a first glance it is useful and will be supplemented by better checks below. View(offenses_known_yearly_1960_2017) From looking at the data in View() we can see that the units are agency-years. Each row is a single agency for a single year. This is useful because it tells us we will have crime in agencies over time, which is a very common type of crime data. Let’s take a look at how many agencies report each year using the table() function which says how many times each value occurs for the column we select. This is also a useful check on if every year from 1960 to 2017 is actually available - don’t just trust that the data has what it says it has! table(offenses_known_yearly_1960_2017$year) #&gt; #&gt; 1960 1961 1962 1963 1964 1965 1966 1967 1968 1969 1970 1971 #&gt; 8452 8456 7825 8713 9038 9097 9147 9275 9398 9477 9835 10509 #&gt; 1972 1973 1974 1975 1976 1977 1978 1979 1980 1981 1982 1983 #&gt; 11302 12002 12510 13516 14518 15230 15770 16176 16413 16614 16792 16913 #&gt; 1984 1985 1986 1987 1988 1989 1990 1991 1992 1993 1994 1995 #&gt; 17037 17267 17441 17527 17298 17430 17608 17852 18012 18195 18367 18482 #&gt; 1996 1997 1998 1999 2000 2001 2002 2003 2004 2005 2006 2007 #&gt; 18536 18921 18510 18778 19655 19820 20214 20388 20585 20739 21011 21219 #&gt; 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 #&gt; 21353 21583 21771 21897 22049 22202 22332 22524 22645 22784 From these results it’s clear that there are huge differences in how many agencies report in early years compared to more recent years. Is this an issue in an analysis? From the above table it is concerning but not entirely clear there is an issue depending on our analysis. It we only care about recent years then it wouldn’t matter. If we only use large agencies, then knowing that relatively few agencies reported in 1960 doesn’t mean that few large agencies reported. For that you’d have to look closer at only the agencies you want to study - we won’t do that here but keep it in mind. 20.2 ORIs - Unique agency identifies In the UCR and other FBI data sets, agencies are identified using ORiginating Agency Identifiers** or ORIs. These are unique ID codes used to identify an agency. If we used the agency’s normal name we’d end up with some duplicates For example, if you looked for the Philadelphia Police Department using the agency name, you’d find both the “Philadelphia Police Department” in Pennsylvania and the one in Mississippi. head(offenses_known_yearly_1960_2017$ori) #&gt; [1] &quot;AK00101&quot; &quot;AK00101&quot; &quot;AK00101&quot; &quot;AK00101&quot; &quot;AK00101&quot; &quot;AK00101&quot; Each ORI is a 7-digit value starting with the state abbreviation (for some reason the FBI incorrectly puts the abbreviation for Nebraska as NB instead of NE) followed by 5 numbers. In the NIBRS data (another FBI data set which we’ll explore in Chapter (#nibrs)) the ORI uses a 9-digit code - expanding the 5 numbers to 7 numbers. When dealing with specific agencies, make sure to use the ORI rather than the agency name to avoid any mistakes. For an easy way to find the ORI number of an agency, use this site. Type an agency name or an ORI code into the search section and it will return everything that is a match. Lets look at some summary statistics of a few columns - we don’t want to run summary() on the whole data as it has too many columns. summary(offenses_known_yearly_1960_2017$actual_murder) #&gt; Min. 1st Qu. Median Mean 3rd Qu. Max. #&gt; -2.0000 0.0000 0.0000 0.9958 0.0000 2245.0000 summary(offenses_known_yearly_1960_2017$actual_rape_total) #&gt; Min. 1st Qu. Median Mean 3rd Qu. Max. #&gt; -3.000 0.000 0.000 4.311 1.000 4054.000 summary(offenses_known_yearly_1960_2017$actual_robbery_with_a_gun) #&gt; Min. 1st Qu. Median Mean 3rd Qu. Max. #&gt; -2.00 0.00 0.00 9.68 1.00 69618.00 20.3 Hierarchy Rule The UCR has what is called the Hierarchy Rule where only the most serious crime in an incident is reported (except for motor vehicle theft which is always included). For example if there is an incident where the victim is robbed and then murdered, only the murder is counted as it is considered more serious than the robbery. How much does this affect our data in practice? Actually very little. Though the Hierarchy Rule does mean this data is an under-count, data from other sources indicate it isn’t much of an under count. The FBI’s other data set, the National Inicident-Based Reporting System (NIBRS) contains every crime that occurs in an incident (i.e. it doesn’t use the Hierarchy Rule). Using this we can measure how many crimes the Hierarchy Rule excludes (Most major cities do not report to NIBRS so what we find in NIBRS may not apply to them). In over 90% of incidents, only one crime is committed. Additionally, when people talk about “crime” they usually mean murder which, while incomplete to discuss crime, means the UCR data here is accurate on that measure. 20.4 Which crimes are included If you look back at the output when we ran names(offenses_known_yearly_1960_2017) you’ll see that it produced five broad categories of columns. The first was information about the agency including population and geographic info, then came four columns with the same values except starting with “actual”, “tot_clr”, “clr_18”, and “unfound”. Following these starting values was 30 crime categories. We’ll discuss what each of those starting values mean in a bit, let’s first talk about which crimes are included and what that means for research. 20.4.1 Index Crimes The Offenses Known and Clearances by Arrest data set contains information on the number of “Index Crimes” (sometimes called Part I crimes) reported to each agency. Other data sets in the UCR, such as the Arrests by Age, Sex, and Race data and the Hate Crime data have more crimes reported. These index crimes are a collection of eight crimes that, for historical reasons based largely by perceived importance in the 1920’s when the UCR program was first developed, are used as the primary measure of crime today. The crimes are, in order by the Hierarchy Rule - Homicide Murder and non-negligent manslaughter Manslaughter by negligence Rape Rape Attempted rape Robbery With a firearm With a knife of cutting instrument With a dangerous weapon not otherwise specified Unarmed - using hands, fists, feet, etc. Aggravated Assault (assault with a weapon or causing serious bodily injury) With a firearm With a knife of cutting instrument With a dangerous weapon not otherwise specified Unarmed - using hands, fists, feet, etc. Burglary With forcible entry Without forcible entry Attempted burglary with forcible entry Theft (other than of a motor vehicle) Motor Vehicle Theft Cars Trucks and buses Other vehicles Arson Simple Assault For a full definition of each of the index crimes see the FBI’s Offense Definitions page here. Arson is considered an index crime but is not reported in this data - you need to use the separate Arson data set of the UCR to get access to arson counts. The ninth crime on that list, simple assault, is not considered an index crime but is nevertheless included in this data. Each of the crimes in the list above, and their subcategories, are included in the UCR data. In most reports, however, you’ll see them reported as the total number of index crimes, summing up categories 1-7 and reporting that as “crime”. These index crimes are often divided into violent index crimes - murder, rape, robbery, and aggravated assault - and property index crimes - burglary, theft, motor vehicle theft. 20.4.2 The problem with using index crimes The biggest problem with index crimes is that it is simply the sum of 8 (or 7 since arson data usually isn’t available) crimes. Index crimes have a huge range in their seriousness - it includes both murder and theft.This is clearly wrong as 100 murders is more serious than 100 thefts. This is especially a problem as less serious crimes (theft mostly) are far more common than more serious crimes (in 2017 there were 1.25 million violent index crimes in the United States. That same year had 5.5 million thefts.). So index crimes under-count the seriousness of crimes. Looking at total index crimes is, in effect, mostly just looking at theft. This is especially a problem because it hide trends in violent crimes. San Francisco, as an example, has had a huge increase in index crimes in the last several years. When looking closer, that increase is driven almost entirely by the near doubling of theft since 2011. During the same years, violent crime has stayed fairly steady. So the city isn’t getting more dangerous but it appears like it is due to just looking at total index crimes. While many researchers divide index crimes into violent and nonviolent categories, which helps but even this isn’t entirely sufficient. Take Chicago as an example. It is a city infamous for its large number of murders. But as a fraction of index crimes, Chicago has a rounding error worth of murders. Their 653 murders in 2017 is only 0.5% of total index crimes. For violent index crimes, murder makes up 2.2%. What this means is that changes in murder are very difficult to detect. If Chicago had no murders this year, but a less serious crime (such as theft) increased slightly, we couldn’t tell from looking at the number of index crimes. 20.4.3 Rape definition change Starting in 2013, rape has a new, broader definition in the UCR to include oral and anal penetration (by a body part or object) and allow men to be victims. The previous definition included only forcible intercourse against a woman. As this revised definition is broader than the original one, more rapes are reported ( social changes may also be partly responsible as they could encourage victims to report more). This definition change makes post-2013 rape data non-comparable to pre-2013 data. 20.5 Actual offenses, clearances, and unfounded offenses For each crime we have four different categories indicating the number of crimes actually committed, the number cleared, and the number determined to not have occurred. 20.5.1 Actual This is the number of offenses that occurred, simply a count of the number of crimes that month. For example if 10 people are murdered in a city the number of “actual murders” would be 10. 20.5.2 Total Cleared A crime is cleared when an offender is arrested or when the case is considered cleared by exceptional means. When a single offender for a crime is arrested, that crime is considered cleared. If multiple people committed a crime, only a single person must be arrested for it to be cleared, and as the UCR data is at the offense level, making multiple arrests for an incident only counts as one incident cleared. So if 10 people committed a murder and all 10 were arrested, it would report one murder cleared not 10. If only one of these people are arrested it would still report one murder cleared - the UCR does not even say how many people commit a crime. A crime is considered exceptionally cleared if the police can identify the offender, have enough evidence to arrest the offender, know where the offender is, but is unable to arrest them. Some examples of this are the death of the offender or when the victim refuses to cooperate in the case. Unfortunately this data does not differentiate between clearances by arrest or by exceptional means. For a comprehensive report on how this variable can be exploited to exaggerate clearance rates, see this report by ProPublica on exceptional clearances with rape cases. 20.5.3 Cleared Where All Offenders Are Under 18 This variable is very similar to Total Cleared except is only for offenses in which every offender is younger than age 18. 20.5.4 Unfounded An unfounded crime is one in which a police investigation has determined that the reported crime did not actually happen. For example if the police are called to a possible burglary but later find out that a burglary did not occur they would put it down as 1 unfounded burglary. This is based on police investigation rather than the decision of any other party such as a coroner, judge, jury, or prosecutor. "],
["census-data-from-social-explorer.html", "21 Census Data from Social Explorer 21.1 Getting Census data from Social Explorer", " 21 Census Data from Social Explorer 21.1 Getting Census data from Social Explorer Social Explorer is a convenient tool to let us get Census data in a relatively clean format. The tool has interactive graphs for a huge number of variables and different levels of geographies for data in the United States. For our purposes we will focus on their Tables feature which lets you select different data sets (we will focus on Census data), select the variables you want, and get an Excel file with that data. We will do this to get tract-level Census data and merge it in with the tract-level shooting data to make some basic scatterplots and correlations. For students on Penn’s campus you can go directly to Social Explorer’s Website since Penn pays for a license to use the site. Otherwise you can go through a link in the school’s library website here, click “Connect to resource.” near the bottom. For those going through the library website, click “Use as guest” on the page it opens up. We want a table to click Tables on the left side of the page. And we’ll get data from the American Community Surveys (5-Year Estimates). Once you click “Census Tract data (CSV)” it’ll download a .csv file. I have renamed the file “philly_census_tract_essentials.csv” to give it a more descriptive name. Now we are ready to work with this data and merge it with the shootings data. library(readr) tracts &lt;- read_csv(&quot;data/philly_census_tract_essentials.csv&quot;) #&gt; Warning: Duplicated column names deduplicated: &#39;Total Population&#39; =&gt; #&gt; &#39;Total Population_1&#39; [59], &#39;Area (Land)&#39; =&gt; &#39;Area (Land)_1&#39; [61], &#39;Total #&gt; Population:&#39; =&gt; &#39;Total Population:_1&#39; [65], &#39;Total Population:&#39; =&gt; &#39;Total #&gt; Population:_2&#39; [78] #&gt; Parsed with column specification: #&gt; cols( #&gt; .default = col_character() #&gt; ) #&gt; See spec(...) for full column specifications. "],
["census-data-from-ipums.html", "22 Census Data from IPUMS 22.1 Getting IPUMS data 22.2 Cleaning the data 22.3 Aggregating the data 22.4 Graphing the data 22.5 Mapping the data", " 22 Census Data from IPUMS In Chapter 15 we used the website Social Explorer to look at Census data at the Census tract level. This is a tool to quickly get Census data without writing too much code. As mentioned earlier, there are a number of limitations to this tool. Primarily that we are limited to just the variables it decides to give us. If we want other variables, or combinations of variables, we need to use another tool. 22.1 Getting IPUMS data 22.2 Cleaning the data 22.3 Aggregating the data 22.4 Graphing the data 22.5 Mapping the data "],
["nibrs.html", "23 National Incident-Based Reporting System (NIBRS) Data 23.1 Downloading the data 23.2 Reading the data", " 23 National Incident-Based Reporting System (NIBRS) Data https://www.icpsr.umich.edu/icpsrweb/ICPSR/studies/25109 Through our work with the UCR, we’ve already discussed reported crime. Nonetheless, not all crimes are reported to the police. Also, sometimes the UCR doesn’t provide us with specific information about a victim-involved crime incident such as whether the victim knew the offenders or the location of the crime incident. Each year, the U.S. Census Bureau conducts the National Crime Victimization Survey (NCVS), which is a valuable source of self-reported victimization data. The Census Bureau interviews a sample of people about the number and characteristics of crime victimizations they experienced during the prior 6 months. In 2015, for example, they collected data from 95,760 households and 163,880 persons. The NCVS contains valuable information about nonfatal personal crimes such as rape or robbery as well as property crimes such as burglary. Additional information about the NCVS can be found at the BJS website. To give a sense of the type of data that the NCVS contains, refer to the Official 2012-2013 BJS Crime Victimization report. 23.1 Downloading the data First, we will download the [NCVS 2016] data()https://www.icpsr.umich.edu/icpsrweb/NACJD/studies/36828/datadocumentation. We want the following file: DS4 Incident Record-Type File. Click the download button to the right and select “ASCII + SPSS Setup”. Don’t select R. While NACJD does provide the data as an R file, this file has some issues where the column names are not easy to understand (e.g. Often they are just the letter V followed by a number such as V1, V2, V3). Using the ASCII+SPSS file lets us easily read in the data with usable column names. That’ll download a zipped folder. Inside the folder is another folder called ICPSR_36828. Inside that is a folder called DS0004 (named 4 as it is the 4th file available to download on that page), and inside that are the two files we want: “36828-0004-Data.txt” and “36828-0004-Setup”. Take both of these files and move them into your working directory. NACJD data will come with a numeric name which is just the unique identifier of that data. So I prefer to change the name to something that is easy to understand what the file holds. In this case I renamed the files to “ncvs_incident_2016.txt” and “ncvs_incident_2016.sps”. 23.2 Reading the data (The FBI still sends out their data in this format!) To read in these files we will use the package asciiSetupReader which has been built for this exact purpose. install.packages(&quot;asciiSetupReader&quot;) library(asciiSetupReader) Unlike when reading in .rda files, with this package we read in the file to an object which we name ourselves. We will call it ncvs for ease. The relevant function is read_ascii_setup() which has two mandatory parameters data and setup_file. data is the name (in quotes) of the text (.txt) file which holds the data. setup_file is similar but now is the name of the setup (.sps) file, again in quotes. ` As a standard first step let’s check the number of rows and columns in the data. This data has 952 columns which is too many for us to run names() or head(). That many variables means that most of the columns are not relevant for our purposes here. What we want to do is make a smaller data set with only the relevant columns. That way we have data that can be easily checked with head() or View(). When dealing with enormous data sets (such as NIBRS data we’ll look at soon that can have millions of rows), having smaller files makes the code run quicker and in some cases allows it to run at all (too big of a file can cause R to run extremely slowly or crash). Normally we would subset this data to keep only the columns we want to use. However, as we used the asciiSetupReader package, there is a better solution. The read_ascii_setup() function has a parameter select_columns that allows us to select the columns we want and it will only read in those columns. This is useful as it means we can start with a subsetted file which avoids any issues of reading in enormous files. For select_columns we need to have a vector c() of either numbers or the column names (in quotes) that we want to keep. For this, open up the file “ncvs_incident_2016.sps” (this is not an R file so you can just double-click it to open on your computer’s default software for this type of file, usually Microsoft Word or Wordpad). Scroll down to the selection labeled “VARIABLE LABELS” and it will show a list of variable names on the left and “cleaned” versions of their names on the right. (You can also choose columns by using the codebook included in the folder downloaded from NACJD. The codebook is helpful because it explains what each variable means and you should definitely read the codebook before working with new data. However, as NCVS data has several different files included (Address-level, Household-level, Person-level, and Incident-level), the codebook covers all of these. The file “ncvs_incident_2016.sps” includes only the incident-level data columns we are using so it is a little easier to work with in this case.) "],
["useful-resources.html", "A Useful Resources", " A Useful Resources A.0.1 Learning R and coding issues R for Data Science - This free online book provides a good introduction for R though it differs in several important ways from this class. Stack Overflow - Stack Overflow is a website that answers programming-related questions. It’s like the Yahoo Answers of programming. That said, a lot of the answer are bad. Some answers are overly confusing or provide code that you may not understand. You can use this source, but don’t rely too heavily on it. Its search function isn’t great so it’s better to Google your question and choose the stackoverflow.com result. A.0.2 Data Crime Data - Crime Data (cleaned) - General Data - Census Data - Local crime data - "]
]
